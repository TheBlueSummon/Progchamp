[
    {
        "name": "DeepOnto",
        "description": "A package for ontology engineering with deep learning and language models.",
        "languages": {
            "Python": 380409,
            "Scala": 75701,
            "Java": 2419,
            "Shell": 375,
            "Groovy": 294,
            "Batchfile": 158
        }
    },
    {
        "name": "opendigitaltwins-building",
        "description": "Open Digital Twins Definition Language (DTDL) RealEstateCore Ontology",
        "languages": {}
    },
    {
        "name": "umls2rdf",
        "description": "These python scripts connect to the Unified Medical Language System (UMLS) database and translate the ontologies into RDF/OWL files. This is part of the BioPortal project.",
        "languages": {
            "Python": 29571,
            "Shell": 983
        }
    },
    {
        "name": "LLMs4OL",
        "description": "LLMs4OL:\u200c Large Language Models for Ontology Learning",
        "languages": {
            "Python": 227801,
            "Jupyter Notebook": 50606,
            "Shell": 20369,
            "Dockerfile": 546
        }
    },
    {
        "name": "-L-",
        "description": "W3C Strategic Highlights  September 2019  This report was prepared for the September 2019 W3C Advisory Committee Meeting (W3C Member link). See the accompanying W3C Fact Sheet \u2014 September 2019. For the previous edition, see the April 2019 W3C Strategic Highlights. For future editions of this report, please consult the latest version.  A Chinese translation is available.  \u2630 Contents  Introduction Future Web Standards Meeting Industry Needs Web Payments Digital Publishing Media and Entertainment Web & Telecommunications Real-Time Communications (WebRTC) Web & Networks Automotive Web of Things Strengthening the Core of the Web HTML CSS Fonts SVG Audio Performance Web Performance WebAssembly Testing Browser Testing and Tools WebPlatform Tests Web of Data Web for All Security, Privacy, Identity Internationalization (i18n) Web Accessibility Outreach to the world W3C Developer Relations W3C Training Translations W3C Liaisons Introduction  This report highlights recent work of enhancement of the existing landscape of the Web platform and innovation for the growth and strength of the Web.  33 working groups and a dozen interest groups enable W3C to pursue its mission through the creation of Web standards, guidelines, and supporting materials. We track the tremendous work done across the Consortium through homogeneous work-spaces in Github which enables better monitoring and management.  We are in the middle of a period where we are chartering numerous working groups which demonstrate the rapid degree of change for the Web platform:  After 4 years, we are nearly ready to publish a Payment Request API Proposed Recommendation and we need to soon charter follow-on work. In the last year we chartered the Web Payment Security Interest Group. In the last year we chartered the Web Media Working Group with 7 specifications for next generation Media support on the Web. We have Accessibility Guidelines under W3C Member review which includes Silver, a new approach. We have just launched the Decentralized Identifier Working Group which has tremendous potential because Decentralized Identifier (DID) is an identifier that is globally unique, resolveable with high availability, and cryptographically verifiable. We have Privacy IG (PING) under W3C Member review which strengthens our focus on the tradeoff between privacy and function. We have a new CSS charter under W3C Member review which maps the group's work for the next three years. In this period, W3C and the WHATWG have succesfully completed the negotiation of a Memorandum of Understanding rooted in the mutual belief that that having two distinct specifications claiming to be normative is generally harmful for the Web community. The MOU, signed last May, describes how the two organizations are to collaborate on the development of a single authoritative version of the HTML and DOM specifications. W3C subsequently rechartered the HTML Working Group to assist the W3C community in raising issues and proposing solutions for the HTML and DOM specifications, and for the production of W3C Recommendations from WHATWG Review Drafts.  As the Web evolves continuously, some groups are looking for ways for specifications to do so as well. So-called \"evergreen recommendations\" or \"living standards\" aim to track continuous development (and maintenance) of features, on a feature-by-feature basis, while getting review and patent commitments.  We see the maturation and further development of an incredible number of new technologies coming to the Web. Continued progress in many areas demonstrates the vitality of the W3C and the Web community, as the rest of the report illustrates.  Future Web Standards W3C has a variety of mechanisms for listening to what the community thinks could become good future Web standards. These include discussions with the Membership, discussions with other standards bodies, the activities of thousands of participants in over 300 community groups, and W3C Workshops. There are lots of good ideas. The W3C strategy team has been identifying promising topics and invites public participation.   Future, recent and under consideration Workshops include:  Inclusive XR (5-6 November 2019, Seattle, WA, USA) to explore existing and future approaches on making Virtual and Augmented Reality experiences more inclusive, including to people with disabilities; W3C Workshop on Data Models for Transportation (12-13 September 2019, Palo Alto, CA, USA) W3C Workshop on Web Games (27-28 June 2019, Redmond, WA, USA), view report Second W3C Workshop on the Web of Things (3-5 June 2019, Munich, Germany) W3C Workshop on Web Standardization for Graph Data; Creating Bridges: RDF, Property Graph and SQL (4-6 March 2019, Berlin, Germany), view report Web & Machine Learning. The Strategy Funnel documents the staff's exploration of potential new work at various phases: Exploration and Investigation, Incubation and Evaluation, and eventually to the chartering of a new standards group. The Funnel view is a GitHub Project where new area are issues represented by \u201ccards\u201d which move through the columns, usually from left to right. Most cards start in Exploration and move towards Chartering, or move out of the funnel.  Public input is welcome at any stage but particularly once Incubation has begun. This helps W3C identify work that is sufficiently incubated to warrant standardization, to review the ecosystem around the work and indicate interest in participating in its standardization, and then to draft a charter that reflects an appropriate scope. Ongoing feedback can speed up the overall standardization process.  Since the previous highlights document, W3C has chartered a number of groups, and started discussion on many more:  Newly Chartered or Rechartered  Web Application Security WG (03-Apr) Web Payment Security IG (17-Apr) Patent and Standards IG (24-Apr) Web Applications WG (14-May) Web & Networks IG (16-May) Media WG (23-May) Media and Entertainment IG (06-Jun) HTML WG (06-Jun) Decentralized Identifier WG (05-Sep) Extended  Privacy IG (PING) (30-Sep) Verifiable Claims WG (30-Sep) Service Workers WG (31-Dec) Dataset Exchange WG (31-Dec) Web of Things Working Group (31-Dec) Web Audio Working Group (31-Dec) Proposed charters / Advance Notice  Accessibility Guidelines WG Privacy IG (PING) RDF Literal Direction WG Timed Text WG CSS WG Web Authentication WG Closed  Internationalization Tag Set IG Meeting Industry Needs Web Payments   All Web Payments specifications  W3C's payments standards enable a streamlined checkout experience, enabling a consistent user experience across the Web with lower front end development costs for merchants. Users can store and reuse information and more quickly and accurately complete online transactions.  The Web Payments Working Group has republished Payment Request API as a Candidate Recommendation, aiming to publish a Proposed Recommendation in the Fall 2019, and is discussing use cases and features for Payment Request after publication of the 1.0 Recommendation. Browser vendors have been finalizing implementation of features added in the past year (view the implementation report).  As work continues on the Payment Handler API and its implementation (currently in Chrome and Edge Canary), one focus in 2019 is to increase adoption in other browsers. Recently, Mastercard demonstrated the use of Payment Request API to carry out EMVCo's Secure Remote Commerce (SRC) protocol whose payment method definition is being developed with active participation by Visa, Mastercard, American Express, and Discover. Payment method availability is a key factor in merchant considerations about adopting Payment Request API. The ability to get uniform adoption of a new payment method such as Secure Remote Commerce (SRC) also depends on the availability of the Payment Handler API in browsers, or of proprietary alternatives.  Web Monetization, which the Web Payments Working Group will discuss again at its face-to-face meeting in September, can be used to enable micropayments as an alternative revenue stream to advertising.  Since the beginning of 2019, Amazon, Brave Software, JCB, Certus Cybersecurity Solutions and Netflix have joined the Web Payments Working Group.  In April, W3C launched the Web Payment Security Group to enable W3C, EMVCo, and the FIDO Alliance to collaborate on a vision for Web payment security and interoperability. Participants will define areas of collaboration and identify gaps between existing technical specifications in order to increase compatibility among different technologies, such as:  How do SRC, FIDO, and Payment Request relate? The Payment Services Directive 2 (PSD2) regulations in Europe are scheduled to take effect in September 2019. What is the role of EMVCo, W3C, and FIDO technologies, and what is the current state of readiness for the deadline? How can we improve privacy on the Web at the same time as we meet industry requirements regarding user identity? Digital Publishing   All Digital Publishing specifications, Publication milestones  The Web is the universal publishing platform. Publishing is increasingly impacted by the Web, and the Web increasingly impacts Publishing.  Topic of particular interest to Publishing@W3C include typography and layout, accessibility, usability, portability, distribution, archiving, offline access, print on demand, and reliable cross referencing. And the diverse publishing community represented in the groups consist of the traditional \"trade\" publishers, ebook reading system manufacturers, but also publishers of audio book, scholarly journals or educational materials, library scientists or browser developers.  The Publishing Working Group currently concentrates on Audiobooks which lack a comprehensive standard, thus incurring extra costs and time to publish in this booming market. Active development is ongoing on the future standard:  Publication Manifest Audiobook profile for Web Publications Lightweight Packaging Format The BD Comics Manga Community Group, the Synchronized Multimedia for Publications Community Group, the Publishing Community Group and a future group on archival, are companions to the working group where specific work is developed and incubated.  The Publishing Community Group is a recently launched incubation channel for Publishing@W3C. The goal of the group is to propose, document, and prototype features broadly related to:  publications on the Web reading modes and systems and the user experience of publications The EPUB 3 Community Group has successfully completed the revision of EPUB 3.2.  The Publishing Business Group fosters ongoing participation by members of the publishing industry and the overall ecosystem in the development of Web infrastructure to better support the needs of the industry. The Business Group serves as an additional conduit to the Publishing Working Group and several Community Groups for feedback between the publishing ecosystem and W3C. The Publishing BG has played a vital role in fostering and advancing the adoption and continued development of EPUB 3. In particular the BG provided critical support to the update of EPUBCheck to validate EPUB content to the new EPUB 3.2 specification. This resulted in the development, in conjunction with the EPUB3 Community Group, of a new generation of EPUBCheck, i.e., EPUBCheck 4.2 production-ready release.  Media and Entertainment   All Media specifications  The Media and Entertainment vertical tracks media-related topics and features that create immersive experiences for end users. HTML5 brought standard audio and video elements to the Web. Standardization activities since then have aimed at turning the Web into a professional platform fully suitable for the delivery of media content and associated materials, enabling missing features to stream video content on the Web such as adaptive streaming and content protection. Together with Microsoft, Comcast, Netflix and Google, W3C received an Technology & Engineering Emmy Award in April 2019 for standardization of a full TV experience on the Web. Current goals are to:  Reinforce core media technologies: Creation of the Media Working Group, to develop media-related specifications incubated in the WICG (e.g. Media Capabilities, Picture-in-picture, Media Session) and maintain maintain/evolve Media Source Extensions (MSE) and Encrypted Media Extensions (EME). Improve support for Media Timed Events: data cues incubation. Enhance color support (HDR, wide gamut), in scope of the CSS WG and in the Color on the Web CG. Reduce fragmentation: Continue annual releases of a common and testable baseline media devices, in scope of the Web Media APIs CG and in collaboration with the CTA WAVE Project. Maintain the Road-map of Media Technologies for the Web which highlights Web technologies that can be used to build media applications and services, as well as known gaps to enable additional use cases. Create the future: Discuss perspectives for Media and Entertainment for the Web. Bring the power of GPUs to the Web (graphics, machine learning, heavy processing), under incubation in the GPU for the Web CG. Transition to a Working Group is under discussion. Determine next steps after the successful W3C Workshop on Web Games of June 2019. View the report. Timed Text  The Timed Text Working Group develops and maintains formats used for the representation of text synchronized with other timed media, like audio and video, and notably works on TTML, profiles of TTML, and WebVTT. Recent progress includes:  A robust WebVTT implementation report poises the specification for publication as a proposed recommendation. Discussions around re-chartering, notably to add a TTML Profile for Audio Description deliverable to the scope of the group, and clarify that rendering of captions within XR content is also in scope. Immersive Web  Hardware that enables Virtual Reality (VR) and Augmented Reality (AR) applications are now broadly available to consumers, offering an immersive computing platform with both new opportunities and challenges. The ability to interact directly with immersive hardware is critical to ensuring that the web is well equipped to operate as a first-class citizen in this environment.  The Immersive Web Working Group has been stabilizing the WebXR Device API while the companion Immersive Web Community Group incubates the next series of features identified as key for the future of the Immersive Web.  W3C plans a workshop focused on the needs and benefits at the intersection of VR & Accessibility (Inclusive XR), on 5-6 November 2019 in Seattle, WA, USA, to explore existing and future approaches on making Virtual and Augmented Reality experiences more inclusive.  Web & Telecommunications  The Web is the Open Platform for Mobile. Telecommunication service providers and network equipment providers have long been critical actors in the deployment of Web technologies. As the Web platform matures, it brings richer and richer capabilities to extend existing services to new users and devices, and propose new and innovative services.  Real-Time Communications (WebRTC)   All Real-Time Communications specifications  WebRTC has reshaped the whole communication landscape by making any connected device a potential communication end-point, bringing audio and video communications anywhere, on any network, vastly expanding the ability of operators to reach their customers. WebRTC serves as the corner-stone of many online communication and collaboration services.  The WebRTC Working Group aims to bringing WebRTC 1.0 (and companion specification Media Capture and Streams) to Recommendation by the end of 2019. Intense efforts are focused on testing (supported by a dedicated hackathon at IETF 104) and interoperability. The group is considering pushing features that have not gotten enough traction to separate modules or to a later minor revision of the spec.  Beyond WebRTC 1.0, the WebRTC Working Group will focus its efforts on WebRTC NV which the group has started documenting by identifying use cases.  Web & Networks  Recently launched, in the wake of the May 2018 Web5G workshop, the Web & Networks Interest Group is chaired by representatives from AT&T, China Mobile and Intel, with a goal to explore solutions for web applications to achieve better performance and resource allocation, both on the device and network. The group's first efforts are around use cases, privacy & security requirements and liaisons.  Automotive   All Automotive specifications  To create a rich application ecosystem for vehicles and other devices allowed to connect to the vehicle, the W3C Automotive Working Group is delivering a service specification to expose all common vehicle signals (engine temperature, fuel/charge level, range, tire pressure, speed, etc.)  The Vehicle Information Service Specification (VISS), which is a Candidate Recommendation, is seeing more implementations across the industry. It provides the access method to a common data model for all the vehicle signals \u2013presently encapsulating a thousand or so different data elements\u2013 and will be growing to accommodate the advances in automotive such as autonomous and driver assist technologies and electrification.  The group is already working on a successor to VISS, leveraging the underlying data model and the VIWI submission from Volkswagen, for a more robust means of accessing vehicle signals information and the same paradigm for other automotive needs including location-based services, media, notifications and caching content.  The Automotive and Web Platform Business Group acts as an incubator for prospective standards work. One of its task forces is using W3C VISS in performing data sampling and off-boarding the information to the cloud. Access to the wealth of information that W3C's auto signals standard exposes is of interest to regulators, urban planners, insurance companies, auto manufacturers, fleet managers and owners, service providers and others. In addition to components needed for data sampling and edge computing, capturing user and owner consent, information collection methods and handling of data are in scope.  The upcoming W3C Workshop on Data Models for Transportation (September 2019) is expected to focus on the need of additional ontologies around transportation space.  Web of Things   All Web of Things specifications  W3C's Web of Things work is designed to bridge disparate technology stacks to allow devices to work together and achieve scale, thus enabling the potential of the Internet of Things by eliminating fragmentation and fostering interoperability.  Thing descriptions expressed in JSON-LD cover the behavior, interaction affordances, data schema, security configuration, and protocol bindings. The Web of Things complements existing IoT ecosystems to reduce the cost and risk for suppliers and consumers of applications that create value by combining multiple devices and information services. There are many sectors that will benefit, e.g. smart homes, smart cities, smart industry, smart agriculture, smart healthcare and many more.  The Web of Things Working Group is finishing the initial Web of Things standards, with support from the Web of Things Interest Group:  Web of Things Architecture Thing Descriptions Strengthening the Core of the Web HTML   The HTML Working Group was chartered early June to assist the W3C community in raising issues and proposing solutions for the HTML and DOM specifications, and to produce W3C Recommendations from WHATWG Review Drafts.  A few days before, W3C and the WHATWG signed a Memorandum of Understanding outlining the agreement to collaborate on the development of a single version of the HTML and DOM specifications.  Issues and proposed solutions for HTML and DOM done via the newly rechartered HTML Working Group in the WHATWG repositories  The HTML Working Group is targetting November 2019 to bring HTML and DOM to Candidate Recommendations.  CSS  All CSS specifications  CSS is a critical part of the Open Web Platform. The CSS Working Group gathers requirements from two large groups of CSS users: the publishing industry and application developers. Within W3C, those groups are exemplified by the Publishing groups and the Web Platform Working Group. The former requires things like better pagination support and advanced font handling, the latter needs intelligent (and fast!) scrolling and animations.  What we know as CSS is actually a collection of almost a hundred specifications, referred to as \u2018modules\u2019. The current state of CSS is defined by a snapshot, updated once a year. The group also publishes an index defining every term defined by CSS specifications.  Fonts   All Fonts specifications  The Web Fonts Working Group develops specifications that allow the interoperable deployment of downloadable fonts on the Web, with a focus on Progressive Font Enrichment as well as maintenance of WOFF Recommendations.  Recent and ongoing work includes:  Early API experiments by Adobe and Monotype have demonstrated the feasibility of a font enrichment API, where a server delivers a font with minimal glyph repertoire and the client can query the full repertoire and request additional subsets on-the-fly. In other experiments, the Brotli compression used in WOFF 2 was extended to support shared dictionaries and patch update. Metrics to quantify improvement are a current hot discussion topic. The group will meet at ATypi 2019 in Japan, to gather requirements from the international typography community. The group will first produce a report summarizing the strengths and weaknesses of each prototype solution by Q2 2020. SVG   All SVG specifications  SVG is an important and widely-used part of the Open Web Platform. The SVG Working Group focuses on aligning the SVG 2.0 specification with browser implementations, having split the specification into a currently-implemented 2.0 and a forward-looking 2.1. Current activity is on stabilization, increased integration with the Open Web Platform, and test coverage analysis.  The Working Group was rechartered in March 2019. A new work item concerns native (non-Web-browser) uses of SVG as a non-interactive, vector graphics format.  Audio  The Web Audio Working Group was extended to finish its work on the Web Audio API, expecting to publish it as a Recommendation by year end. The specification enables synthesizing audio in the browser. Audio operations are performed with audio nodes, which are linked together to form a modular audio routing graph. Multiple sources \u2014 with different types of channel layout \u2014 are supported. This modular design provides the flexibility to create complex audio functions with dynamic effects.  The first version of Web Audio API is now feature complete and is implemented in all modern browsers. Work has started on the next version, and new features are being incubated in the Audio Community Group.  Performance   Web Performance  All Web Performance specifications  There are currently 18 specifications in development in the Web Performance Working Group aiming to provide methods to observe and improve aspects of application performance of user agent features and APIs. The W3C team is looking at related work incubated in the W3C GPU for the Web (WebGPU) Community Group which is poised to transition to a W3C Working Group. A preliminary draft charter is available.  WebAssembly  All WebAssembly specifications  WebAssembly improves Web performance and power by being a virtual machine and execution environment enabling loaded pages to run native (compiled) code. It is deployed in Firefox, Edge, Safari and Chrome. The specification will soon reach Candidate Recommendation.  WebAssembly enables near-native performance, optimized load time, and perhaps most importantly, a compilation target for existing code bases. While it has a small number of native types, much of the performance increase relative to Javascript derives from its use of consistent typing. WebAssembly leverages decades of optimization for compiled languages and the byte code is optimized for compactness and streaming (the web page starts executing while the rest of the code downloads). Network and API access all occurs through accompanying Javascript libraries -- the security model is identical to that of Javascript.  Requirements gathering and language development occur in the Community Group while the Working Group manages test development, community review and progression of specifications on the Recommendation Track.  Testing  Browser testing plays a critical role in the growth of the Web by:  Improving the reliability of Web technology definitions; Improving the quality of implementations of these technologies by helping vendors to detect bugs in their products; Improving the data available to Web developers on known bugs and deficiencies of Web technologies by publishing results of these tests. Browser Testing and Tools  The Browser Testing and Tools Working Group is developing WebDriver version 2, having published last year the W3C Recommendation of WebDriver. WebDriver acts as a remote control interface that enables introspection and control of user agents, provides a platform- and language-neutral wire protocol as a way for out-of-process programs to remotely instruct the behavior of Web, and emulates the actions of a real person using the browser.  WebPlatform Tests   The WebPlatform Tests project now provides a mechanism which allows to fully automate tests that previously needed to be run manually: TestDriver.  TestDriver enables sending trusted key and mouse events, sending complex series of trusted pointer and key interactions for things like in-content drag-and-drop or pinch zoom, and even file upload.  Since 2014 W3C began work on this coordinated open-source effort to build a cross-browser test suite for the Web Platform, which WHATWG, and all major browsers adopted.  Web of Data   All Data specifications  There have been several great success stories around the standardization of data on the web over the past year.  Verifiable Claims seems to have significant uptake. It is also significant that the Distributed Identifier WG charter has received numerous favorable reviews, and was just recently launched. JSON-LD has been a major success with the large deployment on Web sites via schema.org.  JSON-LD 1.1 completed technical work, about to transition to CR More than 25% of websites today include schema.org data in JSON-LD The Web of Things description is in CR since May, making use of JSON-LD Verifiable Credentials data model is in CR since July, also making use of JSON-LD Continued strong interest in decentralized identifiers Engagement from the TAG with reframing core documents, such as Ethical Web Principles, to include data on the web within their scope Data is increasingly important for all organizations, especially with the rise of IoT and Big Data. W3C has a mature and extensive suite of standards relating to data that were developed over two decades of experience, with plans for further work on making it easier for developers to work with graph data and knowledge graphs.  Linked Data is about the use of URIs as names for things, the ability to dereference these URIs to get further information and to include links to other data. There are ever-increasing sources of open Linked Data on the Web, as well as data services that are restricted to the suppliers and consumers of those services.  The digital transformation of industry is seeking to exploit advanced digital technologies. This will facilitate businesses to integrate horizontally along the supply and value chains, and vertically from the factory floor to the office floor. W3C is seeking to make it easier to support enterprise-wide data management and governance, reflecting the strategic importance of data to modern businesses.  Traditional approaches to data have focused on tabular databases (SQL/RDBMS), Comma Separated Value (CSV) files, and data embedded in PDF documents and spreadsheets. We're now in midst of a major shift to graph data with nodes and labeled directed links between them. Graph data is:  Faster than using SQL and associated JOIN operations More favorable to integrating data from heterogeneous sources Better suited to situations where the data model is evolving In the wake of the recent W3C Workshop on Graph Data we are in the process of launching a Graph Standardization Business Group to provide a business perspective with use cases and requirements, to coordinate technical standards work and liaisons with external organizations.  Web for All Security, Privacy, Identity  All Security specifications, all Privacy specifications  Authentication on the Web   As the WebAuthn Level 1 W3C Recommendation published last March is seeing wide implementation and adoption of strong cryptographic authentication, work is proceeding on Level 2.  The open standard Web API gives native authentication technology built into native platforms, browsers, operating systems (including mobile) and hardware, offering protection against hacking, credential theft, phishing attacks, thus aiming to end the era of passwords as a security construct. You may read more in our March press release.  Privacy  An increasing number of W3C specifications are benefitting from Privacy and Security review; there are security and privacy aspects to every specification. Early review is essential. Working with the TAG, the Privacy Interest Group has updated the Self-Review Questionnaire: Security and Privacy.  Other recent work of the group includes public blogging further to the exploration of anti-patterns in standards and permission prompts.  Security  The Web Application Security Working Group adopted Feature Policy, aiming to allow developers to selectively enable, disable, or modify the behavior of some of these browser features and APIs within their application; and Fetch Metadata, aiming to provide servers with enough information to make a priori decisions about whether or not to service a request based on the way it was made, and the context in which it will be used.  The Web Payment Security Interest Group, launched last April, convenes members from W3C, EMVCo, and the FIDO Alliance to discuss cooperative work to enhance the security and interoperability of Web payments (read more about payments).  Internationalization (i18n)   All Internationalization specifications, educational articles related to Internationalization, spec developers checklist  Only a quarter or so current Web users use English online and that proportion will continue to decrease as the Web reaches more and more communities of limited English proficiency. If the Web is to live up to the \"World Wide\" portion of its name, and for the Web to truly work for stakeholders all around the world engaging with content in various languages, it must support the needs of worldwide users as they engage with content in the various languages. The growth of epublishing also brings requirements for new features and improved typography on the Web. It is important to ensure the needs of local communities are captured.  The W3C Internationalization Initiative was set up to increase in-house resources dedicated to accelerating progress in making the World Wide Web \"worldwide\" by gathering user requirements, supporting developers, and education & outreach.  For an overview of current projects see the i18n radar. W3C's Internationalization efforts progressed on a number of fronts recently:  Requirements: New African and European language groups will work on the gap analysis, errata and layout requirements. Gap analysis: Japanese, Devanagari, Bengali, Tamil, Lao, Khmer, Javanese, and Ethiopic updated in the gap-analysis documents. Layout requirements document: notable progress tracked in the Southeast Asian Task Force while work continues on Chinese layout requirements. Developer support: Spec reviews: the i18n WG continues active review of specifications of the WHATWG and other W3C Working Groups. Short review checklist: easy way to begin a self-review to help spec developers understand what aspects of their spec are likely to need attention for internationalization, and points them to more detailed checklists for the relevant topics. It also helps those reviewing specs for i18n issues. Strings on the Web: Language and Direction Metadata lays out issues and discusses potential solutions for passing information about language and direction with strings in JSON or other data formats. The document was rewritten for clarity, and expanded. The group is collaborating with the JSON-LD and Web Publishing groups to develop a plan for updating RDF, JSON-LD and related specifications to handle metadata for base direction of text (bidi). User-friendly test format: a new format was developed for Internationalization Test Suite tests, which displays helpful information about how the test works. This particularly useful because those tests are pointed to by educational materials and gap-analysis documents. Web Platform Tests: a large number of tests in the i18n test suite have been ported to the WPT repository, including: css-counter-styles, css-ruby, css-syntax, css-test, css-text-decor, css-writing-modes, and css-pseudo. Education & outreach: (for all educational materials, see the HTML & CSS Authoring Techniques) Web Accessibility   All Accessibility specifications, WAI resources  The Web Accessibility Initiative supports W3C's Web for All mission. Recent achievements include:  Education and training: Inaccessibility of CAPTCHA updated to bring our analysis and recommendations up to date with CAPTCHA practice today, concluding two years of extensive work and invaluable input from the public (read more on the W3C Blog Learn why your web content and applications should be accessible. The Education and Outreach Working Group has completed revision and updating of the Business Case for Digital Accessibility. Accessibility guidelines: The Accessibility Guidelines Working Group has continued to update WCAG Techniques and Understanding WCAG 2.1; and published a Candidate Recommendation of Accessibility Conformance Testing Rules Format 1.0 to improve inter-rater reliability when evaluating conformance of web content to WCAG An updated charter is being developed to host work on \"Silver\", the next generation accessibility guidelines (WCAG 2.2) There are accessibility aspects to most specifications. Check your work with the FAST checklist.  Outreach to the world W3C Developer Relations   To foster the excellent feedback loop between Web Standards development and Web developers, and to grow participation from that diverse community, recent W3C Developer Relations activities include:  @w3cdevs tracks the enormous amount of work happening across W3C W3C Track during the Web Conference 2019 in San Francisco Tech videos: W3C published the 2019 Web Games Workshop videos The 16 September 2019 Developer Meetup in Fukuoka, Japan, is open to all and will combine a set of technical demos prepared by W3C groups, and a series of talks on a selected set of W3C technologies and projects W3C is involved with Mozilla, Google, Samsung, Microsoft and Bocoup in the organization of ViewSource 2019 in Amsterdam (read more on the W3C Blog) W3C Training   In partnership with EdX, W3C's MOOC training program, W3Cx offers a complete \"Front-End Web Developer\" (FEWD) professional certificate program that consists of a suite of five courses on the foundational languages that power the Web: HTML5, CSS and JavaScript. We count nearly 900K students from all over the world.  Translations  Many Web users rely on translations of documents developed at W3C whose official language is English. W3C is extremely grateful to the continuous efforts of its community in ensuring our various deliverables in general, and in our specifications in particular, are made available in other languages, for free, ensuring their exposure to a much more diverse set of readers.  Last Spring we developed a more robust system, a new listing of translations of W3C specifications and updated the instructions on how to contribute to our translation efforts.  W3C Liaisons   Liaisons and coordination with numerous organizations and Standards Development Organizations (SDOs) is crucial for W3C to:  make sure standards are interoperable coordinate our respective agenda in Internet governance: W3C participates in ICANN, GIPO, IGF, the I* organizations (ICANN, IETF, ISOC, IAB). ensure at the government liaison level that our standards work is officially recognized when important to our membership so that products based on them (often done by our members) are part of procurement orders. W3C has ARO/PAS status with ISO. W3C participates in the EU MSP and Rolling Plan on Standardization ensure the global set of Web and Internet standards form a compatible stack of technologies, at the technical and policy level (patent regime, fragmentation, use in policy making) promote Standards adoption equally by the industry, the public sector, and the public at large Coralie Mercier, Editor, W3C Marketing & Communications $Id: Overview.html,v 1.60 2019/10/15 12:05:52 coralie Exp $ Copyright \u00a9 2019 W3C \u00ae (MIT, ERCIM, Keio, Beihang) Usage policies apply.",
        "languages": {}
    },
    {
        "name": "opendigitaltwins-tools",
        "description": "Tools for Open Digital Twins Definition Language (DTDL) RealEstateCore Ontology ",
        "languages": {
            "C#": 514801,
            "Bicep": 73039,
            "Python": 6665,
            "PowerShell": 2114,
            "Makefile": 200
        }
    },
    {
        "name": "ontouml-lightweight-editor",
        "description": "The OntoUML lightweight editor (OLED) is an environment for the development, evaluation and implementation of domain ontologies using the UFO-based ontologically well-founded modeling language OntoUML. The tool provides a simple, lightweight and integrated set of features to ontology engineers, such as syntactical verification, visual simulation, model checking, model inference, automatic semantic-anti-patterns detection and correction, validation of part-hood relations and ontology patterns. The tool aggregates many direct and indirect contributions for NEMO http://nemo.inf.ufes.br/ research group members.",
        "languages": {
            "Java": 11238466,
            "Python": 63898,
            "Shell": 22055,
            "Lex": 20300,
            "Alloy": 20020
        }
    },
    {
        "name": "opendigitaltwins-building",
        "description": "WillowTwin open digital twin definition language (DTDL) ontology for buildings and real estate",
        "languages": {
            "C#": 1926
        }
    },
    {
        "name": "langue",
        "description": "A modern platform for conlanging. Currently in the planning stage.",
        "languages": {
            "TypeScript": 4065
        }
    },
    {
        "name": "Konclude",
        "description": "Konclude: A parallel, tableau-based, high-performance reasoner for the Description Logic SROIQV(D)/the Web Ontology Language (OWL) 2 DL",
        "languages": {
            "C++": 26335736,
            "QMake": 382406,
            "GAP": 23775,
            "C": 168,
            "Shell": 88,
            "Batchfile": 47
        }
    },
    {
        "name": "cowl",
        "description": "\ud83e\udd89 A lightweight C/C++ library for working with Web Ontology Language (OWL) ontologies",
        "languages": {
            "C": 462531,
            "Yacc": 40307,
            "CMake": 9977,
            "Lex": 8880
        }
    },
    {
        "name": "freya",
        "description": "FREyA is a Natural Language Interface for Querying Ontologies",
        "languages": {
            "Perl": 7494480,
            "Java": 741380,
            "JavaScript": 311210,
            "Web Ontology Language": 158750,
            "HTML": 12704,
            "Makefile": 9409,
            "CSS": 3142
        }
    },
    {
        "name": "clinical_informatics_umls",
        "description": "An exploratory, tutorial and analytical view of the Unified Medical Language System (UMLS) & the software/technologies provided via being a free UMLS license holder. This repo will subset 2021AB UMLS native release, introduce/build upon UMLS provided tools to load a configured subset into first a relational database --> MySQL, SQLite, PostgreSQL and MariaDB all covered within this repo. Next the UMLS subset which is stored in a relational DB will be queried, modeled and lastly loaded into a defined Neo4j label property graph. Lastly, Neo4j database containing UMLS 2021AB subset in schema promoting intuitive analysis and rich visualization will become the central datastore for analysis. The datastore contains ~5 million distinct nodes & >40 million distinct relationships (edges). Currently, Neo4j is running via Docker but deployment options are NOT limited to Docker. If choosing to deploy via Neo4j Aura, server, Neo4j Desktop, VM etc... Please note and be aware of the specific volumes and environment variables specified within this repository (docker run). The ability for the loaded Neo4j Graph to interact with RDF data (i.e. import/export RDF data to and from Neo4j) may not be possible via all Neo4j deployment avenues (i.e. Neo4j Aura currently does not support RDF integration that is demonstrated in this repository).",
        "languages": {
            "Python": 46530,
            "Jupyter Notebook": 33856,
            "Shell": 6860,
            "Cypher": 1510
        }
    },
    {
        "name": "References",
        "description": " Poole, Mackworth & Goebel 1998, p. 1.  Russell & Norvig 2003, p. 55.  Definition of AI as the study of intelligent agents: Poole, Mackworth & Goebel (1998), which provides the version that is used in this article. These authors use the term \"computational intelligence\" as a synonym for artificial intelligence.[1] Russell & Norvig (2003) (who prefer the term \"rational agent\") and write \"The whole-agent view is now widely accepted in the field\".[2] Nilsson 1998 Legg & Hutter 2007  Russell & Norvig 2009, p. 2.  McCorduck 2004, p. 204  Maloof, Mark. \"Artificial Intelligence: An Introduction, p. 37\" (PDF). georgetown.edu. Archived (PDF) from the original on 25 August 2018.  \"How AI Is Getting Groundbreaking Changes In Talent Management And HR Tech\". Hackernoon. Archived from the original on 11 September 2019. Retrieved 14 February 2020.  Schank, Roger C. (1991). \"Where's the AI\". AI magazine. Vol. 12 no. 4. p. 38.  Russell & Norvig 2009.  \"AlphaGo \u2013 Google DeepMind\". Archived from the original on 10 March 2016.  Allen, Gregory (April 2020). \"Department of Defense Joint AI Center - Understanding AI Technology\" (PDF). AI.mil - The official site of the Department of Defense Joint Artificial Intelligence Center. Archived (PDF) from the original on 21 April 2020. Retrieved 25 April 2020.  Optimism of early AI: * Herbert Simon quote: Simon 1965, p. 96 quoted in Crevier 1993, p. 109. * Marvin Minsky quote: Minsky 1967, p. 2 quoted in Crevier 1993, p. 109.  Boom of the 1980s: rise of expert systems, Fifth Generation Project, Alvey, MCC, SCI: * McCorduck 2004, pp. 426\u2013441 * Crevier 1993, pp. 161\u2013162,197\u2013203, 211, 240 * Russell & Norvig 2003, p. 24 * NRC 1999, pp. 210\u2013211 * Newquist 1994, pp. 235\u2013248  First AI Winter, Mansfield Amendment, Lighthill report * Crevier 1993, pp. 115\u2013117 * Russell & Norvig 2003, p. 22 * NRC 1999, pp. 212\u2013213 * Howe 1994 * Newquist 1994, pp. 189\u2013201  Second AI winter: * McCorduck 2004, pp. 430\u2013435 * Crevier 1993, pp. 209\u2013210 * NRC 1999, pp. 214\u2013216 * Newquist 1994, pp. 301\u2013318  AI becomes hugely successful in the early 21st century * Clark 2015  Pamela McCorduck (2004, p. 424) writes of \"the rough shattering of AI in subfields\u2014vision, natural language, decision theory, genetic algorithms, robotics ... and these with own sub-subfield\u2014that would hardly have anything to say to each other.\"  This list of intelligent traits is based on the topics covered by the major AI textbooks, including: * Russell & Norvig 2003 * Luger & Stubblefield 2004 * Poole, Mackworth & Goebel 1998 * Nilsson 1998  Kolata 1982.  Maker 2006.  Biological intelligence vs. intelligence in general: Russell & Norvig 2003, pp. 2\u20133, who make the analogy with aeronautical engineering. McCorduck 2004, pp. 100\u2013101, who writes that there are \"two major branches of artificial intelligence: one aimed at producing intelligent behavior regardless of how it was accomplished, and the other aimed at modeling intelligent processes found in nature, particularly human ones.\" Kolata 1982, a paper in Science, which describes McCarthy's indifference to biological models. Kolata quotes McCarthy as writing: \"This is AI, so we don't care if it's psychologically real\".[19] McCarthy recently reiterated his position at the AI@50 conference where he said \"Artificial intelligence is not, by definition, simulation of human intelligence\".[20].  Neats vs. scruffies: * McCorduck 2004, pp. 421\u2013424, 486\u2013489 * Crevier 1993, p. 168 * Nilsson 1983, pp. 10\u201311  Symbolic vs. sub-symbolic AI: * Nilsson (1998, p. 7), who uses the term \"sub-symbolic\".  General intelligence (strong AI) is discussed in popular introductions to AI: * Kurzweil 1999 and Kurzweil 2005  See the Dartmouth proposal, under Philosophy, below.  McCorduck 2004, p. 34.  McCorduck 2004, p. xviii.  McCorduck 2004, p. 3.  McCorduck 2004, pp. 340\u2013400.  This is a central idea of Pamela McCorduck's Machines Who Think. She writes: \"I like to think of artificial intelligence as the scientific apotheosis of a venerable cultural tradition.\"[26] \"Artificial intelligence in one form or another is an idea that has pervaded Western intellectual history, a dream in urgent need of being realized.\"[27] \"Our history is full of attempts\u2014nutty, eerie, comical, earnest, legendary and real\u2014to make artificial intelligences, to reproduce what is the essential us\u2014bypassing the ordinary means. Back and forth between myth and reality, our imaginations supplying what our workshops couldn't, we have engaged for a long time in this odd form of self-reproduction.\"[28] She traces the desire back to its Hellenistic roots and calls it the urge to \"forge the Gods.\"[29]  \"Stephen Hawking believes AI could be mankind's last accomplishment\". BetaNews. 21 October 2016. Archived from the original on 28 August 2017.  Lombardo P, Boehm I, Nairz K (2020). \"RadioComics \u2013 Santa Claus and the future of radiology\". Eur J Radiol. 122 (1): 108771. doi:10.1016/j.ejrad.2019.108771. PMID 31835078.  Ford, Martin; Colvin, Geoff (6 September 2015). \"Will robots create more jobs than they destroy?\". The Guardian. Archived from the original on 16 June 2018. Retrieved 13 January 2018.  AI applications widely used behind the scenes: * Russell & Norvig 2003, p. 28 * Kurzweil 2005, p. 265 * NRC 1999, pp. 216\u2013222 * Newquist 1994, pp. 189\u2013201  AI in myth: * McCorduck 2004, pp. 4\u20135 * Russell & Norvig 2003, p. 939  AI in early science fiction. * McCorduck 2004, pp. 17\u201325  Formal reasoning: * Berlinski, David (2000). The Advent of the Algorithm. Harcourt Books. ISBN 978-0-15-601391-8. OCLC 46890682. Archived from the original on 26 July 2020. Retrieved 22 August 2020.  Turing, Alan (1948), \"Machine Intelligence\", in Copeland, B. Jack (ed.), The Essential Turing: The ideas that gave birth to the computer age, Oxford: Oxford University Press, p. 412, ISBN 978-0-19-825080-7  Russell & Norvig 2009, p. 16.  Dartmouth conference: * McCorduck 2004, pp. 111\u2013136 * Crevier 1993, pp. 47\u201349, who writes \"the conference is generally recognized as the official birthdate of the new science.\" * Russell & Norvig 2003, p. 17, who call the conference \"the birth of artificial intelligence.\" * NRC 1999, pp. 200\u2013201  McCarthy, John (1988). \"Review of The Question of Artificial Intelligence\". Annals of the History of Computing. 10 (3): 224\u2013229., collected in McCarthy, John (1996). \"10. Review of The Question of Artificial Intelligence\". Defending AI Research: A Collection of Essays and Reviews. CSLI., p. 73, \"[O]ne of the reasons for inventing the term \"artificial intelligence\" was to escape association with \"cybernetics\". Its concentration on analog feedback seemed misguided, and I wished to avoid having either to accept Norbert (not Robert) Wiener as a guru or having to argue with him.\"  Hegemony of the Dartmouth conference attendees: * Russell & Norvig 2003, p. 17, who write \"for the next 20 years the field would be dominated by these people and their students.\" * McCorduck 2004, pp. 129\u2013130  Russell & Norvig 2003, p. 18.  Schaeffer J. (2009) Didn't Samuel Solve That Game?. In: One Jump Ahead. Springer, Boston, MA  Samuel, A. L. (July 1959). \"Some Studies in Machine Learning Using the Game of Checkers\". IBM Journal of Research and Development. 3 (3): 210\u2013229. CiteSeerX 10.1.1.368.2254. doi:10.1147/rd.33.0210.  \"Golden years\" of AI (successful symbolic reasoning programs 1956\u20131973): * McCorduck 2004, pp. 243\u2013252 * Crevier 1993, pp. 52\u2013107 * Moravec 1988, p. 9 * Russell & Norvig 2003, pp. 18\u201321 The programs described are Arthur Samuel's checkers program for the IBM 701, Daniel Bobrow's STUDENT, Newell and Simon's Logic Theorist and Terry Winograd's SHRDLU.  DARPA pours money into undirected pure research into AI during the 1960s: * McCorduck 2004, p. 131 * Crevier 1993, pp. 51, 64\u201365 * NRC 1999, pp. 204\u2013205  AI in England: * Howe 1994  Lighthill 1973.  Expert systems: * ACM 1998, I.2.1 * Russell & Norvig 2003, pp. 22\u201324 * Luger & Stubblefield 2004, pp. 227\u2013331 * Nilsson 1998, chpt. 17.4 * McCorduck 2004, pp. 327\u2013335, 434\u2013435 * Crevier 1993, pp. 145\u201362, 197\u2013203 * Newquist 1994, pp. 155\u2013183  Mead, Carver A.; Ismail, Mohammed (8 May 1989). Analog VLSI Implementation of Neural Systems (PDF). The Kluwer International Series in Engineering and Computer Science. 80. Norwell, MA: Kluwer Academic Publishers. doi:10.1007/978-1-4613-1639-8. ISBN 978-1-4613-1639-8. Archived from the original (PDF) on 6 November 2019. Retrieved 24 January 2020.  Formal methods are now preferred (\"Victory of the neats\"): * Russell & Norvig 2003, pp. 25\u201326 * McCorduck 2004, pp. 486\u2013487  McCorduck 2004, pp. 480\u2013483.  Markoff 2011.  \"Ask the AI experts: What's driving today's progress in AI?\". McKinsey & Company. Archived from the original on 13 April 2018. Retrieved 13 April 2018.  Administrator. \"Kinect's AI breakthrough explained\". i-programmer.info. Archived from the original on 1 February 2016.  Rowinski, Dan (15 January 2013). \"Virtual Personal Assistants & The Future Of Your Smartphone [Infographic]\". ReadWrite. Archived from the original on 22 December 2015.  \"Artificial intelligence: Google's AlphaGo beats Go master Lee Se-dol\". BBC News. 12 March 2016. Archived from the original on 26 August 2016. Retrieved 1 October 2016.  Metz, Cade (27 May 2017). \"After Win in China, AlphaGo's Designers Explore New AI\". Wired. Archived from the original on 2 June 2017.  \"World's Go Player Ratings\". May 2017. Archived from the original on 1 April 2017.  \"\u67ef\u6d01\u8fce19\u5c81\u751f\u65e5 \u96c4\u8e1e\u4eba\u7c7b\u4e16\u754c\u6392\u540d\u7b2c\u4e00\u5df2\u4e24\u5e74\" (in Chinese). May 2017. Archived from the original on 11 August 2017.  Clark, Jack (8 December 2015). \"Why 2015 Was a Breakthrough Year in Artificial Intelligence\". Bloomberg News. Archived from the original on 23 November 2016. Retrieved 23 November 2016. After a half-decade of quiet breakthroughs in artificial intelligence, 2015 has been a landmark year. Computers are smarter and learning faster than ever.  \"Reshaping Business With Artificial Intelligence\". MIT Sloan Management Review. Archived from the original on 19 May 2018. Retrieved 2 May 2018.  Lorica, Ben (18 December 2017). \"The state of AI adoption\". O'Reilly Media. Archived from the original on 2 May 2018. Retrieved 2 May 2018.  Allen, Gregory (6 February 2019). \"Understanding China's AI Strategy\". Center for a New American Security. Archived from the original on 17 March 2019.  \"Review | How two AI superpowers \u2013 the U.S. and China \u2013 battle for supremacy in the field\". Washington Post. 2 November 2018. Archived from the original on 4 November 2018. Retrieved 4 November 2018.  at 10:11, Alistair Dabbs 22 Feb 2019. \"Artificial Intelligence: You know it isn't real, yeah?\". www.theregister.co.uk. Archived from the original on 21 May 2020. Retrieved 22 August 2020.  \"Stop Calling it Artificial Intelligence\". Archived from the original on 2 December 2019. Retrieved 1 December 2019.  \"AI isn't taking over the world \u2013 it doesn't exist yet\". GBG Global website. Archived from the original on 11 August 2020. Retrieved 22 August 2020.  Kaplan, Andreas; Haenlein, Michael (1 January 2019). \"Siri, Siri, in my hand: Who's the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence\". Business Horizons. 62 (1): 15\u201325. doi:10.1016/j.bushor.2018.08.004.  Domingos 2015, Chapter 5.  Domingos 2015, Chapter 7.  Lindenbaum, M., Markovitch, S., & Rusakov, D. (2004). Selective sampling for nearest neighbor classifiers. Machine learning, 54(2), 125\u2013152.  Domingos 2015, Chapter 1.  Intractability and efficiency and the combinatorial explosion: * Russell & Norvig 2003, pp. 9, 21\u201322  Domingos 2015, Chapter 2, Chapter 3.  Hart, P. E.; Nilsson, N. J.; Raphael, B. (1972). \"Correction to \"A Formal Basis for the Heuristic Determination of Minimum Cost Paths\"\". SIGART Newsletter (37): 28\u201329. doi:10.1145/1056777.1056779. S2CID 6386648.  Domingos 2015, Chapter 2, Chapter 4, Chapter 6.  \"Can neural network computers learn from experience, and if so, could they ever become what we would call 'smart'?\". Scientific American. 2018. Archived from the original on 25 March 2018. Retrieved 24 March 2018.  Domingos 2015, Chapter 6, Chapter 7.  Domingos 2015, p. 286.  \"Single pixel change fools AI programs\". BBC News. 3 November 2017. Archived from the original on 22 March 2018. Retrieved 12 March 2018.  \"AI Has a Hallucination Problem That's Proving Tough to Fix\". WIRED. 2018. Archived from the original on 12 March 2018. Retrieved 12 March 2018.  Matti, D.; Ekenel, H. K.; Thiran, J. P. (2017). Combining LiDAR space clustering and convolutional neural networks for pedestrian detection. 2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS). pp. 1\u20136. arXiv:1710.06160. doi:10.1109/AVSS.2017.8078512. ISBN 978-1-5386-2939-0. S2CID 2401976.  Ferguson, Sarah; Luders, Brandon; Grande, Robert C.; How, Jonathan P. (2015). Real-Time Predictive Modeling and Robust Avoidance of Pedestrians with Uncertain, Changing Intentions. Algorithmic Foundations of Robotics XI. Springer Tracts in Advanced Robotics. 107. Springer, Cham. pp. 161\u2013177. arXiv:1405.5581. doi:10.1007/978-3-319-16595-0_10. ISBN 978-3-319-16594-3. S2CID 8681101.  \"Cultivating Common Sense | DiscoverMagazine.com\". Discover Magazine. 2017. Archived from the original on 25 March 2018. Retrieved 24 March 2018.  Davis, Ernest; Marcus, Gary (24 August 2015). \"Commonsense reasoning and commonsense knowledge in artificial intelligence\". Communications of the ACM. 58 (9): 92\u2013103. doi:10.1145/2701413. S2CID 13583137. Archived from the original on 22 August 2020. Retrieved 6 April 2020.  Winograd, Terry (January 1972). \"Understanding natural language\". Cognitive Psychology. 3 (1): 1\u2013191. doi:10.1016/0010-0285(72)90002-3.  \"Don't worry: Autonomous cars aren't coming tomorrow (or next year)\". Autoweek. 2016. Archived from the original on 25 March 2018. Retrieved 24 March 2018.  Knight, Will (2017). \"Boston may be famous for bad drivers, but it's the testing ground for a smarter self-driving car\". MIT Technology Review. Archived from the original on 22 August 2020. Retrieved 27 March 2018.  Prakken, Henry (31 August 2017). \"On the problem of making autonomous vehicles conform to traffic law\". Artificial Intelligence and Law. 25 (3): 341\u2013363. doi:10.1007/s10506-017-9210-0.  Lieto, Antonio (May 2018). \"The knowledge level in cognitive architectures: Current limitations and possible developments\". Cognitive Systems Research. 48: 39\u201355. doi:10.1016/j.cogsys.2017.05.001. hdl:2318/1665207. S2CID 206868967.  Problem solving, puzzle solving, game playing and deduction: * Russell & Norvig 2003, chpt. 3\u20139, * Poole, Mackworth & Goebel 1998, chpt. 2,3,7,9, * Luger & Stubblefield 2004, chpt. 3,4,6,8, * Nilsson 1998, chpt. 7\u201312  Uncertain reasoning: * Russell & Norvig 2003, pp. 452\u2013644, * Poole, Mackworth & Goebel 1998, pp. 345\u2013395, * Luger & Stubblefield 2004, pp. 333\u2013381, * Nilsson 1998, chpt. 19  Psychological evidence of sub-symbolic reasoning: * Wason & Shapiro (1966) showed that people do poorly on completely abstract problems, but if the problem is restated to allow the use of intuitive social intelligence, performance dramatically improves. (See Wason selection task) * Kahneman, Slovic & Tversky (1982) have shown that people are terrible at elementary problems that involve uncertain reasoning. (See list of cognitive biases for several examples). * Lakoff & N\u00fa\u00f1ez (2000) have controversially argued that even our skills at mathematics depend on knowledge and skills that come from \"the body\", i.e. sensorimotor and perceptual skills. (See Where Mathematics Comes From)  Knowledge representation: * ACM 1998, I.2.4, * Russell & Norvig 2003, pp. 320\u2013363, * Poole, Mackworth & Goebel 1998, pp. 23\u201346, 69\u201381, 169\u2013196, 235\u2013277, 281\u2013298, 319\u2013345, * Luger & Stubblefield 2004, pp. 227\u2013243, * Nilsson 1998, chpt. 18  Knowledge engineering: * Russell & Norvig 2003, pp. 260\u2013266, * Poole, Mackworth & Goebel 1998, pp. 199\u2013233, * Nilsson 1998, chpt. \u224817.1\u201317.4  Representing categories and relations: Semantic networks, description logics, inheritance (including frames and scripts): * Russell & Norvig 2003, pp. 349\u2013354, * Poole, Mackworth & Goebel 1998, pp. 174\u2013177, * Luger & Stubblefield 2004, pp. 248\u2013258, * Nilsson 1998, chpt. 18.3  Representing events and time:Situation calculus, event calculus, fluent calculus (including solving the frame problem): * Russell & Norvig 2003, pp. 328\u2013341, * Poole, Mackworth & Goebel 1998, pp. 281\u2013298, * Nilsson 1998, chpt. 18.2  Causal calculus: * Poole, Mackworth & Goebel 1998, pp. 335\u2013337  Representing knowledge about knowledge: Belief calculus, modal logics: * Russell & Norvig 2003, pp. 341\u2013344, * Poole, Mackworth & Goebel 1998, pp. 275\u2013277  Sikos, Leslie F. (June 2017). Description Logics in Multimedia Reasoning. Cham: Springer. doi:10.1007/978-3-319-54066-5. ISBN 978-3-319-54066-5. S2CID 3180114. Archived from the original on 29 August 2017.  Ontology: * Russell & Norvig 2003, pp. 320\u2013328  Smoliar, Stephen W.; Zhang, HongJiang (1994). \"Content based video indexing and retrieval\". IEEE Multimedia. 1 (2): 62\u201372. doi:10.1109/93.311653. S2CID 32710913.  Neumann, Bernd; M\u00f6ller, Ralf (January 2008). \"On scene interpretation with description logics\". Image and Vision Computing. 26 (1): 82\u2013101. doi:10.1016/j.imavis.2007.08.013.  Kuperman, G. J.; Reichley, R. M.; Bailey, T. C. (1 July 2006). \"Using Commercial Knowledge Bases for Clinical Decision Support: Opportunities, Hurdles, and Recommendations\". Journal of the American Medical Informatics Association. 13 (4): 369\u2013371. doi:10.1197/jamia.M2055. PMC 1513681. PMID 16622160.  MCGARRY, KEN (1 December 2005). \"A survey of interestingness measures for knowledge discovery\". The Knowledge Engineering Review. 20 (1): 39\u201361. doi:10.1017/S0269888905000408. S2CID 14987656.  Bertini, M; Del Bimbo, A; Torniai, C (2006). \"Automatic annotation and semantic retrieval of video sequences using multimedia ontologies\". MM '06 Proceedings of the 14th ACM international conference on Multimedia. 14th ACM international conference on Multimedia. Santa Barbara: ACM. pp. 679\u2013682.  Qualification problem: * McCarthy & Hayes 1969 * Russell & Norvig 2003[page needed] While McCarthy was primarily concerned with issues in the logical representation of actions, Russell & Norvig 2003 apply the term to the more general issue of default reasoning in the vast network of assumptions underlying all our commonsense knowledge.  Default reasoning and default logic, non-monotonic logics, circumscription, closed world assumption, abduction (Poole et al. places abduction under \"default reasoning\". Luger et al. places this under \"uncertain reasoning\"): * Russell & Norvig 2003, pp. 354\u2013360, * Poole, Mackworth & Goebel 1998, pp. 248\u2013256, 323\u2013335, * Luger & Stubblefield 2004, pp. 335\u2013363, * Nilsson 1998, ~18.3.3  Breadth of commonsense knowledge: * Russell & Norvig 2003, p. 21, * Crevier 1993, pp. 113\u2013114, * Moravec 1988, p. 13, * Lenat & Guha 1989 (Introduction)  Dreyfus & Dreyfus 1986.  Gladwell 2005.  Expert knowledge as embodied intuition: * Dreyfus & Dreyfus 1986 (Hubert Dreyfus is a philosopher and critic of AI who was among the first to argue that most useful human knowledge was encoded sub-symbolically. See Dreyfus' critique of AI) * Gladwell 2005 (Gladwell's Blink is a popular introduction to sub-symbolic reasoning and knowledge.) * Hawkins & Blakeslee 2005 (Hawkins argues that sub-symbolic knowledge should be the primary focus of AI research.)  Planning: * ACM 1998, ~I.2.8, * Russell & Norvig 2003, pp. 375\u2013459, * Poole, Mackworth & Goebel 1998, pp. 281\u2013316, * Luger & Stubblefield 2004, pp. 314\u2013329, * Nilsson 1998, chpt. 10.1\u20132, 22  Information value theory: * Russell & Norvig 2003, pp. 600\u2013604  Classical planning: * Russell & Norvig 2003, pp. 375\u2013430, * Poole, Mackworth & Goebel 1998, pp. 281\u2013315, * Luger & Stubblefield 2004, pp. 314\u2013329, * Nilsson 1998, chpt. 10.1\u20132, 22  Planning and acting in non-deterministic domains: conditional planning, execution monitoring, replanning and continuous planning: * Russell & Norvig 2003, pp. 430\u2013449  Multi-agent planning and emergent behavior: * Russell & Norvig 2003, pp. 449\u2013455  Turing 1950.  Solomonoff 1956.  Alan Turing discussed the centrality of learning as early as 1950, in his classic paper \"Computing Machinery and Intelligence\".[120] In 1956, at the original Dartmouth AI summer conference, Ray Solomonoff wrote a report on unsupervised probabilistic machine learning: \"An Inductive Inference Machine\".[121]  This is a form of Tom Mitchell's widely quoted definition of machine learning: \"A computer program is set to learn from an experience E with respect to some task T and some performance measure P if its performance on T as measured by P improves with experience E.\"  Learning: * ACM 1998, I.2.6, * Russell & Norvig 2003, pp. 649\u2013788, * Poole, Mackworth & Goebel 1998, pp. 397\u2013438, * Luger & Stubblefield 2004, pp. 385\u2013542, * Nilsson 1998, chpt. 3.3, 10.3, 17.5, 20  Jordan, M. I.; Mitchell, T. M. (16 July 2015). \"Machine learning: Trends, perspectives, and prospects\". Science. 349 (6245): 255\u2013260. Bibcode:2015Sci...349..255J. doi:10.1126/science.aaa8415. PMID 26185243. S2CID 677218.  Reinforcement learning: * Russell & Norvig 2003, pp. 763\u2013788 * Luger & Stubblefield 2004, pp. 442\u2013449  Natural language processing: * ACM 1998, I.2.7 * Russell & Norvig 2003, pp. 790\u2013831 * Poole, Mackworth & Goebel 1998, pp. 91\u2013104 * Luger & Stubblefield 2004, pp. 591\u2013632  \"Versatile question answering systems: seeing in synthesis\" Archived 1 February 2016 at the Wayback Machine, Mittal et al., IJIIDS, 5(2), 119\u2013142, 2011  Applications of natural language processing, including information retrieval (i.e. text mining) and machine translation: * Russell & Norvig 2003, pp. 840\u2013857, * Luger & Stubblefield 2004, pp. 623\u2013630  Cambria, Erik; White, Bebo (May 2014). \"Jumping NLP Curves: A Review of Natural Language Processing Research [Review Article]\". IEEE Computational Intelligence Magazine. 9 (2): 48\u201357. doi:10.1109/MCI.2014.2307227. S2CID 206451986.  Vincent, James (7 November 2019). \"OpenAI has published the text-generating AI it said was too dangerous to share\". The Verge. Archived from the original on 11 June 2020. Retrieved 11 June 2020.  Machine perception: * Russell & Norvig 2003, pp. 537\u2013581, 863\u2013898 * Nilsson 1998, ~chpt. 6  Speech recognition: * ACM 1998, ~I.2.7 * Russell & Norvig 2003, pp. 568\u2013578  Object recognition: * Russell & Norvig 2003, pp. 885\u2013892  Computer vision: * ACM 1998, I.2.10 * Russell & Norvig 2003, pp. 863\u2013898 * Nilsson 1998, chpt. 6  Robotics: * ACM 1998, I.2.9, * Russell & Norvig 2003, pp. 901\u2013942, * Poole, Mackworth & Goebel 1998, pp. 443\u2013460  Moving and configuration space: * Russell & Norvig 2003, pp. 916\u2013932  Tecuci 2012.  Robotic mapping (localization, etc): * Russell & Norvig 2003, pp. 908\u2013915  Cadena, Cesar; Carlone, Luca; Carrillo, Henry; Latif, Yasir; Scaramuzza, Davide; Neira, Jose; Reid, Ian; Leonard, John J. (December 2016). \"Past, Present, and Future of Simultaneous Localization and Mapping: Toward the Robust-Perception Age\". IEEE Transactions on Robotics. 32 (6): 1309\u20131332. arXiv:1606.05830. Bibcode:2016arXiv160605830C. doi:10.1109/TRO.2016.2624754. S2CID 2596787.  Moravec, Hans (1988). Mind Children. Harvard University Press. p. 15.  Chan, Szu Ping (15 November 2015). \"This is what will happen when robots take over the world\". Archived from the original on 24 April 2018. Retrieved 23 April 2018.  \"IKEA furniture and the limits of AI\". The Economist. 2018. Archived from the original on 24 April 2018. Retrieved 24 April 2018.  Kismet.  Thompson, Derek (2018). \"What Jobs Will the Robots Take?\". The Atlantic. Archived from the original on 24 April 2018. Retrieved 24 April 2018.  Scassellati, Brian (2002). \"Theory of mind for a humanoid robot\". Autonomous Robots. 12 (1): 13\u201324. doi:10.1023/A:1013298507114. S2CID 1979315.  Cao, Yongcan; Yu, Wenwu; Ren, Wei; Chen, Guanrong (February 2013). \"An Overview of Recent Progress in the Study of Distributed Multi-Agent Coordination\". IEEE Transactions on Industrial Informatics. 9 (1): 427\u2013438. arXiv:1207.3231. doi:10.1109/TII.2012.2219061. S2CID 9588126.  Thro 1993.  Edelson 1991.  Tao & Tan 2005.  Poria, Soujanya; Cambria, Erik; Bajpai, Rajiv; Hussain, Amir (September 2017). \"A review of affective computing: From unimodal analysis to multimodal fusion\". Information Fusion. 37: 98\u2013125. doi:10.1016/j.inffus.2017.02.003. hdl:1893/25490.  Emotion and affective computing: * Minsky 2006  Waddell, Kaveh (2018). \"Chatbots Have Entered the Uncanny Valley\". The Atlantic. Archived from the original on 24 April 2018. Retrieved 24 April 2018.  Pennachin, C.; Goertzel, B. (2007). Contemporary Approaches to Artificial General Intelligence. Artificial General Intelligence. Cognitive Technologies. Cognitive Technologies. Berlin, Heidelberg: Springer. doi:10.1007/978-3-540-68677-4_1. ISBN 978-3-540-23733-4.  Roberts, Jacob (2016). \"Thinking Machines: The Search for Artificial Intelligence\". Distillations. Vol. 2 no. 2. pp. 14\u201323. Archived from the original on 19 August 2018. Retrieved 20 March 2018.  \"The superhero of artificial intelligence: can this genius keep it in check?\". the Guardian. 16 February 2016. Archived from the original on 23 April 2018. Retrieved 26 April 2018.  Mnih, Volodymyr; Kavukcuoglu, Koray; Silver, David; Rusu, Andrei A.; Veness, Joel; Bellemare, Marc G.; Graves, Alex; Riedmiller, Martin; Fidjeland, Andreas K.; Ostrovski, Georg; Petersen, Stig; Beattie, Charles; Sadik, Amir; Antonoglou, Ioannis; King, Helen; Kumaran, Dharshan; Wierstra, Daan; Legg, Shane; Hassabis, Demis (26 February 2015). \"Human-level control through deep reinforcement learning\". Nature. 518 (7540): 529\u2013533. Bibcode:2015Natur.518..529M. doi:10.1038/nature14236. PMID 25719670. S2CID 205242740.  Sample, Ian (14 March 2017). \"Google's DeepMind makes AI program that can learn like a human\". the Guardian. Archived from the original on 26 April 2018. Retrieved 26 April 2018.  \"From not working to neural networking\". The Economist. 2016. Archived from the original on 31 December 2016. Retrieved 26 April 2018.  Domingos 2015.  Artificial brain arguments: AI requires a simulation of the operation of the human brain * Russell & Norvig 2003, p. 957 * Crevier 1993, pp. 271 and 279 A few of the people who make some form of the argument: * Moravec 1988 * Kurzweil 2005, p. 262 * Hawkins & Blakeslee 2005 The most extreme form of this argument (the brain replacement scenario) was put forward by Clark Glymour in the mid-1970s and was touched on by Zenon Pylyshyn and John Searle in 1980.  Goertzel, Ben; Lian, Ruiting; Arel, Itamar; de Garis, Hugo; Chen, Shuo (December 2010). \"A world survey of artificial brain projects, Part II: Biologically inspired cognitive architectures\". Neurocomputing. 74 (1\u20133): 30\u201349. doi:10.1016/j.neucom.2010.08.012.  Nilsson 1983, p. 10.  Nils Nilsson writes: \"Simply put, there is wide disagreement in the field about what AI is all about.\"[163]  AI's immediate precursors: * McCorduck 2004, pp. 51\u2013107 * Crevier 1993, pp. 27\u201332 * Russell & Norvig 2003, pp. 15, 940 * Moravec 1988, p. 3  Haugeland 1985, pp. 112\u2013117  The most dramatic case of sub-symbolic AI being pushed into the background was the devastating critique of perceptrons by Marvin Minsky and Seymour Papert in 1969. See History of AI, AI winter, or Frank Rosenblatt.  Cognitive simulation, Newell and Simon, AI at CMU (then called Carnegie Tech): * McCorduck 2004, pp. 139\u2013179, 245\u2013250, 322\u2013323 (EPAM) * Crevier 1993, pp. 145\u2013149  Soar (history): * McCorduck 2004, pp. 450\u2013451 * Crevier 1993, pp. 258\u2013263  McCarthy and AI research at SAIL and SRI International: * McCorduck 2004, pp. 251\u2013259 * Crevier 1993  AI research at Edinburgh and in France, birth of Prolog: * Crevier 1993, pp. 193\u2013196 * Howe 1994  AI at MIT under Marvin Minsky in the 1960s : * McCorduck 2004, pp. 259\u2013305 * Crevier 1993, pp. 83\u2013102, 163\u2013176 * Russell & Norvig 2003, p. 19  Cyc: * McCorduck 2004, p. 489, who calls it \"a determinedly scruffy enterprise\" * Crevier 1993, pp. 239\u2013243 * Russell & Norvig 2003, p. 363\u2212365 * Lenat & Guha 1989  Knowledge revolution: * McCorduck 2004, pp. 266\u2013276, 298\u2013300, 314, 421 * Russell & Norvig 2003, pp. 22\u201323  Frederick, Hayes-Roth; William, Murray; Leonard, Adelman. \"Expert systems\". AccessScience. doi:10.1036/1097-8542.248550.  Embodied approaches to AI: * McCorduck 2004, pp. 454\u2013462 * Brooks 1990 * Moravec 1988  Weng et al. 2001.  Lungarella et al. 2003.  Asada et al. 2009.  Oudeyer 2010.  Revival of connectionism: * Crevier 1993, pp. 214\u2013215 * Russell & Norvig 2003, p. 25  Computational intelligence * IEEE Computational Intelligence Society Archived 9 May 2008 at the Wayback Machine  Hutson, Matthew (16 February 2018). \"Artificial intelligence faces reproducibility crisis\". Science. pp. 725\u2013726. Bibcode:2018Sci...359..725H. doi:10.1126/science.359.6377.725. Archived from the original on 29 April 2018. Retrieved 28 April 2018.  Norvig 2012.  Langley 2011.  Katz 2012.  The intelligent agent paradigm: * Russell & Norvig 2003, pp. 27, 32\u201358, 968\u2013972 * Poole, Mackworth & Goebel 1998, pp. 7\u201321 * Luger & Stubblefield 2004, pp. 235\u2013240 * Hutter 2005, pp. 125\u2013126 The definition used in this article, in terms of goals, actions, perception and environment, is due to Russell & Norvig (2003). Other definitions also include knowledge and learning as additional criteria.  Agent architectures, hybrid intelligent systems: * Russell & Norvig (2003, pp. 27, 932, 970\u2013972) * Nilsson (1998, chpt. 25)  Hierarchical control system: * Albus 2002  Lieto, Antonio; Lebiere, Christian; Oltramari, Alessandro (May 2018). \"The knowledge level in cognitive architectures: Current limitations and possibile developments\". Cognitive Systems Research. 48: 39\u201355. doi:10.1016/j.cogsys.2017.05.001. hdl:2318/1665207. S2CID 206868967.  Lieto, Antonio; Bhatt, Mehul; Oltramari, Alessandro; Vernon, David (May 2018). \"The role of cognitive architectures in general artificial intelligence\". Cognitive Systems Research. 48: 1\u20133. doi:10.1016/j.cogsys.2017.08.003. hdl:2318/1665249. S2CID 36189683.  Russell & Norvig 2009, p. 1.  White Paper: On Artificial Intelligence - A European approach to excellence and trust (PDF). Brussels: European Commission. 2020. p. 1. Archived (PDF) from the original on 20 February 2020. Retrieved 20 February 2020.  CNN 2006.  Using AI to predict flight delays Archived 20 November 2018 at the Wayback Machine, Ishti.org.  N. Aletras; D. Tsarapatsanis; D. Preotiuc-Pietro; V. Lampos (2016). \"Predicting judicial decisions of the European Court of Human Rights: a Natural Language Processing perspective\". PeerJ Computer Science. 2: e93. doi:10.7717/peerj-cs.93.  \"The Economist Explains: Why firms are piling into artificial intelligence\". The Economist. 31 March 2016. Archived from the original on 8 May 2016. Retrieved 19 May 2016.  Lohr, Steve (28 February 2016). \"The Promise of Artificial Intelligence Unfolds in Small Steps\". The New York Times. Archived from the original on 29 February 2016. Retrieved 29 February 2016.  Frangoul, Anmar (14 June 2019). \"A Californian business is using A.I. to change the way we think about energy storage\". CNBC. Archived from the original on 25 July 2020. Retrieved 5 November 2019.  Wakefield, Jane (15 June 2016). \"Social media 'outstrips TV' as news source for young people\". BBC News. Archived from the original on 24 June 2016.  Smith, Mark (22 July 2016). \"So you think you chose to read this article?\". BBC News. Archived from the original on 25 July 2016.  Brown, Eileen. \"Half of Americans do not believe deepfake news could target them online\". ZDNet. Archived from the original on 6 November 2019. Retrieved 3 December 2019.  The Turing test: Turing's original publication: * Turing 1950 Historical influence and philosophical implications: * Haugeland 1985, pp. 6\u20139 * Crevier 1993, p. 24 * McCorduck 2004, pp. 70\u201371 * Russell & Norvig 2003, pp. 2\u20133 and 948  Dartmouth proposal: * McCarthy et al. 1955 (the original proposal) * Crevier 1993, p. 49 (historical significance)  The physical symbol systems hypothesis: * Newell & Simon 1976, p. 116 * McCorduck 2004, p. 153 * Russell & Norvig 2003, p. 18  Dreyfus 1992, p. 156.  Dreyfus criticized the necessary condition of the physical symbol system hypothesis, which he called the \"psychological assumption\": \"The mind can be viewed as a device operating on bits of information according to formal rules.\"[206]  Dreyfus' critique of artificial intelligence: * Dreyfus 1972, Dreyfus & Dreyfus 1986 * Crevier 1993, pp. 120\u2013132 * McCorduck 2004, pp. 211\u2013239 * Russell & Norvig 2003, pp. 950\u2013952,  G\u00f6del 1951: in this lecture, Kurt G\u00f6del uses the incompleteness theorem to arrive at the following disjunction: (a) the human mind is not a consistent finite machine, or (b) there exist Diophantine equations for which it cannot decide whether solutions exist. G\u00f6del finds (b) implausible, and thus seems to have believed the human mind was not equivalent to a finite machine, i.e., its power exceeded that of any finite machine. He recognized that this was only a conjecture, since one could never disprove (b). Yet he considered the disjunctive conclusion to be a \"certain fact\".  The Mathematical Objection: * Russell & Norvig 2003, p. 949 * McCorduck 2004, pp. 448\u2013449 Making the Mathematical Objection: * Lucas 1961 * Penrose 1989 Refuting Mathematical Objection: * Turing 1950 under \"(2) The Mathematical Objection\" * Hofstadter 1979 Background: * G\u00f6del 1931, Church 1936, Kleene 1935, Turing 1937  Graham Oppy (20 January 2015). \"G\u00f6del's Incompleteness Theorems\". Stanford Encyclopedia of Philosophy. Archived from the original on 22 April 2016. Retrieved 27 April 2016. These G\u00f6delian anti-mechanist arguments are, however, problematic, and there is wide consensus that they fail.  Stuart J. Russell; Peter Norvig (2010). \"26.1.2: Philosophical Foundations/Weak AI: Can Machines Act Intelligently?/The mathematical objection\". Artificial Intelligence: A Modern Approach (3rd ed.). Upper Saddle River, NJ: Prentice Hall. ISBN 978-0-13-604259-4. even if we grant that computers have limitations on what they can prove, there is no evidence that humans are immune from those limitations.  Mark Colyvan. An introduction to the philosophy of mathematics. Cambridge University Press, 2012. From 2.2.2, 'Philosophical significance of G\u00f6del's incompleteness results': \"The accepted wisdom (with which I concur) is that the Lucas-Penrose arguments fail.\"  Iphofen, Ron; Kritikos, Mihalis (3 January 2019). \"Regulating artificial intelligence and robotics: ethics by design in a digital society\". Contemporary Social Science: 1\u201315. doi:10.1080/21582041.2018.1563803. ISSN 2158-2041.  \"Ethical AI Learns Human Rights Framework\". Voice of America. Archived from the original on 11 November 2019. Retrieved 10 November 2019.  Crevier 1993, pp. 132\u2013144.  In the early 1970s, Kenneth Colby presented a version of Weizenbaum's ELIZA known as DOCTOR which he promoted as a serious therapeutic tool.[216]  Joseph Weizenbaum's critique of AI: * Weizenbaum 1976 * Crevier 1993, pp. 132\u2013144 * McCorduck 2004, pp. 356\u2013373 * Russell & Norvig 2003, p. 961 Weizenbaum (the AI researcher who developed the first chatterbot program, ELIZA) argued in 1976 that the misuse of artificial intelligence has the potential to devalue human life.  Wendell Wallach (2010). Moral Machines, Oxford University Press.  Wallach, pp 37\u201354.  Wallach, pp 55\u201373.  Wallach, Introduction chapter.  Michael Anderson and Susan Leigh Anderson (2011), Machine Ethics, Cambridge University Press.  \"Machine Ethics\". aaai.org. Archived from the original on 29 November 2014.  Rubin, Charles (Spring 2003). \"Artificial Intelligence and Human Nature\". The New Atlantis. 1: 88\u2013100. Archived from the original on 11 June 2012.  Brooks, Rodney (10 November 2014). \"artificial intelligence is a tool, not a threat\". Archived from the original on 12 November 2014.  \"Stephen Hawking, Elon Musk, and Bill Gates Warn About Artificial Intelligence\". Observer. 19 August 2015. Archived from the original on 30 October 2015. Retrieved 30 October 2015.  Chalmers, David (1995). \"Facing up to the problem of consciousness\". Journal of Consciousness Studies. 2 (3): 200\u2013219. Archived from the original on 8 March 2005. Retrieved 11 October 2018. See also this link Archived 8 April 2011 at the Wayback Machine  Horst, Steven, (2005) \"The Computational Theory of Mind\" Archived 11 September 2018 at the Wayback Machine in The Stanford Encyclopedia of Philosophy  Searle 1980, p. 1.  This version is from Searle (1999), and is also quoted in Dennett 1991, p. 435. Searle's original formulation was \"The appropriately programmed computer really is a mind, in the sense that computers given the right programs can be literally said to understand and have other cognitive states.\" [230] Strong AI is defined similarly by Russell & Norvig (2003, p. 947): \"The assertion that machines could possibly act intelligently ",
        "languages": {}
    },
    {
        "name": "nmrML",
        "description": "nmrML is an open mark-up language for NMR data. This is the official repository for development of the nmrML schema and NMR ontology.",
        "languages": {
            "HTML": 3617771,
            "R": 809648,
            "Python": 484495,
            "Java": 468042,
            "XSLT": 366045,
            "MATLAB": 61267,
            "JavaScript": 50906,
            "CSS": 11977,
            "Makefile": 11510,
            "Batchfile": 2345,
            "Shell": 476
        }
    },
    {
        "name": "Gellish",
        "description": "Development of the Gellish Communicator reference application and tools for universal data exchange and data integration supporting Formal English and other Gellish formalized natural languages.",
        "languages": {
            "Python": 614947
        }
    },
    {
        "name": "Archived-SANSA-OWL",
        "description": "SANSA Stack OWL (Web Ontology Language) API",
        "languages": {
            "Scala": 541596
        }
    },
    {
        "name": "txt2onto",
        "description": "Code for classifying unstructured text to tissue ontology terms using natural language processing and machine learning.",
        "languages": {
            "Python": 21870,
            "Shell": 630,
            "Dockerfile": 225
        }
    },
    {
        "name": "AI",
        "description": "Several projects for the Artificial Intelligence course, with topics such as Recommender and Rule-based Systems, Ontologies and Natural Language Processing.",
        "languages": {
            "CLIPS": 19470,
            "Prolog": 11109
        }
    },
    {
        "name": "oml",
        "description": "Ontological Modeling Language (OML)",
        "languages": {
            "Java": 2899258,
            "HTML": 774757,
            "Bikeshed": 2555,
            "Shell": 2408,
            "Python": 1949
        }
    },
    {
        "name": "owldotnetapi",
        "description": "The OwlDotNetApi is an OWL (Web Ontology Language) API and parser written in C# for the .NET platform based on the Drive RDF parser.",
        "languages": {
            "HTML": 1616943,
            "C#": 281675,
            "CSS": 8926,
            "JavaScript": 5435
        }
    },
    {
        "name": "NLP-demo-2017",
        "description": "Semantic natural language understanding at scale using Spark, machine-learned annotators and deep-learned ontologies",
        "languages": {
            "Jupyter Notebook": 2411624
        }
    },
    {
        "name": "HPO-translations",
        "description": "Internationalisation of the HPO content",
        "languages": {}
    },
    {
        "name": "OntoUML",
        "description": "The OntoUML Language Documentation.",
        "languages": {
            "Python": 9915,
            "Batchfile": 789,
            "Makefile": 618
        }
    },
    {
        "name": "UnityVGDL",
        "description": "A Video Game Description Language (VGDL) Implementation in Unity of the GVGAI VGDL ontology (https://github.com/GAIGResearch/GVGAI)",
        "languages": {
            "C#": 597819
        }
    },
    {
        "name": "olia",
        "description": "Ontologies of Linguistic Annotation. Machine-readable tagsets and annotation schemata for more than 100 languages. ",
        "languages": {
            "HTML": 9702610,
            "Java": 3672848,
            "JavaScript": 174572,
            "XSLT": 121766,
            "CSS": 63668,
            "Shell": 45847,
            "Python": 34579,
            "Makefile": 8604
        }
    },
    {
        "name": "Arthur",
        "description": "Semantic language-agnostic source code schema",
        "languages": {
            "Groovy": 332630,
            "Java": 22044,
            "C#": 5356,
            "C++": 4274,
            "JavaScript": 2911,
            "Go": 2682,
            "PHP": 2088,
            "Shell": 1889,
            "Python": 1871,
            "Ruby": 1738
        }
    },
    {
        "name": "simphony-osp",
        "description": "A framework that aims to achieve interoperability between software such as simulation engines, databases and data repositories using a knowledge graph as the common language.",
        "languages": {
            "Python": 917345,
            "Dockerfile": 573
        }
    },
    {
        "name": "OWL-API-for-iOS",
        "description": "A native iOS library for working with Web Ontology Language (OWL) ontologies",
        "languages": {
            "Objective-C": 193406,
            "Shell": 4376,
            "C++": 161
        }
    },
    {
        "name": "data-logic",
        "description": "Expert system with deductive querying and verification of constraints expressed in natural language",
        "languages": {
            "Prolog": 7238
        }
    },
    {
        "name": "machine-learning-ontology-matching",
        "description": "Applying of Machine Learning Techniques to Combine String-based, Language-based and Structure-based Similarity Measures for Ontology Matching",
        "languages": {
            "Jupyter Notebook": 1198638,
            "Python": 19728
        }
    },
    {
        "name": "cycr",
        "description": "This library allows for accessing the Cyc ontology from Ruby language.",
        "languages": {
            "Ruby": 47486
        }
    },
    {
        "name": "gov.nasa.jpl.imce.oml",
        "description": "Ontology Modeling Language (OML) Workbench",
        "languages": {
            "Java": 11491377,
            "Xtend": 1087918,
            "GAP": 927514,
            "HTML": 624737,
            "TSQL": 23325,
            "Shell": 10476
        }
    },
    {
        "name": "py-horned-owl",
        "description": "A library for Web Ontology Language in Python created using a bridge from horned-owl to python using PyO3. ",
        "languages": {
            "Rust": 95949,
            "Python": 37474,
            "Jupyter Notebook": 20604
        }
    },
    {
        "name": "OntoMermaid",
        "description": "A RDF-based vocabulary to express OWL ontologies into Mermaid diagram language",
        "languages": {
            "HTML": 83320,
            "Python": 9967
        }
    },
    {
        "name": "Narwhal",
        "description": "Narwhal is a keyword and KEY NARRATIVE manager that creates language-aware classes. Because Narhwal does not use NLP it avoids complexity.",
        "languages": {
            "Python": 392609,
            "C++": 135014,
            "HTML": 55841,
            "Batchfile": 163
        }
    },
    {
        "name": "robot_semantics",
        "description": "Implementation for Paper \"Understanding Contexts Inside Joint Robot and Human Manipulation Tasks through Vision-Language Model with Ontology Constraints in a Video Streamline\"",
        "languages": {
            "Jupyter Notebook": 124206,
            "Python": 91242
        }
    },
    {
        "name": "OWLOOP",
        "description": "An Object Oriented Programming (OOP) interface for Ontology Web language (OWL) ontologies.",
        "languages": {
            "Java": 764831
        }
    },
    {
        "name": "Ontology-for-Nutritional-Studies",
        "description": "The Ontology for Nutritional Studies (ONS) has been developed as part of the ENPADASI European project (http://www.enpadasi.eu/) with the aim to define a common language and building ontologies for nutritional studies.",
        "languages": {}
    },
    {
        "name": "matoll",
        "description": " M-ATOLL: A Framework for the Lexicalization of Ontologies in Multiple Languages",
        "languages": {
            "JavaScript": 7193403,
            "Web Ontology Language": 2374759,
            "Java": 585305,
            "Python": 5068,
            "Shell": 925,
            "Ruby": 887
        }
    },
    {
        "name": "artifact-generator",
        "description": "Tool for generating and publishing programming-language-specific libraries (i.e., artifacts) that bundle together source-code classes to represent individual RDF vocabularies, where each class contains constants for all of the RDF terms (i.e., the RDF Classes and Properties) defined in each of those vocabularies.",
        "languages": {
            "JavaScript": 514881,
            "Handlebars": 118694,
            "Java": 9090
        }
    },
    {
        "name": "vectology",
        "description": "Using language models and ontology topology to perform semantic mapping of traits between biomedical datasets",
        "languages": {
            "Jupyter Notebook": 3624882,
            "Python": 279679,
            "Makefile": 8650,
            "Dockerfile": 308,
            "Shell": 240
        }
    },
    {
        "name": "babelon",
        "description": "A format for language profiles for ontologies",
        "languages": {
            "Python": 87077,
            "Jupyter Notebook": 14013,
            "Makefile": 3680,
            "Shell": 154
        }
    },
    {
        "name": "aceview",
        "description": "ACE View is a natural language based ontology and rule editor. ACE View uses Attempto Controlled English (ACE) in the front-end, and Web Ontology Language (OWL) and Semantic Web Rule Language (SWRL) in the back-end. ACE View has been implemented as a plug-in for Prot\u00e9g\u00e9 4",
        "languages": {
            "Java": 550668,
            "HTML": 58298,
            "XSLT": 4166,
            "JavaScript": 2434,
            "Shell": 2249
        }
    },
    {
        "name": "SecureReqNet",
        "description": "We present a novel approach, called SecureReqNet, for automatically identifying whether issues in bug or issue tracking systems describe security related content that should be given careful attention. Our approach consists of a two-phase deep learning architecture that operates purely on the natural language descriptions of issues. The first phase of our approach learns high dimensional sentence embeddings from hundreds of thousands of descriptions extracted from software vulnerabilities listed in the CVE database and issue descriptions extracted from open source projects using an unsupervised learning process. The second phase then utilizes this semantic ontology of embeddings to train a deep convolutional neural network capable of predicting whether a given issue contains security- related information.",
        "languages": {
            "Jupyter Notebook": 13629012,
            "Python": 87875,
            "Shell": 812,
            "Makefile": 465,
            "Dockerfile": 186
        }
    },
    {
        "name": "AutoRDF",
        "description": "A framework for C++ proxy class generation from Web Ontology Language",
        "languages": {
            "C++": 2426727,
            "Python": 264618,
            "Smarty": 45751,
            "CMake": 37002,
            "M4": 19093,
            "Shell": 16795,
            "Makefile": 14294,
            "Meson": 7741,
            "C": 6882
        }
    },
    {
        "name": "OPPL2",
        "description": "OPPL 2 is the second version of OPPL (Ontology PreProcessing Language). It is a language intended for modification of OWL ontologies, implemented in Java.",
        "languages": {
            "Java": 9067464,
            "GAP": 170585,
            "Smalltalk": 550,
            "HTML": 296,
            "Awk": 258
        }
    },
    {
        "name": "InformationSecurityOntology",
        "description": "Ontology of the area of \u200b\u200bInformation Security, formalized in the OWL language",
        "languages": {}
    },
    {
        "name": "uml-sp",
        "description": "UML2 SP is an object-oriented simulation language ",
        "languages": {}
    },
    {
        "name": "DOL",
        "description": "The Distributed Ontology, Modeling and Specification Language (DOL) - an answer to the OMG RFP OntoIOp. * View the latest version here: https://github.com/tillmo/DOL/raw/master/Standard/dol.pdf. * Convenience version with diff to version of August 24: https://github.com/tillmo/DOL/raw/master/Standard/dol-diff.pdf * Homepage of OntoIOp is",
        "languages": {
            "TeX": 19658392,
            "HTML": 273350,
            "Haskell": 7256,
            "Python": 4516,
            "Shell": 212
        }
    },
    {
        "name": "language-ontology",
        "description": "Development work -- an OBO, BFO language ontology based on ISO-639-3",
        "languages": {
            "Vue": 170704,
            "Makefile": 10918,
            "Python": 5721,
            "Shell": 642,
            "Batchfile": 85,
            "Dockerfile": 33
        }
    },
    {
        "name": "ottr-masterclass",
        "description": "Tutorial and talk about the Reasonable Ontology Language at the Knowledge Graph Conference 2022.",
        "languages": {}
    },
    {
        "name": "Monetary-Ontology-Walkabout",
        "description": "This is my collection of examples and tools for following my exploration of how to work with Web Ontology Language",
        "languages": {
            "Java": 112431,
            "Shell": 14643,
            "Groovy": 6882
        }
    },
    {
        "name": "hindi-nlp",
        "description": "A project - developing an ontology for Hindi language",
        "languages": {
            "Python": 2503
        }
    },
    {
        "name": "NLPMethods2CompareGOterms",
        "description": "Natural language processing methods to compare 2 Gene Ontology terms",
        "languages": {
            "Python": 106766,
            "Perl": 4200,
            "R": 3203
        }
    },
    {
        "name": "pml",
        "description": "The Provenance Markup Language (PML 3.0) is an OWL ontology that extends W3C's PROV-O with the best parts of PML 2.0.",
        "languages": {
            "Shell": 607
        }
    },
    {
        "name": "opendigitaltwins-airport",
        "description": "WillowTwin open digital twin definition language (DTDL) ontology for airports",
        "languages": {
            "C#": 2021
        }
    },
    {
        "name": "ELDER",
        "description": "Endangered Language Data Electronic Repository: A web-based ontologically-compliant collaborative linguistic data cataloguing tool.",
        "languages": {
            "PHP": 275813
        }
    },
    {
        "name": "language-owl2",
        "description": "A Haskell parser and pretty printer for various dialects of the OWL 2 Web Ontology Language",
        "languages": {
            "Haskell": 156032,
            "Nix": 2049,
            "Shell": 878
        }
    },
    {
        "name": "CLaRO",
        "description": "Competency question Language for specifying Requirements for an Ontology",
        "languages": {
            "Java": 51657
        }
    },
    {
        "name": "Ontology-Reasoning",
        "description": "The W3C recommended data model of RDF and its extension to the Web Ontology Language (OWL) help capture the semantics or the meaning of the data.  Learnt how to use this data model for representation and reasoning by creating a Jena Model for RDF and later using Protege created an ontology by adding classes and properties.",
        "languages": {
            "Java": 5921
        }
    },
    {
        "name": "dmn-ont",
        "description": "A Web Ontology Language (OWL) ontology version of the Decision Modelling Notation 1.1 standard's schema",
        "languages": {
            "HTML": 148883,
            "Python": 3845
        }
    },
    {
        "name": "Flight-Operation-Ontology-Simulation-using-RDF-JenaAPI",
        "description": "A semantic web application demonstrating the use of OWL (web ontology language), Apache JENA API and Resource Description Framework (RDF) dataset of Flight operations at a Los Angeles International Airport (LAX).",
        "languages": {
            "Web Ontology Language": 2701544,
            "Java": 4722
        }
    },
    {
        "name": "fastobo-owl",
        "description": "OWL language mapping for ontologies in the OBO flat file format 1.4",
        "languages": {
            "Rust": 87147
        }
    },
    {
        "name": "semantic-knowledge-management-ontology-for-online-library",
        "description": "A semantic web application for an online library management system. Queries are made in SPARQL language and data is stored in RDF format. Apart from the Client role, there is also the Admin role that has access to the admin panel for adding, editing and deleting books.",
        "languages": {
            "Java": 263156,
            "CSS": 105450,
            "JavaScript": 14734
        }
    },
    {
        "name": "Text-Classification-DBpedia-ontology-classes-Using-LSTM",
        "description": "Text classification is the task of assigning a set of predefined categories to free text. Text classifiers can be used to organize, structure, and categorize pretty much anything. For example, new articles can be organized by topics, support tickets can be organized by urgency, chat conversations can be organized by language, brand mentions can be organized by sentiment, and so on.",
        "languages": {
            "Python": 32790,
            "HTML": 6778
        }
    },
    {
        "name": "SWEXSYS",
        "description": "The Semantic Web Expert System Shell -  An intelligent system platform capable of reasoning from multiple ontologies using Resource Description Framework (RDF), Rule Markup Language (RuleML), as well as other knowledge expressed as functional, structural, or causal models.",
        "languages": {
            "Web Ontology Language": 347717,
            "Prolog": 260978
        }
    },
    {
        "name": "AI_ConceptNet5",
        "description": "The project is to develop an AI program that can conduct commonsense reasoning based on a commonsense ontology ConceptNet. It consists of two basic functions of interacting with a commonsense ontology: 1. A simple natural language sentence generation given initial concepts and 2. A common sense question answering system.",
        "languages": {
            "Java": 105011
        }
    },
    {
        "name": "Sociopedia-Twitter-Knowledge-Engine",
        "description": "Building a search engine to discovery web services specified using a natural language query that infers relationships using an ontology of Twitter data. Technologies used are NLTK, Python, Whoosh, Django and CMU Ark Tweet Parser. The fast information sharing on Twitter from millions of users all over the world leads to almost real-time reporting of events. It is extremely important for business and administrative decision makers to learn events popularity as quickly as possible, as it can buy extra precious time for them to make informed decisions. Therefore, we introduce the problem of predicting future popularity trend of events on microblogging platforms. Traditionally, trend prediction has been performed by using time series analysis of past popularity to forecast the future popularity changes.",
        "languages": {
            "HTML": 405770,
            "JavaScript": 288546,
            "CSS": 68974,
            "Python": 37110,
            "Shell": 170
        }
    },
    {
        "name": "WebOntologyLanguage",
        "description": "\u0411\u0430\u0437\u043e\u0432\u044b\u0435 \u043f\u043e\u043d\u044f\u0442\u0438\u044f \u043e\u043d\u0442\u043e\u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u043f\u043e\u0434\u0445\u043e\u0434\u0430 \u0438 \u0438\u043d\u0441\u0442\u0440\u0443\u043c\u0435\u043d\u0442\u0430\u043b\u044c\u043d\u044b\u0435 \u0441\u0440\u0435\u0434\u0441\u0442\u0432\u0430 \u043e\u043d\u0442\u043e\u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f, \u043d\u0430\u0432\u044b\u043a\u0438 \u0440\u0430\u0431\u043e\u0442\u044b \u0441 \u0440\u0435\u0434\u0430\u043a\u0442\u043e\u0440\u043e\u043c \u043e\u043d\u0442\u043e\u043b\u043e\u0433\u0438\u0439 Owlready2.",
        "languages": {
            "Python": 11754
        }
    },
    {
        "name": "Ontomaker-Web",
        "description": "Web shell for presentation and analysis of Ontologies based on Controlled Natural Language",
        "languages": {
            "JavaScript": 333617,
            "HTML": 26272,
            "Java": 16741,
            "CSS": 5400
        }
    },
    {
        "name": "gov.nasa.jpl.imce.oml.doc",
        "description": "The documentation about the Ontological Modeling Language specification",
        "languages": {}
    },
    {
        "name": "py4owl",
        "description": "Advanced  Web Ontology Language (OWL) support in python",
        "languages": {
            "Python": 21223,
            "Makefile": 3038,
            "Dockerfile": 1620
        }
    },
    {
        "name": "opendigitaltwins-rail",
        "description": "WillowTwin open digital twin definition language (DTDL) ontology for rail",
        "languages": {}
    },
    {
        "name": "University-Expret-System-",
        "description": "\u25cf This project introduce an expert university system  and the different relations between its parts represented as facts and rules in clips and hierarchy ontology in prot\u00e9g\u00e9. It also discusses how to infer on it using rule based system \u201cclips\u201d  and SparQl query language.",
        "languages": {
            "CLIPS": 8900,
            "Java": 6849
        }
    },
    {
        "name": "Knowledge_Base_Represented_by_Semantic_Web_Language",
        "description": "Semantic Web languages OWL and RDF for knowledge representation of Alarm-Warning system for mobile robot showing the states for each sensor",
        "languages": {}
    },
    {
        "name": "parrot",
        "description": "Parrot is A RIF and RDF Ontologies documentation Tool. It provides users (both business users and developers) with useful reference documentation about rulesets and ontologies expressed in standard languages, such as OWL and RIF.",
        "languages": {
            "Java": 556972,
            "HTML": 177681,
            "JavaScript": 109275,
            "CSS": 23412,
            "XSLT": 7167,
            "Python": 927
        }
    },
    {
        "name": "OntoVerbal",
        "description": "OntoVerbal is a Protege 4.2 plugin that generates natural language descriptions for classes for an ontology written in OWL ",
        "languages": {
            "Java": 33535
        }
    },
    {
        "name": "rdfex",
        "description": "A language and mapping engine to transfer an OWL ontologies / RDF information models into data interchange formats (e.g. XML, JSON)",
        "languages": {
            "Java": 55680
        }
    },
    {
        "name": "Astronautics-Terminology",
        "description": "A cataloging and examination of terms and definitions in astronautics (spaceflight). This is a task in the Astonautical Knowledge Modeling project, and related ontology projects by Robert Rovetto.",
        "languages": {}
    },
    {
        "name": "RobotML",
        "description": "RobotML stands for Robot Modelling language. It is semi-graphic language created in order to allow robotician to think of their problems without immediately thinking on what actual environment and robots they will work with. It has been implemented in a platform based upon eclipse (http://www.eclipse.org) and papyrus. This language has been defined through redaction of an ontology that is available though this website.",
        "languages": {
            "Web Ontology Language": 1530378,
            "HTML": 52979
        }
    },
    {
        "name": "lesniewski-mereology",
        "description": "LesniewskiMereology is a Coq library created by R. Dapoigny and P. Barlatier whose purpose is to implement the alternative to Set Theory of Stanislaw Lesniewski. It is part of an on-going project using the Coq language and called KDTL (Knowledge-based Dependently Typed Language) to build an alternative to Description Logics. The developed theory is close to the analysis of Denis Mieville (1984) in his book \"Un developpement des systemes logiques de Stanislaw Lesniewski\". It is a theoretical construct which relies on three dependent levels, logic (a.k.a. Protothetic), the Lesniewski Ontologie (LO) and mereology. Each level incorporates a minimal collection of axioms, protothetic and ontologic definitions and a set of theorems together with their intuitionist proofs.",
        "languages": {
            "Coq": 101475,
            "Makefile": 253
        }
    },
    {
        "name": "History",
        "description": "The earliest work in computerized knowledge representation was focused on general problem solvers such as the General Problem Solver (GPS) system developed by Allen Newell and Herbert A. Simon in 1959. These systems featured data structures for planning and decomposition. The system would begin with a goal. It would then decompose that goal into sub-goals and then set out to construct strategies that could accomplish each subgoal.  In these early days of AI, general search algorithms such as A* were also developed. However, the amorphous problem definitions for systems such as GPS meant that they worked only for very constrained toy domains (e.g. the \"blocks world\"). In order to tackle non-toy problems, AI researchers such as Ed Feigenbaum and Frederick Hayes-Roth realized that it was necessary to focus systems on more constrained problems.  These efforts led to the cognitive revolution in psychology and to the phase of AI focused on knowledge representation that resulted in expert systems in the 1970s and 80s, production systems, frame languages, etc. Rather than general problem solvers, AI changed its focus to expert systems that could match human competence on a specific task, such as medical diagnosis.  Expert systems gave us the terminology still in use today where AI systems are divided into a Knowledge Base with facts about the world and rules and an inference engine that applies the rules to the knowledge base in order to answer questions and solve problems. In these early systems the knowledge base tended to be a fairly flat structure, essentially assertions about the values of variables used by the rules.[2]  In addition to expert systems, other researchers developed the concept of frame-based languages in the mid-1980s. A frame is similar to an object class: It is an abstract description of a category describing things in the world, problems, and potential solutions. Frames were originally used on systems geared toward human interaction, e.g. understanding natural language and the social settings in which various default expectations such as ordering food in a restaurant narrow the search space and allow the system to choose appropriate responses to dynamic situations.  It was not long before the frame communities and the rule-based researchers realized that there was synergy between their approaches. Frames were good for representing the real world, described as classes, subclasses, slots (data values) with various constraints on possible values. Rules were good for representing and utilizing complex logic such as the process to make a medical diagnosis. Integrated systems were developed that combined Frames and Rules. One of the most powerful and well known was the 1983 Knowledge Engineering Environment (KEE) from Intellicorp. KEE had a complete rule engine with forward and backward chaining. It also had a complete frame based knowledge base with triggers, slots (data values), inheritance, and message passing. Although message passing originated in the object-oriented community rather than AI it was quickly embraced by AI researchers as well in environments such as KEE and in the operating systems for Lisp machines from Symbolics, Xerox, and Texas Instruments.[3]  The integration of Frames, rules, and object-oriented programming was significantly driven by commercial ventures such as KEE and Symbolics spun off from various research projects. At the same time as this was occurring, there was another strain of research that was less commercially focused and was driven by mathematical logic and automated theorem proving. One of the most influential languages in this research was the KL-ONE language of the mid-'80s. KL-ONE was a frame language that had a rigorous semantics, formal definitions for concepts such as an Is-A relation.[4] KL-ONE and languages that were influenced by it such as Loom had an automated reasoning engine that was based on formal logic rather than on IF-THEN rules. This reasoner is called the classifier. A classifier can analyze a set of declarations and infer new assertions, for example, redefine a class to be a subclass or superclass of some other class that wasn't formally specified. In this way the classifier can function as an inference engine, deducing new facts from an existing knowledge base. The classifier can also provide consistency checking on a knowledge base (which in the case of KL-ONE languages is also referred to as an Ontology).[5]  Another area of knowledge representation research was the problem of common sense reasoning. One of the first realizations learned from trying to make software that can function with human natural language was that humans regularly draw on an extensive foundation of knowledge about the real world that we simply take for granted but that is not at all obvious to an artificial agent. Basic principles of common sense physics, causality, intentions, etc. An example is the frame problem, that in an event driven logic there need to be axioms that state things maintain position from one moment to the next unless they are moved by some external force. In order to make a true artificial intelligence agent that can converse with humans using natural language and can process basic statements and questions about the world, it is essential to represent this kind of knowledge. One of the most ambitious programs to tackle this problem was Doug Lenat's Cyc project. Cyc established its own Frame language and had large numbers of analysts document various areas of common sense reasoning in that language. The knowledge recorded in Cyc included common sense models of time, causality, physics, intentions, and many others.[6]  The starting point for knowledge representation is the knowledge representation hypothesis first formalized by Brian C. Smith in 1985:[7]  Any mechanically embodied intelligent process will be comprised of structural ingredients that a) we as external observers naturally take to represent a propositional account of the knowledge that the overall process exhibits, and b) independent of such external semantic attribution, play a formal but causal and essential role in engendering the behavior that manifests that knowledge.  Currently one of the most active areas of knowledge representation research are projects associated with the Semantic Web. The Semantic Web seeks to add a layer of semantics (meaning) on top of the current Internet. Rather than indexing web sites and pages via keywords, the Semantic Web creates large ontologies of concepts. Searching for a concept will be more effective than traditional text only searches. Frame languages and automatic classification play a big part in the vision for the future Semantic Web. The automatic classification gives developers technology to provide order on a constantly evolving network of knowledge. Defining ontologies that are static and incapable of evolving on the fly would be very limiting for Internet-based systems. The classifier technology provides the ability to deal with the dynamic environment of the Internet.  Recent projects funded primarily by the Defense Advanced Research Projects Agency (DARPA) have integrated frame languages and classifiers with markup languages based on XML. The Resource Description Framework (RDF) provides the basic capability to define classes, subclasses, and properties of objects. The Web Ontology Language (OWL) provides additional levels of semantics and enables integration with classification engines.[8][9]",
        "languages": {}
    },
    {
        "name": "container-ontology",
        "description": "Container ontology for use with PAML (Protocol Activity Markup Language)",
        "languages": {
            "Jupyter Notebook": 140481,
            "Python": 38902,
            "M4": 1380,
            "Makefile": 1250
        }
    },
    {
        "name": "arabic-ontology",
        "description": "A Scientific research project aims to provide the theoretical basis and the practical implementation of a system kernel that extracts general ontology for Arabic language.",
        "languages": {
            "HTML": 687566,
            "CSS": 507623,
            "Java": 482723,
            "JavaScript": 286066,
            "PHP": 30326,
            "Batchfile": 30
        }
    },
    {
        "name": "basic-ontology-language",
        "description": "An experimental ontology language formalized in Coq with many semantics",
        "languages": {
            "Coq": 37802
        }
    },
    {
        "name": "WikiOnto",
        "description": "A prototype for analysing an extracted ontology in the computer languages domain.",
        "languages": {
            "Java": 123486
        }
    },
    {
        "name": "Learn-Web-Ontology-Language",
        "description": "\ud83d\udcda\ufe0f A repository for showcasing my knowledge of the  Web Ontology Language (OWL programming language, and continuing to learn the language.",
        "languages": {
            "Web Ontology Language": 210894,
            "HTML": 528
        }
    },
    {
        "name": "VehiclesOntology",
        "description": "Bulding OWL ontology with java for Natural Language Processing Project (Transportation)",
        "languages": {
            "Java": 58089
        }
    },
    {
        "name": "ontology-alignment",
        "description": "A tool for matching or aligning of ontologies with transformer language models.",
        "languages": {
            "Python": 156488,
            "Java": 3020,
            "Shell": 2320
        }
    },
    {
        "name": "SNU_2D_ProgrammingTools_IDE_Web-Ontology-Language",
        "description": "\u2328\ufe0f The Web Ontology Language (OWL) programming language IDE submodule for SNU Programming Tools (2D Mode) ",
        "languages": {
            "Web Ontology Language": 210894,
            "HTML": 528
        }
    },
    {
        "name": "AI2001_Category-Source_Code-SC-Web-Ontology-Language",
        "description": "\ud83e\udde0\ufe0f\ud83d\udda5\ufe0f2\ufe0f\u20e3\ufe0f0\ufe0f\u20e3\ufe0f0\ufe0f\u20e3\ufe0f1\ufe0f\u20e3\ufe0f\ud83d\udcbe\ufe0f\ud83d\udcdc\ufe0f The sourceCode:Web-Ontology-Language category for AI2001, containing Web Ontology Language (OWL) programming language datasets",
        "languages": {
            "Web Ontology Language": 246043,
            "R": 175745,
            "HTML": 528
        }
    },
    {
        "name": "CEDS-Ontology",
        "description": "The CEDS Ontology is draft project to express the Common Education Data Standards (CEDS) in Web Ontology Language (OWL).",
        "languages": {}
    },
    {
        "name": "NEON-GPT",
        "description": "Large Language Model for supporting Ontology Engineering",
        "languages": {
            "Rich Text Format": 45211,
            "Python": 14571,
            "Shell": 739
        }
    },
    {
        "name": "oml-tutorials",
        "description": "A tutorial on the Ontological Modeling Language",
        "languages": {
            "HTML": 777988,
            "Bikeshed": 2542,
            "Shell": 73,
            "Batchfile": 62
        }
    },
    {
        "name": "UML-ODM-to-OWL-XML",
        "description": "A script that converts UML Ontology Definition Metamodel files into XML Web Ontology Language files.",
        "languages": {
            "Python": 33064,
            "XSLT": 10692,
            "Shell": 193
        }
    },
    {
        "name": "Standard-PASS-Ontology",
        "description": "This is the public repository to hold the most recent version of the standard PASS Ontolgoy (in OWL), defining the official exchange standard for subject-oriented process models in the Parallel Activity Specification Shema (PASS) language",
        "languages": {}
    },
    {
        "name": "Automated-Semantic-Environment-Generation",
        "description": "Toolset to create ontologies for virtual worlds from natural language",
        "languages": {
            "Python": 78506
        }
    },
    {
        "name": "hpo-translations",
        "description": "This repo will contain the Human Phenotype Ontology language profiles",
        "languages": {
            "Makefile": 1014
        }
    },
    {
        "name": "decprov-ont",
        "description": "A Web Ontology Language (OWL) ontology extending the PROV ontology for modelling decisions and thus the causes for actions or the use or generation of things",
        "languages": {
            "HTML": 13788,
            "CSS": 2275
        }
    },
    {
        "name": "link-ont",
        "description": "Repository for the Web Ontology Language (OWL) ontology and documentation for the Location Information Knowledge Platform (http://link.fsdf.org.au/).",
        "languages": {
            "HTML": 42774
        }
    },
    {
        "name": "LLMap-Prelim",
        "description": "A preliminary investigation for ontology alignment (OM) with large language models (LLMs).",
        "languages": {
            "Python": 21782,
            "Jupyter Notebook": 13137
        }
    },
    {
        "name": "ewso",
        "description": "Emergent Web Structure Ontology: Using Pseudo-Cypher Natural Language and Compressed Ontology Representation Language to Provide an Abstract Syntax for Autonomous Ontology Engineering with Artificial Intelligence Enabled Agents in a Simulated Environment. EWSO was specifically designed for SANC (Sanctuary Allegorical Network Cipher) compatibility.",
        "languages": {}
    },
    {
        "name": "reibar",
        "description": "Prolog English language DCG for producing X-bar syntax trees and ontologically promiscuous semantics.",
        "languages": {
            "Prolog": 27983,
            "Ruby": 22505
        }
    },
    {
        "name": "SUST-MSC-Semntiment_Analysis-Semantically",
        "description": "This research proposes a new framework for analyzing Arabic opinions and measuring the sentiment analysis for Arabic contents using semantic approach and text analysis. The proposed framework detects the Arabic opinion orientation using Arabic ontology and Part Of Speech Tag \u2018POS\u2019  for Arabic words. The framework consisted of five components. These are; the Arabic Part Of Speech \u201cPOS\u201d tagger which was  used to assign the correct tag for every word in the opinion, the Arabic Ontology Classifier to query RDF Ontology using ontology engineering; the SPARQL language to extract the main concepts, the third component  is Arabic Sentiment Lexicon  which was used as the Arabic  dictionary; and the final components are the Counter and Report components which perform the calculation and display the final results and reports.         A framework was designed using advance integration technologies such as Stanford POS tagger, Stanford Ontology  prot\u00e9g\u00e9, and Jean framework from Apache which was used to integrate the Ontology. The framework was tested against Arabic comments using the Arabic movie ontology, and the results showed that the framework was successfully able to detect and classify the pilot comments written in Arabic language and measure them against the five star rating system. The results also agreed well with the calculated stars which was entered by the opinion holders.",
        "languages": {}
    },
    {
        "name": "umlsmap2rdf",
        "description": "These python scripts connect to the Unified Medical Language System (UMLS) database and translate the ontologies into RDF/OWL files.",
        "languages": {
            "Python": 5903
        }
    },
    {
        "name": "IEC-CIM-in-OWL",
        "description": "experimental  attempt to to express IEC CIM in the Web Ontology Language in accordance to the UML to OWL mapping suggested by the OMG ODM specification. Transformation is done manually",
        "languages": {}
    },
    {
        "name": "Overview",
        "description": "Knowledge-representation is a field of artificial intelligence that focuses on designing computer representations that capture information about the world that can be used to solve complex problems.  The justification for knowledge representation is that conventional procedural code is not the best formalism to use to solve complex problems. Knowledge representation makes complex software easier to define and maintain than procedural code and can be used in expert systems.  For example, talking to experts in terms of business rules rather than code lessens the semantic gap between users and developers and makes development of complex systems more practical.  Knowledge representation goes hand in hand with automated reasoning because one of the main purposes of explicitly representing knowledge is to be able to reason about that knowledge, to make inferences, assert new knowledge, etc. Virtually all knowledge representation languages have a reasoning or inference engine as part of the system.[10]  A key trade-off in the design of a knowledge representation formalism is that between expressivity and practicality. The ultimate knowledge representation formalism in terms of expressive power and compactness is First Order Logic (FOL). There is no more powerful formalism than that used by mathematicians to define general propositions about the world. However, FOL has two drawbacks as a knowledge representation formalism: ease of use and practicality of implementation. First order logic can be intimidating even for many software developers. Languages that do not have the complete formal power of FOL can still provide close to the same expressive power with a user interface that is more practical for the average developer to understand. The issue of practicality of implementation is that FOL in some ways is too expressive. With FOL it is possible to create statements (e.g. quantification over infinite sets) that would cause a system to never terminate if it attempted to verify them.  Thus, a subset of FOL can be both easier to use and more practical to implement. This was a driving motivation behind rule-based expert systems. IF-THEN rules provide a subset of FOL but a very useful one that is also very intuitive. The history of most of the early AI knowledge representation formalisms; from databases to semantic nets to theorem provers and production systems can be viewed as various design decisions on whether to emphasize expressive power or computability and efficiency.[11]  In a key 1993 paper on the topic, Randall Davis of MIT outlined five distinct roles to analyze a knowledge representation framework:[12]  A knowledge representation (KR) is most fundamentally a surrogate, a substitute for the thing itself, used to enable an entity to determine consequences by thinking rather than acting, i.e., by reasoning about the world rather than taking action in it. It is a set of ontological commitments, i.e., an answer to the question: In what terms should I think about the world? It is a fragmentary theory of intelligent reasoning, expressed in terms of three components: (i) the representation's fundamental conception of intelligent reasoning; (ii) the set of inferences the representation sanctions; and (iii) the set of inferences it recommends. It is a medium for pragmatically efficient computation, i.e., the computational environment in which thinking is accomplished. One contribution to this pragmatic efficiency is supplied by the guidance a representation provides for organizing information so as to facilitate making the recommended inferences. It is a medium of human expression, i.e., a language in which we say things about the world. Knowledge representation and reasoning are a key enabling technology for the Semantic Web. Languages based on the Frame model with automatic classification provide a layer of semantics on top of the existing Internet. Rather than searching via text strings as is typical today, it will be possible to define logical queries and find pages that map to those queries.[13] The automated reasoning component in these systems is an engine known as the classifier. Classifiers focus on the subsumption relations in a knowledge base rather than rules. A classifier can infer new classes and dynamically change the ontology as new information becomes available. This capability is ideal for the ever-changing and evolving information space of the Internet.[14]  The Semantic Web integrates concepts from knowledge representation and reasoning with markup languages based on XML. The Resource Description Framework (RDF) provides the basic capabilities to define knowledge-based objects on the Internet with basic features such as Is-A relations and object properties. The Web Ontology Language (OWL) adds additional semantics and integrates with automatic classification reasoners.[15]",
        "languages": {}
    },
    {
        "name": "Programming_Languages_Ontology",
        "description": "Meta-ontology for three Object oriented programming languages viz. C++, Java and Python. ",
        "languages": {}
    },
    {
        "name": "panto",
        "description": "portable natural language interface to ontologies",
        "languages": {
            "Java": 11066
        }
    },
    {
        "name": "ontoqa",
        "description": "Question Answering system with ontology-based natural language processing. Coursework in Artificial Intelligence 2016/2017",
        "languages": {
            "Java": 1278454,
            "Web Ontology Language": 339134,
            "TeX": 151049,
            "HTML": 11808,
            "JavaScript": 6478,
            "CSS": 5504,
            "Groovy": 719
        }
    },
    {
        "name": "do-ont",
        "description": "A Web Ontology Language (OWL) ontology providing means for describing decisions and decision making",
        "languages": {
            "HTML": 84169
        }
    },
    {
        "name": "OntologyWebLanguage",
        "description": "Welcome to the Ontology Web Language (OWL) repository for ECOLOPES (ECOlogical building enveLOPES), a groundbreaking design approach for regenerating urban ecosystems",
        "languages": {
            "Java": 149169,
            "HTML": 5888,
            "Batchfile": 932,
            "Shell": 258
        }
    },
    {
        "name": "facts",
        "description": "Exploration of ontological/semantic approaches for use in a distributed programming language. An AGH-UST project.",
        "languages": {}
    },
    {
        "name": "pyosl",
        "description": "Python Ontology Specification Language",
        "languages": {
            "Python": 165920,
            "Shell": 563
        }
    },
    {
        "name": "auto_ontology",
        "description": "Code for automating creation of legal-to-everyday language ontology",
        "languages": {
            "Jupyter Notebook": 105000,
            "Python": 1534,
            "Dockerfile": 934
        }
    },
    {
        "name": "Ontology-on-Q-A-for-Natural-Language-Processing",
        "description": "Question answering (QA) system aims at retrieving precise information from a large collection of documents against a query. The proposed architecture defines four basic modules suitable for enhancing current QA capabilities with the ability of processing complex questions. The first module was the question processing, which analyses and classifies the question and also reformulates the user query. The second module allows the process of retrieving the relevant ontological relations from the given question. The next module processes the retrieved words from question. Natural language processing techniques are used for processing the question and documents and also for answer extraction. Ontology and domain knowledge are used for reformulating queries and identifying the relations. ",
        "languages": {
            "Java": 42075,
            "TSQL": 404
        }
    },
    {
        "name": "rontology",
        "description": "An ontology for Romanian language",
        "languages": {}
    },
    {
        "name": "LM-ontology-concept-placement",
        "description": "Language Model based ontology concept placement",
        "languages": {
            "Python": 846019,
            "Shell": 136531
        }
    },
    {
        "name": "An-ontology-for-amazigh-berber-language-phrase-syntax-recognition",
        "description": "this project aims to make an ontology for amzigh language which will help us to recognize the syntax of the sentences",
        "languages": {}
    },
    {
        "name": "FoodOntologyGraph",
        "description": "A Visualization of the Food Ontology available in the Wolfram Language",
        "languages": {
            "Mathematica": 10633974
        }
    },
    {
        "name": "easytv-semantic-annotator",
        "description": "Semantic annotator for sign language ontology",
        "languages": {
            "Java": 201243,
            "Perl": 70902,
            "Shell": 13398,
            "Batchfile": 11460
        }
    },
    {
        "name": "Green_Library_Ontology",
        "description": "A brief information about class and types of Green Libraries on Web Ontology Language",
        "languages": {
            "Web Ontology Language": 46403
        }
    },
    {
        "name": "GRhOOT-Ontology",
        "description": "GRhOOT, the German RhetOrical OnTology, is a domain ontology of rhetorical figures in the German language.",
        "languages": {
            "Python": 2051
        }
    },
    {
        "name": "LLMs4OM",
        "description": "LLMs4OM: Matching Ontologies with Large Language Models",
        "languages": {
            "Python": 179691,
            "TeX": 103027,
            "Jupyter Notebook": 12122,
            "Shell": 5020,
            "HTML": 3610,
            "JavaScript": 2075,
            "Dockerfile": 546
        }
    },
    {
        "name": "owlapi_dependencies",
        "description": "Simple OWL API dependencies (Web Ontology Language)",
        "languages": {}
    },
    {
        "name": "JAMSROL",
        "description": "Java Atoms Molecules Science Resource Ontology Language",
        "languages": {
            "Java": 30679
        }
    },
    {
        "name": "semantic-search-arabic",
        "description": "Semantic Search in Arabic Language using an Ontology",
        "languages": {
            "Python": 48295
        }
    },
    {
        "name": "ont-lang",
        "description": "Simple tools for adding additional languages to ontologies",
        "languages": {
            "Python": 4045
        }
    },
    {
        "name": "ontoprolog",
        "description": "Ontoprolog: a Prolog-based language for describing ontologies",
        "languages": {}
    },
    {
        "name": "TWONTO",
        "description": "Classification of Assets in Web Ontology Language (OWL)",
        "languages": {
            "Python": 955
        }
    },
    {
        "name": "SIMON-A-Simple-Measurement-Vocabulary",
        "description": "A Web Ontology Language (OWL) ontology designed to represent 1, 2, and n dimensional measurements.",
        "languages": {}
    },
    {
        "name": "POC-azure-IOT-DTDL-ontology",
        "description": "The power of Ontology in the Digital Twins Definition Language universe to build powerful and sustainable devices.",
        "languages": {
            "JavaScript": 13274
        }
    },
    {
        "name": "KDM_2016",
        "description": "Ontology Creation using Natural Language Processing and Maching Learning",
        "languages": {
            "Web Ontology Language": 82684,
            "Java": 51921,
            "XSLT": 41986,
            "Scala": 30790,
            "CSS": 8742,
            "HTML": 7497
        }
    },
    {
        "name": "gov.nasa.jpl.imce.oml.frameless",
        "description": "Scala/Frameless-based API for the Ontological Modeling Language",
        "languages": {
            "Scala": 627913,
            "HTML": 3018,
            "Shell": 2697
        }
    },
    {
        "name": "owl-parser",
        "description": "Biblioteca para converter XML OWL(Web Ontology Language) para BPMN.",
        "languages": {
            "C#": 30219,
            "Dockerfile": 1266
        }
    },
    {
        "name": "rdformer",
        "description": "A Bulletproof Way to Generate RDF ontologies from Language Models",
        "languages": {}
    },
    {
        "name": "opm-owl",
        "description": "Web Ontology Language (OWL) representation of the Complex Property Model (CPM)",
        "languages": {
            "HTML": 50858
        }
    },
    {
        "name": "nlp2Sparql",
        "description": "Natural language -> SPARQL conversion for Semantic search engine based on the data from dbpedia ontology",
        "languages": {
            "Python": 30051
        }
    },
    {
        "name": "dissertation-public-resources",
        "description": "MSc Dissertation on \"Leveraging Large Language Models in Conjunction with Ontologies for Annotation of AI Incidents\"",
        "languages": {
            "Jupyter Notebook": 984912,
            "Python": 19428,
            "HTML": 1170
        }
    },
    {
        "name": "info",
        "description": "InFO is a policy language for regulating information flow control.",
        "languages": {}
    },
    {
        "name": "Personal-Expenditure-Insights",
        "description": "A light-weight methodology for extracting insights from text representing personal transactions using Triple Stores and Web Ontology Language(OWL).",
        "languages": {
            "Python": 16782
        }
    },
    {
        "name": "Filmowledge",
        "description": "An ontology-based film recommendation system built with natural language processing, knowledge graphs and SPARQL, that takes input in natural language and outputs recommended movies to users.",
        "languages": {
            "Jupyter Notebook": 6214534,
            "HTML": 132147,
            "PHP": 97773,
            "Shell": 11250,
            "Python": 9739,
            "Dockerfile": 3262,
            "CSS": 381
        }
    },
    {
        "name": "oats",
        "description": "A Python package for working with datasets of genes and phenotypes, and comparing phenotypes using ontologies and natural language processing.",
        "languages": {
            "Python": 225582
        }
    },
    {
        "name": "MOVIE-ANALYSIS---SEMANTIC-WEB",
        "description": "Created a web application in Java to extract film data from DBPEDIA ontology using SPARQL query language and Apache Jena framework.",
        "languages": {
            "Java": 57698
        }
    },
    {
        "name": "icon-745751",
        "description": "Academic project involving Knowledge Engineering methods for analysis of custom ratings of Italian school websites. Language of docs: :it:",
        "languages": {
            "Jupyter Notebook": 450661,
            "Python": 90787,
            "Prolog": 76375
        }
    },
    {
        "name": "FGTP",
        "description": "This code repository is the official resource for the paper \"Fine-Grained Task Planning for Service Robot Based on Object Ontology Knowledge via Large Language Models.\"",
        "languages": {
            "Python": 145277
        }
    },
    {
        "name": "RIFed-OntoRules",
        "description": "A repository of rule sets, described in RIF-Core, implementing the same semantics as various Ontology description languages and dialects, such as RDFS and OWL 2 RL.",
        "languages": {}
    },
    {
        "name": "protege_a3",
        "description": "Protege-OWL API Programmer's Guide  The Protege-OWL API is an open-source Java library for the Web Ontology Language (OWL) and RDF(S). The API provides classes and methods to load and save OWL files, to query and manipulate OWL data models, and to perform reasoning based on Description Logic engines. Furthermore, the API is optimized for the implementation of graphical user interfaces.",
        "languages": {
            "Java": 74887,
            "Python": 16983
        }
    },
    {
        "name": "DeepPhenoNet",
        "description": "DeepPhenoNet works to enhance the computability and interoperability of human phenotypes, diseases, and biomedical concepts from basic biomedical research to clinical medicine using large language models (LLMs)s, bridging the gap between diverse biomedical ontologies and actionable insights",
        "languages": {
            "Jupyter Notebook": 110118398,
            "HTML": 19226099
        }
    },
    {
        "name": "AutomatiMultiple-Choice-Question-Generator",
        "description": "A system takes a text as an input and by applying NLP techniques and question patterns, then it creates questions and get the choices from an online ontology \"WordNet\" according to similarity functions. the system is web application in  Python language.",
        "languages": {
            "Python": 312089,
            "HTML": 8887,
            "JavaScript": 6319,
            "CSS": 1182
        }
    },
    {
        "name": "XiaohuiZou-orcid-paper",
        "description": "Xiaohui Zou's ORCID: https://orcid.org/0000-0002-5577-8245 New Approaches to Natural Language Understanding,The Third International Conference on Intelligence Science (ICIS2018) The Formal Understanding Models2019 | book-chapter DOI: 10.1007/978-981-13-7983-3_30 Optimize Expert Knowledge Acquisition with Attribute Calculation: How to Understand Twin Turing Machine2019 | book-chapter DOI: 10.1007/978-981-13-7983-3_17 How to Understand the Fundamental Laws of Information2019 | book-chapter DOI: 10.1007/978-981-13-7986-4_4 New Approach of Big Data and Education: Any Term Must Be in the Characters Chessboard as a Super Matrix, 2019 https://dl.acm.org/doi/10.1145/3322134.3323932 Smart System Studied,Proceedings of the 2019 International Conference on Artificial Intelligence and Computer Science - AICS 2019,DOI: 10.1145/3349341.3349360 The Hub of Digital Library and Interdisciplinary Knowledge Center: Knowledge Fusion and Cultural Genetic Systems Engineering 2019-11-28 | conference-paper The Strategy of Constructing an Interdisciplinary Knowledge Center2020 | book-chapter,DOI: 10.1007/978-3-030-32591-6_112 Fundamental law of Information: Proved by Double Matrices on Numbers and Characters,AAAS Annual Meeting 2017-02 | conference-paper Ecological Characteristics of Information and Its Scientific Research,Conference FIS 2017: The Seventh International Conference on the Foundations of Information Science, in IS4SI-2017 Understanding: How to Resolve Ambiguity,2nd International Conference on Intelligence Science (ICIS) 2017-10 | conference-paper,DOI: 10.1007/978-3-319-68121-4\\_36 Bilingual Processing Method and Its Principle on Entropy 2015-11-15 | conference-abstract Basic Law of Information: Fundamental Theory of Generalized Bilingual Processing, ISIS Summit Vienna 2015THE INFORMATION SOCIETY AT THE CROSSROADS 2015-06 | conference-abstract,SOURCE-WORK-ID: 0602172206942-4 Formal Chinese Room 2014 | patent Collaborative Intelligent Computing System: Theoretical Model with Its Application,AAAS Annual Meeting 2012-02 | conference-abstract Value-Takingand Confidence-Building of Language,AAAS Annual Meeting 2012-02 | conference-abstract Value-Taking and Confidence-Building of Language: Computer-Aided Instruction and Analysis on the Object of Study in General Linguistics,Language and Value (International Conference on Values in Globalization and Change)2011-08 | conference-paper SOURCE-WORK-ID: 0602172206943-11 A Brand-New Machine Translation Strategy 2011 | SOURCE-WORK-ID: 0602172206943-12 University Education and Management \"Overlapping\" Model2011 | conference-paper  The Meaning of the Information Model on Knowledge Management in University 2010-08 | conference-paper Intelligence means information processing VII International Ontology Congress,Real or Virtual: from Plato's Cave to Internet 2006-10 | conference-paper ",
        "languages": {}
    },
    {
        "name": "Leo",
        "description": "A well-founded ontology learner based on Natural Language Processing",
        "languages": {
            "Java": 87683
        }
    },
    {
        "name": "offensive-language-ontology",
        "description": null,
        "languages": {
            "Shell": 352
        }
    },
    {
        "name": "Language-Family-Ontology",
        "description": "Dil aileleri ontolojsi",
        "languages": {}
    },
    {
        "name": "offensive-language-ontology",
        "description": null,
        "languages": {}
    },
    {
        "name": "ontology",
        "description": "Medical Ontologies such as the Unified Medical Language System",
        "languages": {}
    },
    {
        "name": "Language-Agnostic-Ontology-Extension-Framework",
        "description": "Introduce an automatic generation framework facilitating the creation of language-independent ontologies, bridging the gap between traditional manual ontology construction and the dynamic needs of diverse language formats.",
        "languages": {
            "Jupyter Notebook": 606217
        }
    },
    {
        "name": "ontology-design-pattern-representation-language",
        "description": "This repository contains the Ontology Pattern Language (OPLa) ",
        "languages": {}
    },
    {
        "name": "Wlanguage",
        "description": "language for ontology",
        "languages": {
            "Python": 16089
        }
    },
    {
        "name": "Ontology-of-the-C-Programming-Language",
        "description": "A simple ontology of C++, developed by Prot\u00e9g\u00e9.",
        "languages": {}
    },
    {
        "name": "Twitter-Disease-incidence-Description-Language-Ontology",
        "description": "An Ontology of Concepts used to communicate disease incidence on Twitter",
        "languages": {
            "Web Ontology Language": 24738
        }
    },
    {
        "name": "ontology_server",
        "description": "Language Server for Data Mining and Natural Language around SBOL and Related Ontologies/Terms.",
        "languages": {
            "Python": 1067,
            "Shell": 325,
            "Dockerfile": 88
        }
    },
    {
        "name": "LinguisticsOntology",
        "description": "Ontology for spoken and written language.",
        "languages": {}
    },
    {
        "name": "claraol-ui",
        "description": "Clara ontology language editor",
        "languages": {
            "Java": 114913,
            "CSS": 18643
        }
    },
    {
        "name": "IIA-Ontology-about-Watches-Vigier",
        "description": "Web Ontology Language (OWL)",
        "languages": {}
    },
    {
        "name": "metanetics",
        "description": "ontological SDN programming language",
        "languages": {
            "OCaml": 22956,
            "Makefile": 952,
            "Standard ML": 318
        }
    },
    {
        "name": "BBEdit-N3-CodelessLanguageModule",
        "description": "A CodelessLanguageModule for N3 and turtle ontologies",
        "languages": {}
    },
    {
        "name": "pl_ontology",
        "description": "Implementation of Programming languages ontology in OWLReady2",
        "languages": {
            "Python": 28498,
            "Jupyter Notebook": 3356
        }
    },
    {
        "name": "Recommender-Ontology",
        "description": "Protege design for ontology word language generation",
        "languages": {}
    },
    {
        "name": "hmong-ontology",
        "description": "A semantic ontology resource for the Hmong language",
        "languages": {
            "Python": 3369
        }
    },
    {
        "name": "Tutorial.Ontology.QuickStart",
        "description": "Ontology Web Language Sample (Owlready,Protege)",
        "languages": {
            "Python": 701
        }
    },
    {
        "name": "sl-onto",
        "description": "An Ontology for Sign Languages",
        "languages": {}
    },
    {
        "name": "ExperimentOntology",
        "description": "A Domain-Specific Experiment Management Language developed towards defining simulation experiments.",
        "languages": {
            "Java": 3620341,
            "GAP": 631082,
            "Xtend": 53074
        }
    },
    {
        "name": "instrument-ontology",
        "description": "Scientific instrument ontology for use with PAML (Protocol Activity Modeling Language)",
        "languages": {}
    },
    {
        "name": "library-system-ontology",
        "description": "Presentation of the Library Model Ontology using OWL language",
        "languages": {}
    },
    {
        "name": "ontology-lexicalization_de",
        "description": "Bridging the gap between natural language and knowledge base",
        "languages": {
            "Perl": 331872,
            "Python": 86928,
            "Shell": 16662,
            "Dockerfile": 1284
        }
    },
    {
        "name": "Ontology-about-States-of-India-Languages-and-IT-companies",
        "description": "Ontology about States of India, Languages and IT companies",
        "languages": {}
    },
    {
        "name": "dmo-ont",
        "description": "A Web Ontology Language (OWL) version of the Decision-Making Ontology",
        "languages": {
            "HTML": 21361
        }
    },
    {
        "name": "DialectOntology",
        "description": "Collecting names, codes, and all kinds of Information for a set of language (varieties).",
        "languages": {
            "Python": 25590
        }
    },
    {
        "name": "knowcode",
        "description": "Some natural language concept/ontology code.",
        "languages": {
            "OCaml": 14215,
            "Makefile": 291
        }
    },
    {
        "name": "natural-language-convertor",
        "description": "a java tool to convert OWL axioms from reasoning tasks to natural language",
        "languages": {
            "Java": 12579
        }
    },
    {
        "name": "ontology-from-text",
        "description": "This project aims to create ontologies based on texts in the Bulgarian language.",
        "languages": {
            "JavaScript": 14178
        }
    },
    {
        "name": "MULON",
        "description": "Create a multilingual ontology by merging two ontologies from different natural languages.",
        "languages": {
            "Scala": 68972
        }
    },
    {
        "name": "KR_forgetting_ontology",
        "description": "Forgetting Ontology is applied into OWL language in order to evaluate behavior of classes",
        "languages": {
            "Jupyter Notebook": 8968249,
            "Python": 10274
        }
    },
    {
        "name": "ontology_translation",
        "description": "Building an efficient approach towards mapping, crossdomain enrichment of dual-lingual ontologies using machine learning and natural language processing",
        "languages": {
            "Python": 214234
        }
    },
    {
        "name": "setu-ontology",
        "description": "Domain language for the flexible staffing industry. Developed by large consortium of staffing suppliers and software vendors in The Netherlands",
        "languages": {
            "Dockerfile": 779
        }
    },
    {
        "name": "Cognitive_Module_Ontology",
        "description": "An ontology in the Web Ontology Language to model the concept of cognitive modules from evolutionary psychology",
        "languages": {}
    },
    {
        "name": "langandonto.github.io",
        "description": "Website for the Language and Ontologies Workshop",
        "languages": {
            "CSS": 543421,
            "JavaScript": 306158,
            "HTML": 23801
        }
    },
    {
        "name": "Enhancing-LLMs-with-Ontologies",
        "description": "Project 'Enhancing Large Language Models Using Ontologies'",
        "languages": {
            "Jupyter Notebook": 1409197,
            "Python": 848
        }
    },
    {
        "name": "ftwr_luzl_ontology",
        "description": "First design of the Luzl language as initially designed as a social-network metalanguage to dinamize hives of people.",
        "languages": {}
    },
    {
        "name": "Ontology-based-PPI-explanation-using-LLMs",
        "description": "Ontology-based protein-protein interaction explanation using large language models",
        "languages": {
            "Python": 34732
        }
    },
    {
        "name": "Semantic_Web",
        "description": "Ontology expansion from text using Natural Language Processing",
        "languages": {
            "Jupyter Notebook": 2540114
        }
    },
    {
        "name": "oml-old",
        "description": "The implementation of the Ontology Modeling Language (OML)",
        "languages": {
            "Xtend": 135612
        }
    },
    {
        "name": "vim-dol",
        "description": "Vim Syntaxhighlight for DOL-files (distributed ontology language)",
        "languages": {
            "Vim Script": 1259
        }
    },
    {
        "name": "owl-samples",
        "description": "Java samples using the Web Ontology Language API",
        "languages": {
            "Java": 7166
        }
    },
    {
        "name": "A-Conceptual-Design-Generation-Approach-Leveraging-the-FBS-Ontology-and-Large-Language-Models",
        "description": null,
        "languages": {
            "HTML": 8522,
            "CSS": 3669,
            "Python": 2820,
            "JavaScript": 428
        }
    },
    {
        "name": "Country_ontology_and_queries",
        "description": "Builds an ontology representing information about countries based on wikipedia, and processes natural language queries producing results based on the ontology ",
        "languages": {
            "Python": 48523
        }
    },
    {
        "name": "ses-natural-language-tool",
        "description": "Developing a natural language-based tool to support modeling and simulation processes that use the System Entity Structure ontological framework.",
        "languages": {
            "Java": 488297,
            "ANTLR": 5072
        }
    },
    {
        "name": "Universe-Ontology",
        "description": "The **Universe Ontology** is an OWL (Web Ontology Language) file that represents a conceptual model of the universe. It aims to provide a structured representation of various entities and relationships within the universe, including celestial bodies, physical laws, astronomical events, and more.",
        "languages": {}
    }
]