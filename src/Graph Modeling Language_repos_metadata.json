[
    {
        "name": "funNLP",
        "description": "\u4e2d\u82f1\u6587\u654f\u611f\u8bcd\u3001\u8bed\u8a00\u68c0\u6d4b\u3001\u4e2d\u5916\u624b\u673a/\u7535\u8bdd\u5f52\u5c5e\u5730/\u8fd0\u8425\u5546\u67e5\u8be2\u3001\u540d\u5b57\u63a8\u65ad\u6027\u522b\u3001\u624b\u673a\u53f7\u62bd\u53d6\u3001\u8eab\u4efd\u8bc1\u62bd\u53d6\u3001\u90ae\u7bb1\u62bd\u53d6\u3001\u4e2d\u65e5\u6587\u4eba\u540d\u5e93\u3001\u4e2d\u6587\u7f29\u5199\u5e93\u3001\u62c6\u5b57\u8bcd\u5178\u3001\u8bcd\u6c47\u60c5\u611f\u503c\u3001\u505c\u7528\u8bcd\u3001\u53cd\u52a8\u8bcd\u8868\u3001\u66b4\u6050\u8bcd\u8868\u3001\u7e41\u7b80\u4f53\u8f6c\u6362\u3001\u82f1\u6587\u6a21\u62df\u4e2d\u6587\u53d1\u97f3\u3001\u6c6a\u5cf0\u6b4c\u8bcd\u751f\u6210\u5668\u3001\u804c\u4e1a\u540d\u79f0\u8bcd\u5e93\u3001\u540c\u4e49\u8bcd\u5e93\u3001\u53cd\u4e49\u8bcd\u5e93\u3001\u5426\u5b9a\u8bcd\u5e93\u3001\u6c7d\u8f66\u54c1\u724c\u8bcd\u5e93\u3001\u6c7d\u8f66\u96f6\u4ef6\u8bcd\u5e93\u3001\u8fde\u7eed\u82f1\u6587\u5207\u5272\u3001\u5404\u79cd\u4e2d\u6587\u8bcd\u5411\u91cf\u3001\u516c\u53f8\u540d\u5b57\u5927\u5168\u3001\u53e4\u8bd7\u8bcd\u5e93\u3001IT\u8bcd\u5e93\u3001\u8d22\u7ecf\u8bcd\u5e93\u3001\u6210\u8bed\u8bcd\u5e93\u3001\u5730\u540d\u8bcd\u5e93\u3001\u5386\u53f2\u540d\u4eba\u8bcd\u5e93\u3001\u8bd7\u8bcd\u8bcd\u5e93\u3001\u533b\u5b66\u8bcd\u5e93\u3001\u996e\u98df\u8bcd\u5e93\u3001\u6cd5\u5f8b\u8bcd\u5e93\u3001\u6c7d\u8f66\u8bcd\u5e93\u3001\u52a8\u7269\u8bcd\u5e93\u3001\u4e2d\u6587\u804a\u5929\u8bed\u6599\u3001\u4e2d\u6587\u8c23\u8a00\u6570\u636e\u3001\u767e\u5ea6\u4e2d\u6587\u95ee\u7b54\u6570\u636e\u96c6\u3001\u53e5\u5b50\u76f8\u4f3c\u5ea6\u5339\u914d\u7b97\u6cd5\u96c6\u5408\u3001bert\u8d44\u6e90\u3001\u6587\u672c\u751f\u6210&\u6458\u8981\u76f8\u5173\u5de5\u5177\u3001cocoNLP\u4fe1\u606f\u62bd\u53d6\u5de5\u5177\u3001\u56fd\u5185\u7535\u8bdd\u53f7\u7801\u6b63\u5219\u5339\u914d\u3001\u6e05\u534e\u5927\u5b66XLORE:\u4e2d\u82f1\u6587\u8de8\u8bed\u8a00\u767e\u79d1\u77e5\u8bc6\u56fe\u8c31\u3001\u6e05\u534e\u5927\u5b66\u4eba\u5de5\u667a\u80fd\u6280\u672f\u7cfb\u5217\u62a5\u544a\u3001\u81ea\u7136\u8bed\u8a00\u751f\u6210\u3001NLU\u592a\u96be\u4e86\u7cfb\u5217\u3001\u81ea\u52a8\u5bf9\u8054\u6570\u636e\u53ca\u673a\u5668\u4eba\u3001\u7528\u6237\u540d\u9ed1\u540d\u5355\u5217\u8868\u3001\u7f6a\u540d\u6cd5\u52a1\u540d\u8bcd\u53ca\u5206\u7c7b\u6a21\u578b\u3001\u5fae\u4fe1\u516c\u4f17\u53f7\u8bed\u6599\u3001cs224n\u6df1\u5ea6\u5b66\u4e60\u81ea\u7136\u8bed\u8a00\u5904\u7406\u8bfe\u7a0b\u3001\u4e2d\u6587\u624b\u5199\u6c49\u5b57\u8bc6\u522b\u3001\u4e2d\u6587\u81ea\u7136\u8bed\u8a00\u5904\u7406 \u8bed\u6599/\u6570\u636e\u96c6\u3001\u53d8\u91cf\u547d\u540d\u795e\u5668\u3001\u5206\u8bcd\u8bed\u6599\u5e93+\u4ee3\u7801\u3001\u4efb\u52a1\u578b\u5bf9\u8bdd\u82f1\u6587\u6570\u636e\u96c6\u3001ASR \u8bed\u97f3\u6570\u636e\u96c6 + \u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u4e2d\u6587\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u3001\u7b11\u58f0\u68c0\u6d4b\u5668\u3001Microsoft\u591a\u8bed\u8a00\u6570\u5b57/\u5355\u4f4d/\u5982\u65e5\u671f\u65f6\u95f4\u8bc6\u522b\u5305\u3001\u4e2d\u534e\u65b0\u534e\u5b57\u5178\u6570\u636e\u5e93\u53caapi(\u5305\u62ec\u5e38\u7528\u6b47\u540e\u8bed\u3001\u6210\u8bed\u3001\u8bcd\u8bed\u548c\u6c49\u5b57)\u3001\u6587\u6863\u56fe\u8c31\u81ea\u52a8\u751f\u6210\u3001SpaCy \u4e2d\u6587\u6a21\u578b\u3001Common Voice\u8bed\u97f3\u8bc6\u522b\u6570\u636e\u96c6\u65b0\u7248\u3001\u795e\u7ecf\u7f51\u7edc\u5173\u7cfb\u62bd\u53d6\u3001\u57fa\u4e8ebert\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u3001\u5173\u952e\u8bcd(Keyphrase)\u62bd\u53d6\u5305pke\u3001\u57fa\u4e8e\u533b\u7597\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u7684\u95ee\u7b54\u7cfb\u7edf\u3001\u57fa\u4e8e\u4f9d\u5b58\u53e5\u6cd5\u4e0e\u8bed\u4e49\u89d2\u8272\u6807\u6ce8\u7684\u4e8b\u4ef6\u4e09\u5143\u7ec4\u62bd\u53d6\u3001\u4f9d\u5b58\u53e5\u6cd5\u5206\u67904\u4e07\u53e5\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u3001cnocr\uff1a\u7528\u6765\u505a\u4e2d\u6587OCR\u7684Python3\u5305\u3001\u4e2d\u6587\u4eba\u7269\u5173\u7cfb\u77e5\u8bc6\u56fe\u8c31\u9879\u76ee\u3001\u4e2d\u6587nlp\u7ade\u8d5b\u9879\u76ee\u53ca\u4ee3\u7801\u6c47\u603b\u3001\u4e2d\u6587\u5b57\u7b26\u6570\u636e\u3001speech-aligner: \u4ece\u201c\u4eba\u58f0\u8bed\u97f3\u201d\u53ca\u5176\u201c\u8bed\u8a00\u6587\u672c\u201d\u4ea7\u751f\u97f3\u7d20\u7ea7\u522b\u65f6\u95f4\u5bf9\u9f50\u6807\u6ce8\u7684\u5de5\u5177\u3001AmpliGraph: \u77e5\u8bc6\u56fe\u8c31\u8868\u793a\u5b66\u4e60(Python)\u5e93\uff1a\u77e5\u8bc6\u56fe\u8c31\u6982\u5ff5\u94fe\u63a5\u9884\u6d4b\u3001Scattertext \u6587\u672c\u53ef\u89c6\u5316(python)\u3001\u8bed\u8a00/\u77e5\u8bc6\u8868\u793a\u5de5\u5177\uff1aBERT & ERNIE\u3001\u4e2d\u6587\u5bf9\u6bd4\u82f1\u6587\u81ea\u7136\u8bed\u8a00\u5904\u7406NLP\u7684\u533a\u522b\u7efc\u8ff0\u3001Synonyms\u4e2d\u6587\u8fd1\u4e49\u8bcd\u5de5\u5177\u5305\u3001HarvestText\u9886\u57df\u81ea\u9002\u5e94\u6587\u672c\u6316\u6398\u5de5\u5177\uff08\u65b0\u8bcd\u53d1\u73b0-\u60c5\u611f\u5206\u6790-\u5b9e\u4f53\u94fe\u63a5\u7b49\uff09\u3001word2word\uff1a(Python)\u65b9\u4fbf\u6613\u7528\u7684\u591a\u8bed\u8a00\u8bcd-\u8bcd\u5bf9\u96c6\uff1a62\u79cd\u8bed\u8a00/3,564\u4e2a\u591a\u8bed\u8a00\u5bf9\u3001\u8bed\u97f3\u8bc6\u522b\u8bed\u6599\u751f\u6210\u5de5\u5177\uff1a\u4ece\u5177\u6709\u97f3\u9891/\u5b57\u5e55\u7684\u5728\u7ebf\u89c6\u9891\u521b\u5efa\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b(ASR)\u8bed\u6599\u5e93\u3001\u6784\u5efa\u533b\u7597\u5b9e\u4f53\u8bc6\u522b\u7684\u6a21\u578b\uff08\u5305\u542b\u8bcd\u5178\u548c\u8bed\u6599\u6807\u6ce8\uff09\u3001\u5355\u6587\u6863\u975e\u76d1\u7763\u7684\u5173\u952e\u8bcd\u62bd\u53d6\u3001Kashgari\u4e2d\u4f7f\u7528gpt-2\u8bed\u8a00\u6a21\u578b\u3001\u5f00\u6e90\u7684\u91d1\u878d\u6295\u8d44\u6570\u636e\u63d0\u53d6\u5de5\u5177\u3001\u6587\u672c\u81ea\u52a8\u6458\u8981\u5e93TextTeaser: \u4ec5\u652f\u6301\u82f1\u6587\u3001\u4eba\u6c11\u65e5\u62a5\u8bed\u6599\u5904\u7406\u5de5\u5177\u96c6\u3001\u4e00\u4e9b\u5173\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u57fa\u672c\u6a21\u578b\u3001\u57fa\u4e8e14W\u6b4c\u66f2\u77e5\u8bc6\u5e93\u7684\u95ee\u7b54\u5c1d\u8bd5--\u529f\u80fd\u5305\u62ec\u6b4c\u8bcd\u63a5\u9f99and\u5df2\u77e5\u6b4c\u8bcd\u627e\u6b4c\u66f2\u4ee5\u53ca\u6b4c\u66f2\u6b4c\u624b\u6b4c\u8bcd\u4e09\u89d2\u5173\u7cfb\u7684\u95ee\u7b54\u3001\u57fa\u4e8eSiamese bilstm\u6a21\u578b\u7684\u76f8\u4f3c\u53e5\u5b50\u5224\u5b9a\u6a21\u578b\u5e76\u63d0\u4f9b\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u6d4b\u8bd5\u6570\u636e\u96c6\u3001\u7528Transformer\u7f16\u89e3\u7801\u6a21\u578b\u5b9e\u73b0\u7684\u6839\u636eHacker News\u6587\u7ae0\u6807\u9898\u81ea\u52a8\u751f\u6210\u8bc4\u8bba\u3001\u7528BERT\u8fdb\u884c\u5e8f\u5217\u6807\u8bb0\u548c\u6587\u672c\u5206\u7c7b\u7684\u6a21\u677f\u4ee3\u7801\u3001LitBank\uff1aNLP\u6570\u636e\u96c6\u2014\u2014\u652f\u6301\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u8ba1\u7b97\u4eba\u6587\u5b66\u79d1\u4efb\u52a1\u7684100\u90e8\u5e26\u6807\u8bb0\u82f1\u6587\u5c0f\u8bf4\u8bed\u6599\u3001\u767e\u5ea6\u5f00\u6e90\u7684\u57fa\u51c6\u4fe1\u606f\u62bd\u53d6\u7cfb\u7edf\u3001\u865a\u5047\u65b0\u95fb\u6570\u636e\u96c6\u3001Facebook: LAMA\u8bed\u8a00\u6a21\u578b\u5206\u6790\uff0c\u63d0\u4f9bTransformer-XL/BERT/ELMo/GPT\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u7edf\u4e00\u8bbf\u95ee\u63a5\u53e3\u3001CommonsenseQA\uff1a\u9762\u5411\u5e38\u8bc6\u7684\u82f1\u6587QA\u6311\u6218\u3001\u4e2d\u6587\u77e5\u8bc6\u56fe\u8c31\u8d44\u6599\u3001\u6570\u636e\u53ca\u5de5\u5177\u3001\u5404\u5927\u516c\u53f8\u5185\u90e8\u91cc\u5927\u725b\u5206\u4eab\u7684\u6280\u672f\u6587\u6863 PDF \u6216\u8005 PPT\u3001\u81ea\u7136\u8bed\u8a00\u751f\u6210SQL\u8bed\u53e5\uff08\u82f1\u6587\uff09\u3001\u4e2d\u6587NLP\u6570\u636e\u589e\u5f3a\uff08EDA\uff09\u5de5\u5177\u3001\u82f1\u6587NLP\u6570\u636e\u589e\u5f3a\u5de5\u5177 \u3001\u57fa\u4e8e\u533b\u836f\u77e5\u8bc6\u56fe\u8c31\u7684\u667a\u80fd\u95ee\u7b54\u7cfb\u7edf\u3001\u4eac\u4e1c\u5546\u54c1\u77e5\u8bc6\u56fe\u8c31\u3001\u57fa\u4e8emongodb\u5b58\u50a8\u7684\u519b\u4e8b\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u9879\u76ee\u3001\u57fa\u4e8e\u8fdc\u76d1\u7763\u7684\u4e2d\u6587\u5173\u7cfb\u62bd\u53d6\u3001\u8bed\u97f3\u60c5\u611f\u5206\u6790\u3001\u4e2d\u6587ULMFiT-\u60c5\u611f\u5206\u6790-\u6587\u672c\u5206\u7c7b-\u8bed\u6599\u53ca\u6a21\u578b\u3001\u4e00\u4e2a\u62cd\u7167\u505a\u9898\u7a0b\u5e8f\u3001\u4e16\u754c\u5404\u56fd\u5927\u89c4\u6a21\u4eba\u540d\u5e93\u3001\u4e00\u4e2a\u5229\u7528\u6709\u8da3\u4e2d\u6587\u8bed\u6599\u5e93 qingyun \u8bad\u7ec3\u51fa\u6765\u7684\u4e2d\u6587\u804a\u5929\u673a\u5668\u4eba\u3001\u4e2d\u6587\u804a\u5929\u673a\u5668\u4ebaseqGAN\u3001\u7701\u5e02\u533a\u9547\u884c\u653f\u533a\u5212\u6570\u636e\u5e26\u62fc\u97f3\u6807\u6ce8\u3001\u6559\u80b2\u884c\u4e1a\u65b0\u95fb\u8bed\u6599\u5e93\u5305\u542b\u81ea\u52a8\u6587\u6458\u529f\u80fd\u3001\u5f00\u653e\u4e86\u5bf9\u8bdd\u673a\u5668\u4eba-\u77e5\u8bc6\u56fe\u8c31-\u8bed\u4e49\u7406\u89e3-\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5de5\u5177\u53ca\u6570\u636e\u3001\u4e2d\u6587\u77e5\u8bc6\u56fe\u8c31\uff1a\u57fa\u4e8e\u767e\u5ea6\u767e\u79d1\u4e2d\u6587\u9875\u9762-\u62bd\u53d6\u4e09\u5143\u7ec4\u4fe1\u606f-\u6784\u5efa\u4e2d\u6587\u77e5\u8bc6\u56fe\u8c31\u3001masr: \u4e2d\u6587\u8bed\u97f3\u8bc6\u522b-\u63d0\u4f9b\u9884\u8bad\u7ec3\u6a21\u578b-\u9ad8\u8bc6\u522b\u7387\u3001Python\u97f3\u9891\u6570\u636e\u589e\u5e7f\u5e93\u3001\u4e2d\u6587\u5168\u8bcd\u8986\u76d6BERT\u53ca\u4e24\u4efd\u9605\u8bfb\u7406\u89e3\u6570\u636e\u3001ConvLab\uff1a\u5f00\u6e90\u591a\u57df\u7aef\u5230\u7aef\u5bf9\u8bdd\u7cfb\u7edf\u5e73\u53f0\u3001\u4e2d\u6587\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6570\u636e\u96c6\u3001\u57fa\u4e8e\u6700\u65b0\u7248\u672crasa\u642d\u5efa\u7684\u5bf9\u8bdd\u7cfb\u7edf\u3001\u57fa\u4e8eTensorFlow\u548cBERT\u7684\u7ba1\u9053\u5f0f\u5b9e\u4f53\u53ca\u5173\u7cfb\u62bd\u53d6\u3001\u4e00\u4e2a\u5c0f\u578b\u7684\u8bc1\u5238\u77e5\u8bc6\u56fe\u8c31/\u77e5\u8bc6\u5e93\u3001\u590d\u76d8\u6240\u6709NLP\u6bd4\u8d5b\u7684TOP\u65b9\u6848\u3001OpenCLaP\uff1a\u591a\u9886\u57df\u5f00\u6e90\u4e2d\u6587\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4ed3\u5e93\u3001UER\uff1a\u57fa\u4e8e\u4e0d\u540c\u8bed\u6599+\u7f16\u7801\u5668+\u76ee\u6807\u4efb\u52a1\u7684\u4e2d\u6587\u9884\u8bad\u7ec3\u6a21\u578b\u4ed3\u5e93\u3001\u4e2d\u6587\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5411\u91cf\u5408\u96c6\u3001\u57fa\u4e8e\u91d1\u878d-\u53f8\u6cd5\u9886\u57df(\u517c\u6709\u95f2\u804a\u6027\u8d28)\u7684\u804a\u5929\u673a\u5668\u4eba\u3001g2pC\uff1a\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u6c49\u8bed\u8bfb\u97f3\u81ea\u52a8\u6807\u8bb0\u6a21\u5757\u3001Zincbase \u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u5de5\u5177\u5305\u3001\u8bd7\u6b4c\u8d28\u91cf\u8bc4\u4ef7/\u7ec6\u7c92\u5ea6\u60c5\u611f\u8bd7\u6b4c\u8bed\u6599\u5e93\u3001\u5feb\u901f\u8f6c\u5316\u300c\u4e2d\u6587\u6570\u5b57\u300d\u548c\u300c\u963f\u62c9\u4f2f\u6570\u5b57\u300d\u3001\u767e\u5ea6\u77e5\u9053\u95ee\u7b54\u8bed\u6599\u5e93\u3001\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u95ee\u7b54\u7cfb\u7edf\u3001jieba_fast \u52a0\u901f\u7248\u7684jieba\u3001\u6b63\u5219\u8868\u8fbe\u5f0f\u6559\u7a0b\u3001\u4e2d\u6587\u9605\u8bfb\u7406\u89e3\u6570\u636e\u96c6\u3001\u57fa\u4e8eBERT\u7b49\u6700\u65b0\u8bed\u8a00\u6a21\u578b\u7684\u62bd\u53d6\u5f0f\u6458\u8981\u63d0\u53d6\u3001Python\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u8fdb\u884c\u6587\u672c\u6458\u8981\u7684\u7efc\u5408\u6307\u5357\u3001\u77e5\u8bc6\u56fe\u8c31\u6df1\u5ea6\u5b66\u4e60\u76f8\u5173\u8d44\u6599\u6574\u7406\u3001\u7ef4\u57fa\u5927\u89c4\u6a21\u5e73\u884c\u6587\u672c\u8bed\u6599\u3001StanfordNLP 0.2.0\uff1a\u7eafPython\u7248\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5305\u3001NeuralNLP-NeuralClassifier\uff1a\u817e\u8baf\u5f00\u6e90\u6df1\u5ea6\u5b66\u4e60\u6587\u672c\u5206\u7c7b\u5de5\u5177\u3001\u7aef\u5230\u7aef\u7684\u5c01\u95ed\u57df\u5bf9\u8bdd\u7cfb\u7edf\u3001\u4e2d\u6587\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff1aNeuroNER vs. BertNER\u3001\u65b0\u95fb\u4e8b\u4ef6\u7ebf\u7d22\u62bd\u53d6\u30012019\u5e74\u767e\u5ea6\u7684\u4e09\u5143\u7ec4\u62bd\u53d6\u6bd4\u8d5b\uff1a\u201c\u79d1\u5b66\u7a7a\u95f4\u961f\u201d\u6e90\u7801\u3001\u57fa\u4e8e\u4f9d\u5b58\u53e5\u6cd5\u7684\u5f00\u653e\u57df\u6587\u672c\u77e5\u8bc6\u4e09\u5143\u7ec4\u62bd\u53d6\u548c\u77e5\u8bc6\u5e93\u6784\u5efa\u3001\u4e2d\u6587\u7684GPT2\u8bad\u7ec3\u4ee3\u7801\u3001ML-NLP - \u673a\u5668\u5b66\u4e60(Machine Learning)NLP\u9762\u8bd5\u4e2d\u5e38\u8003\u5230\u7684\u77e5\u8bc6\u70b9\u548c\u4ee3\u7801\u5b9e\u73b0\u3001nlp4han:\u4e2d\u6587\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5de5\u5177\u96c6(\u65ad\u53e5/\u5206\u8bcd/\u8bcd\u6027\u6807\u6ce8/\u7ec4\u5757/\u53e5\u6cd5\u5206\u6790/\u8bed\u4e49\u5206\u6790/NER/N\u5143\u8bed\u6cd5/HMM/\u4ee3\u8bcd\u6d88\u89e3/\u60c5\u611f\u5206\u6790/\u62fc\u5199\u68c0\u67e5\u3001XLM\uff1aFacebook\u7684\u8de8\u8bed\u8a00\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u3001\u7528\u57fa\u4e8eBERT\u7684\u5fae\u8c03\u548c\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u6765\u8fdb\u884c\u77e5\u8bc6\u56fe\u8c31\u767e\u5ea6\u767e\u79d1\u4eba\u7269\u8bcd\u6761\u5c5e\u6027\u62bd\u53d6\u3001\u4e2d\u6587\u81ea\u7136\u8bed\u8a00\u5904\u7406\u76f8\u5173\u7684\u5f00\u653e\u4efb\u52a1-\u6570\u636e\u96c6-\u5f53\u524d\u6700\u4f73\u7ed3\u679c\u3001CoupletAI - \u57fa\u4e8eCNN+Bi-LSTM+Attention \u7684\u81ea\u52a8\u5bf9\u5bf9\u8054\u7cfb\u7edf\u3001\u62bd\u8c61\u77e5\u8bc6\u56fe\u8c31\u3001MiningZhiDaoQACorpus - 580\u4e07\u767e\u5ea6\u77e5\u9053\u95ee\u7b54\u6570\u636e\u6316\u6398\u9879\u76ee\u3001brat rapid annotation tool: \u5e8f\u5217\u6807\u6ce8\u5de5\u5177\u3001\u5927\u89c4\u6a21\u4e2d\u6587\u77e5\u8bc6\u56fe\u8c31\u6570\u636e\uff1a1.4\u4ebf\u5b9e\u4f53\u3001\u6570\u636e\u589e\u5f3a\u5728\u673a\u5668\u7ffb\u8bd1\u53ca\u5176\u4ed6nlp\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u53ca\u6548\u679c\u3001allennlp\u9605\u8bfb\u7406\u89e3:\u652f\u6301\u591a\u79cd\u6570\u636e\u548c\u6a21\u578b\u3001PDF\u8868\u683c\u6570\u636e\u63d0\u53d6\u5de5\u5177 \u3001 Graphbrain\uff1aAI\u5f00\u6e90\u8f6f\u4ef6\u5e93\u548c\u79d1\u7814\u5de5\u5177\uff0c\u76ee\u7684\u662f\u4fc3\u8fdb\u81ea\u52a8\u610f\u4e49\u63d0\u53d6\u548c\u6587\u672c\u7406\u89e3\u4ee5\u53ca\u77e5\u8bc6\u7684\u63a2\u7d22\u548c\u63a8\u65ad\u3001\u7b80\u5386\u81ea\u52a8\u7b5b\u9009\u7cfb\u7edf\u3001\u57fa\u4e8e\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7684\u7b80\u5386\u81ea\u52a8\u6458\u8981\u3001\u4e2d\u6587\u8bed\u8a00\u7406\u89e3\u6d4b\u8bc4\u57fa\u51c6\uff0c\u5305\u62ec\u4ee3\u8868\u6027\u7684\u6570\u636e\u96c6&\u57fa\u51c6\u6a21\u578b&\u8bed\u6599\u5e93&\u6392\u884c\u699c\u3001\u6811\u6d1e OCR \u6587\u5b57\u8bc6\u522b \u3001\u4ece\u5305\u542b\u8868\u683c\u7684\u626b\u63cf\u56fe\u7247\u4e2d\u8bc6\u522b\u8868\u683c\u548c\u6587\u5b57\u3001\u8bed\u58f0\u8fc1\u79fb\u3001Python\u53e3\u8bed\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5de5\u5177\u96c6(\u82f1\u6587)\u3001 similarity\uff1a\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u5de5\u5177\u5305\uff0cjava\u7f16\u5199\u3001\u6d77\u91cf\u4e2d\u6587\u9884\u8bad\u7ec3ALBERT\u6a21\u578b \u3001Transformers 2.0 \u3001\u57fa\u4e8e\u5927\u89c4\u6a21\u97f3\u9891\u6570\u636e\u96c6Audioset\u7684\u97f3\u9891\u589e\u5f3a \u3001Poplar\uff1a\u7f51\u9875\u7248\u81ea\u7136\u8bed\u8a00\u6807\u6ce8\u5de5\u5177\u3001\u56fe\u7247\u6587\u5b57\u53bb\u9664\uff0c\u53ef\u7528\u4e8e\u6f2b\u753b\u7ffb\u8bd1 \u3001186\u79cd\u8bed\u8a00\u7684\u6570\u5b57\u53eb\u6cd5\u5e93\u3001Amazon\u53d1\u5e03\u57fa\u4e8e\u77e5\u8bc6\u7684\u4eba-\u4eba\u5f00\u653e\u9886\u57df\u5bf9\u8bdd\u6570\u636e\u96c6 \u3001\u4e2d\u6587\u6587\u672c\u7ea0\u9519\u6a21\u5757\u4ee3\u7801\u3001\u7e41\u7b80\u4f53\u8f6c\u6362 \u3001 Python\u5b9e\u73b0\u7684\u591a\u79cd\u6587\u672c\u53ef\u8bfb\u6027\u8bc4\u4ef7\u6307\u6807\u3001\u7c7b\u4f3c\u4e8e\u4eba\u540d/\u5730\u540d/\u7ec4\u7ec7\u673a\u6784\u540d\u7684\u547d\u540d\u4f53\u8bc6\u522b\u6570\u636e\u96c6 \u3001\u4e1c\u5357\u5927\u5b66\u300a\u77e5\u8bc6\u56fe\u8c31\u300b\u7814\u7a76\u751f\u8bfe\u7a0b(\u8d44\u6599)\u3001. \u82f1\u6587\u62fc\u5199\u68c0\u67e5\u5e93 \u3001 wwsearch\u662f\u4f01\u4e1a\u5fae\u4fe1\u540e\u53f0\u81ea\u7814\u7684\u5168\u6587\u68c0\u7d22\u5f15\u64ce\u3001CHAMELEON\uff1a\u6df1\u5ea6\u5b66\u4e60\u65b0\u95fb\u63a8\u8350\u7cfb\u7edf\u5143\u67b6\u6784 \u3001 8\u7bc7\u8bba\u6587\u68b3\u7406BERT\u76f8\u5173\u6a21\u578b\u8fdb\u5c55\u4e0e\u53cd\u601d\u3001DocSearch\uff1a\u514d\u8d39\u6587\u6863\u641c\u7d22\u5f15\u64ce\u3001 LIDA\uff1a\u8f7b\u91cf\u4ea4\u4e92\u5f0f\u5bf9\u8bdd\u6807\u6ce8\u5de5\u5177 \u3001aili - the fastest in-memory index in the East \u4e1c\u534a\u7403\u6700\u5feb\u5e76\u53d1\u7d22\u5f15 \u3001\u77e5\u8bc6\u56fe\u8c31\u8f66\u97f3\u5de5\u4f5c\u9879\u76ee\u3001\u81ea\u7136\u8bed\u8a00\u751f\u6210\u8d44\u6e90\u5927\u5168 \u3001\u4e2d\u65e5\u97e9\u5206\u8bcd\u5e93mecab\u7684Python\u63a5\u53e3\u5e93\u3001\u4e2d\u6587\u6587\u672c\u6458\u8981/\u5173\u952e\u8bcd\u63d0\u53d6\u3001\u6c49\u5b57\u5b57\u7b26\u7279\u5f81\u63d0\u53d6\u5668 (featurizer)\uff0c\u63d0\u53d6\u6c49\u5b57\u7684\u7279\u5f81\uff08\u53d1\u97f3\u7279\u5f81\u3001\u5b57\u5f62\u7279\u5f81\uff09\u7528\u505a\u6df1\u5ea6\u5b66\u4e60\u7684\u7279\u5f81\u3001\u4e2d\u6587\u751f\u6210\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bc4 \u3001\u4e2d\u6587\u7f29\u5199\u6570\u636e\u96c6\u3001\u4e2d\u6587\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bc4 - \u4ee3\u8868\u6027\u7684\u6570\u636e\u96c6-\u57fa\u51c6(\u9884\u8bad\u7ec3)\u6a21\u578b-\u8bed\u6599\u5e93-baseline-\u5de5\u5177\u5305-\u6392\u884c\u699c\u3001PySS3\uff1a\u9762\u5411\u53ef\u89e3\u91caAI\u7684SS3\u6587\u672c\u5206\u7c7b\u5668\u673a\u5668\u53ef\u89c6\u5316\u5de5\u5177 \u3001\u4e2d\u6587NLP\u6570\u636e\u96c6\u5217\u8868\u3001COPE - \u683c\u5f8b\u8bd7\u7f16\u8f91\u7a0b\u5e8f\u3001doccano\uff1a\u57fa\u4e8e\u7f51\u9875\u7684\u5f00\u6e90\u534f\u540c\u591a\u8bed\u8a00\u6587\u672c\u6807\u6ce8\u5de5\u5177 \u3001PreNLP\uff1a\u81ea\u7136\u8bed\u8a00\u9884\u5904\u7406\u5e93\u3001\u7b80\u5355\u7684\u7b80\u5386\u89e3\u6790\u5668\uff0c\u7528\u6765\u4ece\u7b80\u5386\u4e2d\u63d0\u53d6\u5173\u952e\u4fe1\u606f\u3001\u7528\u4e8e\u4e2d\u6587\u95f2\u804a\u7684GPT2\u6a21\u578b\uff1aGPT2-chitchat\u3001\u57fa\u4e8e\u68c0\u7d22\u804a\u5929\u673a\u5668\u4eba\u591a\u8f6e\u54cd\u5e94\u9009\u62e9\u76f8\u5173\u8d44\u6e90\u5217\u8868(Leaderboards\u3001Datasets\u3001Papers)\u3001(Colab)\u62bd\u8c61\u6587\u672c\u6458\u8981\u5b9e\u73b0\u96c6\u9526(\u6559\u7a0b \u3001\u8bcd\u8bed\u62fc\u97f3\u6570\u636e\u3001\u9ad8\u6548\u6a21\u7cca\u641c\u7d22\u5de5\u5177\u3001NLP\u6570\u636e\u589e\u5e7f\u8d44\u6e90\u96c6\u3001\u5fae\u8f6f\u5bf9\u8bdd\u673a\u5668\u4eba\u6846\u67b6 \u3001 GitHub Typo Corpus\uff1a\u5927\u89c4\u6a21GitHub\u591a\u8bed\u8a00\u62fc\u5199\u9519\u8bef/\u8bed\u6cd5\u9519\u8bef\u6570\u636e\u96c6\u3001TextCluster\uff1a\u77ed\u6587\u672c\u805a\u7c7b\u9884\u5904\u7406\u6a21\u5757 Short text cluster\u3001\u9762\u5411\u8bed\u97f3\u8bc6\u522b\u7684\u4e2d\u6587\u6587\u672c\u89c4\u8303\u5316\u3001BLINK\uff1a\u6700\u5148\u8fdb\u7684\u5b9e\u4f53\u94fe\u63a5\u5e93\u3001BertPunc\uff1a\u57fa\u4e8eBERT\u7684\u6700\u5148\u8fdb\u6807\u70b9\u4fee\u590d\u6a21\u578b\u3001Tokenizer\uff1a\u5feb\u901f\u3001\u53ef\u5b9a\u5236\u7684\u6587\u672c\u8bcd\u6761\u5316\u5e93\u3001\u4e2d\u6587\u8bed\u8a00\u7406\u89e3\u6d4b\u8bc4\u57fa\u51c6\uff0c\u5305\u62ec\u4ee3\u8868\u6027\u7684\u6570\u636e\u96c6\u3001\u57fa\u51c6(\u9884\u8bad\u7ec3)\u6a21\u578b\u3001\u8bed\u6599\u5e93\u3001\u6392\u884c\u699c\u3001spaCy \u533b\u5b66\u6587\u672c\u6316\u6398\u4e0e\u4fe1\u606f\u63d0\u53d6 \u3001 NLP\u4efb\u52a1\u793a\u4f8b\u9879\u76ee\u4ee3\u7801\u96c6\u3001 python\u62fc\u5199\u68c0\u67e5\u5e93\u3001chatbot-list - \u884c\u4e1a\u5185\u5173\u4e8e\u667a\u80fd\u5ba2\u670d\u3001\u804a\u5929\u673a\u5668\u4eba\u7684\u5e94\u7528\u548c\u67b6\u6784\u3001\u7b97\u6cd5\u5206\u4eab\u548c\u4ecb\u7ecd\u3001\u8bed\u97f3\u8d28\u91cf\u8bc4\u4ef7\u6307\u6807(MOSNet, BSSEval, STOI, PESQ, SRMR)\u3001 \u7528138GB\u8bed\u6599\u8bad\u7ec3\u7684\u6cd5\u6587RoBERTa\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b \u3001BERT-NER-Pytorch\uff1a\u4e09\u79cd\u4e0d\u540c\u6a21\u5f0f\u7684BERT\u4e2d\u6587NER\u5b9e\u9a8c\u3001\u65e0\u9053\u8bcd\u5178 - \u6709\u9053\u8bcd\u5178\u7684\u547d\u4ee4\u884c\u7248\u672c\uff0c\u652f\u6301\u82f1\u6c49\u4e92\u67e5\u548c\u5728\u7ebf\u67e5\u8be2\u30012019\u5e74NLP\u4eae\u70b9\u56de\u987e\u3001 Chinese medical dialogue data \u4e2d\u6587\u533b\u7597\u5bf9\u8bdd\u6570\u636e\u96c6 \u3001\u6700\u597d\u7684\u6c49\u5b57\u6570\u5b57(\u4e2d\u6587\u6570\u5b57)-\u963f\u62c9\u4f2f\u6570\u5b57\u8f6c\u6362\u5de5\u5177\u3001 \u57fa\u4e8e\u767e\u79d1\u77e5\u8bc6\u5e93\u7684\u4e2d\u6587\u8bcd\u8bed\u591a\u8bcd\u4e49/\u4e49\u9879\u83b7\u53d6\u4e0e\u7279\u5b9a\u53e5\u5b50\u8bcd\u8bed\u8bed\u4e49\u6d88\u6b67\u3001awesome-nlp-sentiment-analysis - \u60c5\u611f\u5206\u6790\u3001\u60c5\u7eea\u539f\u56e0\u8bc6\u522b\u3001\u8bc4\u4ef7\u5bf9\u8c61\u548c\u8bc4\u4ef7\u8bcd\u62bd\u53d6\u3001LineFlow\uff1a\u9762\u5411\u6240\u6709\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7684NLP\u6570\u636e\u9ad8\u6548\u52a0\u8f7d\u5668\u3001\u4e2d\u6587\u533b\u5b66NLP\u516c\u5f00\u8d44\u6e90\u6574\u7406 \u3001MedQuAD\uff1a(\u82f1\u6587)\u533b\u5b66\u95ee\u7b54\u6570\u636e\u96c6\u3001\u5c06\u81ea\u7136\u8bed\u8a00\u6570\u5b57\u4e32\u89e3\u6790\u8f6c\u6362\u4e3a\u6574\u6570\u548c\u6d6e\u70b9\u6570\u3001Transfer Learning in Natural Language Processing (NLP) \u3001\u9762\u5411\u8bed\u97f3\u8bc6\u522b\u7684\u4e2d\u6587/\u82f1\u6587\u53d1\u97f3\u8f9e\u5178\u3001Tokenizers\uff1a\u6ce8\u91cd\u6027\u80fd\u4e0e\u591a\u529f\u80fd\u6027\u7684\u6700\u5148\u8fdb\u5206\u8bcd\u5668\u3001CLUENER \u7ec6\u7c92\u5ea6\u547d\u540d\u5b9e\u4f53\u8bc6\u522b Fine Grained Named Entity Recognition\u3001 \u57fa\u4e8eBERT\u7684\u4e2d\u6587\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u3001\u4e2d\u6587\u8c23\u8a00\u6570\u636e\u5e93\u3001NLP\u6570\u636e\u96c6/\u57fa\u51c6\u4efb\u52a1\u5927\u5217\u8868\u3001nlp\u76f8\u5173\u7684\u4e00\u4e9b\u8bba\u6587\u53ca\u4ee3\u7801, \u5305\u62ec\u4e3b\u9898\u6a21\u578b\u3001\u8bcd\u5411\u91cf(Word Embedding)\u3001\u547d\u540d\u5b9e\u4f53\u8bc6\u522b(NER)\u3001\u6587\u672c\u5206\u7c7b(Text Classificatin)\u3001\u6587\u672c\u751f\u6210(Text Generation)\u3001\u6587\u672c\u76f8\u4f3c\u6027(Text Similarity)\u8ba1\u7b97\u7b49\uff0c\u6d89\u53ca\u5230\u5404\u79cd\u4e0enlp\u76f8\u5173\u7684\u7b97\u6cd5\uff0c\u57fa\u4e8ekeras\u548ctensorflow \u3001Python\u6587\u672c\u6316\u6398/NLP\u5b9e\u6218\u793a\u4f8b\u3001 Blackstone\uff1a\u9762\u5411\u975e\u7ed3\u6784\u5316\u6cd5\u5f8b\u6587\u672c\u7684spaCy pipeline\u548cNLP\u6a21\u578b\u901a\u8fc7\u540c\u4e49\u8bcd\u66ff\u6362\u5b9e\u73b0\u6587\u672c\u201c\u53d8\u8138\u201d \u3001\u4e2d\u6587 \u9884\u8bad\u7ec3 ELECTREA \u6a21\u578b: \u57fa\u4e8e\u5bf9\u6297\u5b66\u4e60 pretrain Chinese Model \u3001albert-chinese-ner - \u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578bALBERT\u505a\u4e2d\u6587NER \u3001\u57fa\u4e8eGPT2\u7684\u7279\u5b9a\u4e3b\u9898\u6587\u672c\u751f\u6210/\u6587\u672c\u589e\u5e7f\u3001\u5f00\u6e90\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5408\u96c6\u3001\u591a\u8bed\u8a00\u53e5\u5411\u91cf\u5305\u3001\u7f16\u7801\u3001\u6807\u8bb0\u548c\u5b9e\u73b0\uff1a\u4e00\u79cd\u53ef\u63a7\u9ad8\u6548\u7684\u6587\u672c\u751f\u6210\u65b9\u6cd5\u3001 \u82f1\u6587\u810f\u8bdd\u5927\u5217\u8868 \u3001attnvis\uff1aGPT2\u3001BERT\u7b49transformer\u8bed\u8a00\u6a21\u578b\u6ce8\u610f\u529b\u4ea4\u4e92\u53ef\u89c6\u5316\u3001CoVoST\uff1aFacebook\u53d1\u5e03\u7684\u591a\u8bed\u79cd\u8bed\u97f3-\u6587\u672c\u7ffb\u8bd1\u8bed\u6599\u5e93\uff0c\u5305\u62ec11\u79cd\u8bed\u8a00(\u6cd5\u8bed\u3001\u5fb7\u8bed\u3001\u8377\u5170\u8bed\u3001\u4fc4\u8bed\u3001\u897f\u73ed\u7259\u8bed\u3001\u610f\u5927\u5229\u8bed\u3001\u571f\u8033\u5176\u8bed\u3001\u6ce2\u65af\u8bed\u3001\u745e\u5178\u8bed\u3001\u8499\u53e4\u8bed\u548c\u4e2d\u6587)\u7684\u8bed\u97f3\u3001\u6587\u5b57\u8f6c\u5f55\u53ca\u82f1\u6587\u8bd1\u6587\u3001Jiagu\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5de5\u5177 - \u4ee5BiLSTM\u7b49\u6a21\u578b\u4e3a\u57fa\u7840\uff0c\u63d0\u4f9b\u77e5\u8bc6\u56fe\u8c31\u5173\u7cfb\u62bd\u53d6 \u4e2d\u6587\u5206\u8bcd \u8bcd\u6027\u6807\u6ce8 \u547d\u540d\u5b9e\u4f53\u8bc6\u522b \u60c5\u611f\u5206\u6790 \u65b0\u8bcd\u53d1\u73b0 \u5173\u952e\u8bcd \u6587\u672c\u6458\u8981 \u6587\u672c\u805a\u7c7b\u7b49\u529f\u80fd\u3001\u7528unet\u5b9e\u73b0\u5bf9\u6587\u6863\u8868\u683c\u7684\u81ea\u52a8\u68c0\u6d4b\uff0c\u8868\u683c\u91cd\u5efa\u3001NLP\u4e8b\u4ef6\u63d0\u53d6\u6587\u732e\u8d44\u6e90\u5217\u8868 \u3001 \u91d1\u878d\u9886\u57df\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7814\u7a76\u8d44\u6e90\u5927\u5217\u8868\u3001CLUEDatasetSearch - \u4e2d\u82f1\u6587NLP\u6570\u636e\u96c6\uff1a\u641c\u7d22\u6240\u6709\u4e2d\u6587NLP\u6570\u636e\u96c6\uff0c\u9644\u5e38\u7528\u82f1\u6587NLP\u6570\u636e\u96c6 \u3001medical_NER - \u4e2d\u6587\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u547d\u540d\u5b9e\u4f53\u8bc6\u522b \u3001(\u54c8\u4f5b)\u8bb2\u56e0\u679c\u63a8\u7406\u7684\u514d\u8d39\u4e66\u3001\u77e5\u8bc6\u56fe\u8c31\u76f8\u5173\u5b66\u4e60\u8d44\u6599/\u6570\u636e\u96c6/\u5de5\u5177\u8d44\u6e90\u5927\u5217\u8868\u3001Forte\uff1a\u7075\u6d3b\u5f3a\u5927\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406pipeline\u5de5\u5177\u96c6 \u3001Python\u5b57\u7b26\u4e32\u76f8\u4f3c\u6027\u7b97\u6cd5\u5e93\u3001PyLaia\uff1a\u9762\u5411\u624b\u5199\u6587\u6863\u5206\u6790\u7684\u6df1\u5ea6\u5b66\u4e60\u5de5\u5177\u5305\u3001TextFooler\uff1a\u9488\u5bf9\u6587\u672c\u5206\u7c7b/\u63a8\u7406\u7684\u5bf9\u6297\u6587\u672c\u751f\u6210\u6a21\u5757\u3001Haystack\uff1a\u7075\u6d3b\u3001\u5f3a\u5927\u7684\u53ef\u6269\u5c55\u95ee\u7b54(QA)\u6846\u67b6\u3001\u4e2d\u6587\u5173\u952e\u77ed\u8bed\u62bd\u53d6\u5de5\u5177",
        "languages": {
            "Python": 365
        }
    },
    {
        "name": "ollama",
        "description": "Get up and running with Llama 3, Mistral, Gemma, and other large language models.",
        "languages": {
            "Go": 531550,
            "Shell": 36912,
            "C": 19525,
            "TypeScript": 17718,
            "PowerShell": 16637,
            "Dockerfile": 6152,
            "Inno Setup": 5644,
            "Python": 2520,
            "CSS": 518,
            "Objective-C": 435,
            "JavaScript": 248,
            "HTML": 123
        }
    },
    {
        "name": "gpt4free",
        "description": "The official gpt4free repository | various collection of powerful language models",
        "languages": {
            "Python": 630295,
            "JavaScript": 52795,
            "CSS": 22655,
            "HTML": 12815,
            "Dockerfile": 2584,
            "Shell": 200
        }
    },
    {
        "name": "ChatGLM-6B",
        "description": "ChatGLM-6B: An Open Bilingual Dialogue Language Model | \u5f00\u6e90\u53cc\u8bed\u5bf9\u8bdd\u8bed\u8a00\u6a21\u578b",
        "languages": {
            "Python": 250116,
            "Shell": 3703
        }
    },
    {
        "name": "text-generation-webui",
        "description": "A Gradio web UI for Large Language Models. Supports transformers, GPTQ, AWQ, EXL2, llama.cpp (GGUF), Llama models.",
        "languages": {
            "Python": 822703,
            "CSS": 30023,
            "JavaScript": 21930,
            "Shell": 12224,
            "Batchfile": 6489,
            "Jupyter Notebook": 5033,
            "Dockerfile": 4173
        }
    },
    {
        "name": "FastChat",
        "description": "An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and Chatbot Arena.",
        "languages": {
            "Python": 913120,
            "Jupyter Notebook": 99331,
            "Shell": 8461,
            "Dockerfile": 294
        }
    },
    {
        "name": "llm-course",
        "description": "Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks.",
        "languages": {
            "Jupyter Notebook": 4768793
        }
    },
    {
        "name": "gpt-2",
        "description": "Code for the paper \"Language Models are Unsupervised Multitask Learners\"",
        "languages": {
            "Python": 21268
        }
    },
    {
        "name": "guidance",
        "description": "A guidance language for controlling large language models.",
        "languages": {
            "Jupyter Notebook": 2006868,
            "Python": 406983,
            "JavaScript": 9704,
            "C++": 3821,
            "Rust": 386
        }
    },
    {
        "name": "StableLM",
        "description": "StableLM: Stability AI Language Models",
        "languages": {
            "Jupyter Notebook": 9973
        }
    },
    {
        "name": "gpt-3",
        "description": "GPT-3: Language Models are Few-Shot Learners",
        "languages": {}
    },
    {
        "name": "Awesome-LLM",
        "description": "Awesome-LLM: a curated list of Large Language Model",
        "languages": {}
    },
    {
        "name": "arangodb",
        "description": "\ud83e\udd51 ArangoDB is a native multi-model database with flexible data models for documents, graphs, and key-values. Build high performance applications using a convenient SQL-like query language or JavaScript extensions.",
        "languages": {
            "C++": 36631599,
            "JavaScript": 33489711,
            "TypeScript": 758793,
            "NASL": 758009,
            "CMake": 306929,
            "Python": 276313,
            "SCSS": 245566,
            "C": 240618,
            "CSS": 196570,
            "EJS": 138767,
            "Shell": 125513,
            "Yacc": 89279,
            "SourcePawn": 16408,
            "LLVM": 14804,
            "HTML": 11585,
            "PowerShell": 7819,
            "Dockerfile": 5108,
            "Makefile": 551,
            "Max": 437,
            "Batchfile": 109
        }
    },
    {
        "name": "MOSS",
        "description": "An open-source tool-augmented conversational language model from Fudan University",
        "languages": {
            "Python": 162626
        }
    },
    {
        "name": "FinGPT",
        "description": "FinGPT: Open-Source Financial Large Language Models!  Revolutionize \ud83d\udd25    We release the trained model on HuggingFace.",
        "languages": {
            "Jupyter Notebook": 5362368,
            "Python": 726494,
            "Shell": 41478,
            "TypeScript": 1883
        }
    },
    {
        "name": "char-rnn",
        "description": "Multi-layer Recurrent Neural Networks (LSTM, GRU, RNN) for character-level language models in Torch",
        "languages": {
            "Lua": 44091
        }
    },
    {
        "name": "Qwen",
        "description": "The official repo of Qwen (\u901a\u4e49\u5343\u95ee) chat & pretrained large language model proposed by Alibaba Cloud.",
        "languages": {
            "Python": 209094,
            "Jupyter Notebook": 102495,
            "Shell": 17882,
            "Dockerfile": 3022,
            "Jinja": 453
        }
    },
    {
        "name": "dolly",
        "description": "Databricks\u2019 Dolly, a large language model trained on the Databricks Machine Learning Platform",
        "languages": {
            "Python": 33042,
            "Shell": 111
        }
    },
    {
        "name": "NeMo",
        "description": "A scalable generative AI framework built for researchers and developers working on Large Language Models, Multimodal, and Speech AI (Automatic Speech Recognition and Text-to-Speech)",
        "languages": {
            "Python": 16456906,
            "Jupyter Notebook": 6508792,
            "Shell": 40848,
            "C++": 27587,
            "Dockerfile": 6664,
            "Groovy": 5587,
            "HTML": 4324,
            "CSS": 2001,
            "Makefile": 890
        }
    },
    {
        "name": "ChatRWKV",
        "description": "ChatRWKV is like ChatGPT but powered by RWKV (100% RNN) language model, and open source.",
        "languages": {
            "Python": 275953,
            "Cuda": 14232,
            "C++": 12870
        }
    },
    {
        "name": "web-llm",
        "description": "Bringing large-language models and chat to web browsers. Everything runs inside the browser with no server support.",
        "languages": {
            "TypeScript": 208510,
            "HTML": 2708,
            "Shell": 2185,
            "JavaScript": 1256
        }
    },
    {
        "name": "FlexGen",
        "description": "Running large language models on a single GPU for throughput-oriented scenarios.",
        "languages": {
            "Python": 735326,
            "Shell": 25794
        }
    },
    {
        "name": "LoRA",
        "description": "Code for loralib, an implementation of \"LoRA: Low-Rank Adaptation of Large Language Models\"",
        "languages": {
            "Python": 15334
        }
    },
    {
        "name": "Awesome-Multimodal-Large-Language-Models",
        "description": ":sparkles::sparkles:Latest Papers and Datasets on Multimodal Large Language Models, and Their Evaluation.",
        "languages": {}
    },
    {
        "name": "LLMSurvey",
        "description": "The official GitHub page for the survey paper \"A Survey of Large Language Models\".",
        "languages": {
            "Python": 738327,
            "Shell": 38077,
            "JavaScript": 22995,
            "Rust": 3380,
            "Scheme": 2111,
            "C++": 869
        }
    },
    {
        "name": "shell_gpt",
        "description": "A command-line productivity tool powered by AI large language models like GPT-4, will help you accomplish your tasks faster and more efficiently.",
        "languages": {
            "Python": 89152,
            "Shell": 367,
            "Dockerfile": 194
        }
    },
    {
        "name": "trl",
        "description": "Train transformer language models with reinforcement learning.",
        "languages": {
            "Python": 879745,
            "Shell": 16385,
            "Dockerfile": 4328,
            "Makefile": 1264
        }
    },
    {
        "name": "Fay",
        "description": "Fay is an open-source digital human framework integrating language models and digital characters. It offers retail, assistant, and agent versions for diverse applications like virtual shopping guides, broadcasters, assistants, waiters, teachers, and voice or text-based mobile assistants.",
        "languages": {}
    },
    {
        "name": "prompt-engineering",
        "description": "Tips and tricks for working with Large Language Models like OpenAI's GPT-4.",
        "languages": {}
    },
    {
        "name": "text-generation-inference",
        "description": "Large Language Model Text Generation Inference",
        "languages": {
            "Python": 1336791,
            "Rust": 386804,
            "Cuda": 150454,
            "C++": 11411,
            "Dockerfile": 8462,
            "JavaScript": 5039,
            "Makefile": 2821,
            "C": 1001,
            "Shell": 654
        }
    },
    {
        "name": "BELLE",
        "description": "BELLE: Be Everyone's Large Language model Engine\uff08\u5f00\u6e90\u4e2d\u6587\u5bf9\u8bdd\u5927\u6a21\u578b\uff09",
        "languages": {
            "HTML": 686866,
            "Python": 626321,
            "Jupyter Notebook": 178157,
            "Shell": 24447,
            "Cuda": 15843,
            "Dockerfile": 9305,
            "C++": 2258
        }
    },
    {
        "name": "Yi",
        "description": "A series of large language models trained from scratch by developers @01-ai",
        "languages": {
            "Python": 163097,
            "Shell": 1954,
            "Dockerfile": 1918
        }
    },
    {
        "name": "txtai",
        "description": "\ud83d\udca1 All-in-one open-source embeddings database for semantic search, LLM orchestration and language model workflows",
        "languages": {
            "Python": 839386,
            "Dockerfile": 3163,
            "Makefile": 2022
        }
    },
    {
        "name": "PowerInfer",
        "description": "High-speed Large Language Model Serving on PCs with Consumer-grade GPUs",
        "languages": {
            "C++": 1349794,
            "C": 1108069,
            "Cuda": 364323,
            "Python": 224151,
            "Metal": 106747,
            "Objective-C": 90604,
            "Shell": 44569,
            "CMake": 42755,
            "Zig": 6287,
            "Nix": 5761,
            "Dockerfile": 4120,
            "Swift": 1915
        }
    },
    {
        "name": "dowhy",
        "description": "DoWhy is a Python library for causal inference that supports explicit modeling and testing of causal assumptions. DoWhy is based on a unified language for causal inference, combining causal graphical models and potential outcomes frameworks. ",
        "languages": {
            "Python": 1868774
        }
    },
    {
        "name": "OpenNMT-py",
        "description": "Open Source Neural Machine Translation and (Large) Language Models in PyTorch",
        "languages": {
            "Python": 1230526,
            "Shell": 45722,
            "Perl": 6480,
            "Dockerfile": 1218
        }
    },
    {
        "name": "TensorRT-LLM",
        "description": "TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT-LLM also contains components to create Python and C++ runtimes that execute those TensorRT engines.",
        "languages": {
            "C++": 693120729,
            "Python": 3509687,
            "Cuda": 857566,
            "CMake": 67866,
            "Smarty": 21686,
            "Shell": 21117,
            "PowerShell": 14835,
            "Dockerfile": 9340,
            "Makefile": 6574,
            "C": 5050
        }
    },
    {
        "name": "pytext",
        "description": "A natural language modeling framework based on PyTorch",
        "languages": {
            "Python": 2869961,
            "Makefile": 709,
            "Shell": 600,
            "Batchfile": 535
        }
    },
    {
        "name": "ERNIE",
        "description": "Official implementations for various pre-training models of ERNIE-family, covering topics of Language Understanding & Generation, Multimodal Understanding & Generation, and beyond.",
        "languages": {
            "Python": 987904,
            "Shell": 5950
        }
    },
    {
        "name": "streaming-llm",
        "description": "[ICLR 2024] Efficient Streaming Language Models with Attention Sinks",
        "languages": {
            "Python": 23735
        }
    },
    {
        "name": "llm",
        "description": "An ecosystem of Rust libraries for working with large language models",
        "languages": {
            "Rust": 541735,
            "Nix": 885,
            "Dockerfile": 731
        }
    },
    {
        "name": "lit-llama",
        "description": "Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.",
        "languages": {
            "Python": 278014
        }
    },
    {
        "name": "sui",
        "description": " Sui, a next-generation smart contract platform with high throughput, low latency, and an asset-oriented programming model powered by the Move programming language",
        "languages": {
            "Rust": 25469742,
            "Move": 5746252,
            "TypeScript": 3014600,
            "Python": 198764,
            "Solidity": 195235,
            "MDX": 169203,
            "Shell": 77182,
            "JavaScript": 42609,
            "SCSS": 28635,
            "Dockerfile": 14832,
            "PLpgSQL": 4456,
            "Boogie": 4258,
            "HTML": 4055,
            "CSS": 1843
        }
    },
    {
        "name": "Baichuan-7B",
        "description": "A large-scale 7B pretraining language model developed by BaiChuan-Inc.",
        "languages": {
            "Python": 51328,
            "Shell": 133
        }
    },
    {
        "name": "ponyc",
        "description": "Pony is an open-source, actor-model, capabilities-secure, high performance programming language",
        "languages": {
            "C": 2416637,
            "Pony": 1522375,
            "C++": 710801,
            "CMake": 46113,
            "PowerShell": 21802,
            "Shell": 15689,
            "Makefile": 14952,
            "Dockerfile": 11541,
            "GAP": 11094,
            "DTrace": 6422,
            "LLVM": 675
        }
    },
    {
        "name": "bitsandbytes",
        "description": "Accessible large language models via k-bit quantization for PyTorch.",
        "languages": {
            "Python": 540596,
            "Cuda": 219418,
            "C++": 94865,
            "Shell": 9781,
            "CMake": 9710,
            "Metal": 2796,
            "Objective-C++": 1624,
            "C": 648
        }
    },
    {
        "name": "azure-search-openai-demo",
        "description": "A sample app for the Retrieval-Augmented Generation pattern running in Azure, using Azure AI Search for retrieval and Azure OpenAI large language models  to power ChatGPT-style and Q&A experiences.",
        "languages": {
            "Python": 440462,
            "Bicep": 102129,
            "TypeScript": 100960,
            "CSS": 11574,
            "PowerShell": 9250,
            "Shell": 7916,
            "HTML": 414
        }
    },
    {
        "name": "LLM-Agent-Paper-List",
        "description": "The paper list of the 86-page paper \"The Rise and Potential of Large Language Model Based Agents: A Survey\" by Zhiheng Xi et al.",
        "languages": {}
    },
    {
        "name": "Voyager",
        "description": "An Open-Ended Embodied Agent with Large Language Models",
        "languages": {
            "JavaScript": 174952,
            "Python": 88305
        }
    },
    {
        "name": "cvxpy",
        "description": "A Python-embedded modeling language for convex optimization problems.",
        "languages": {
            "C++": 7060732,
            "Python": 2443621,
            "C": 104717,
            "Makefile": 6320,
            "Shell": 4529,
            "SWIG": 2403,
            "CMake": 694
        }
    },
    {
        "name": "openchat",
        "description": "OpenChat: Advancing Open-source Language Models with Imperfect Data",
        "languages": {
            "Python": 164394,
            "Jupyter Notebook": 130676
        }
    },
    {
        "name": "CogVLM",
        "description": "a state-of-the-art-level open visual language model | \u591a\u6a21\u6001\u9884\u8bad\u7ec3\u6a21\u578b",
        "languages": {
            "Python": 296433,
            "Shell": 6645
        }
    },
    {
        "name": "lm-evaluation-harness",
        "description": "A framework for few-shot evaluation of language models.",
        "languages": {
            "Python": 881065,
            "C++": 6748,
            "Shell": 207
        }
    },
    {
        "name": "edward",
        "description": "A probabilistic programming language in TensorFlow. Deep generative models, variational inference.",
        "languages": {
            "Jupyter Notebook": 1104545,
            "Python": 472815,
            "Dockerfile": 2818,
            "Makefile": 1917,
            "Smarty": 198
        }
    },
    {
        "name": "JSONExport",
        "description": "JSONExport is a desktop application for Mac OS X which enables you to export JSON objects as model classes with their associated constructors, utility methods, setters and getters in your favorite language.",
        "languages": {
            "Swift": 120496
        }
    },
    {
        "name": "keto",
        "description": "Open Source (Go) implementation of \"Zanzibar: Google's Consistent, Global Authorization System\". Ships gRPC, REST APIs, newSQL, and an easy and granular permission language. Supports ACL, RBAC, and other access models.",
        "languages": {
            "Go": 563181,
            "Mustache": 90479,
            "Shell": 30337,
            "JavaScript": 13219,
            "Makefile": 5368,
            "TypeScript": 2933,
            "Dockerfile": 623
        }
    },
    {
        "name": "Resume-Matcher",
        "description": "Resume Matcher is an open source, free tool to improve your resume. It works by using language models to compare and rank resumes with job descriptions. ",
        "languages": {
            "Python": 90852,
            "Dockerfile": 301
        }
    },
    {
        "name": "RWKV-Runner",
        "description": "A RWKV management and startup tool, full automation, only 8MB. And provides an interface compatible with the OpenAI API. RWKV is a large language model that is fully open source and available for commercial use.",
        "languages": {
            "TypeScript": 326073,
            "Python": 93232,
            "Go": 39084,
            "Ruby": 8864,
            "JavaScript": 6524,
            "Shell": 4179,
            "Batchfile": 2642,
            "SCSS": 1469,
            "Dockerfile": 1439,
            "Makefile": 696,
            "HTML": 354
        }
    },
    {
        "name": "camel",
        "description": "\ud83d\udc2b CAMEL: Communicative Agents for \u201cMind\u201d Exploration of Large Language Model Society (NeruIPS'2023) https://www.camel-ai.org",
        "languages": {
            "Python": 771766,
            "Makefile": 3868,
            "HTML": 11
        }
    },
    {
        "name": "wing",
        "description": "A programming language for the cloud \u2601\ufe0f A unified programming model, combining infrastructure and runtime code into one language \u26a1",
        "languages": {
            "TypeScript": 2449128,
            "Rust": 867290,
            "JavaScript": 37973,
            "CWeb": 17164,
            "C": 6690,
            "Shell": 3722,
            "Makefile": 3658,
            "CSS": 2723,
            "AppleScript": 2691,
            "HTML": 2620,
            "Python": 2324,
            "Scheme": 1646,
            "Swift": 1430,
            "Go": 634,
            "C++": 575,
            "Dockerfile": 521
        }
    },
    {
        "name": "ToolBench",
        "description": "[ICLR'24 spotlight] An open platform for training, serving, and evaluating large language model for tool learning.",
        "languages": {
            "Python": 385356,
            "Shell": 8298
        }
    },
    {
        "name": "RedPajama-Data",
        "description": "The RedPajama-Data repository contains code for preparing large datasets for training large language models.",
        "languages": {
            "Python": 223920,
            "Shell": 8218,
            "Dockerfile": 650
        }
    },
    {
        "name": "trlx",
        "description": "A repo for distributed training of language models with Reinforcement Learning via Human Feedback (RLHF)",
        "languages": {
            "Python": 503051,
            "Shell": 6320,
            "Dockerfile": 1436
        }
    },
    {
        "name": "01",
        "description": "The open-source language model computer",
        "languages": {
            "Python": 125476,
            "C++": 31212,
            "TypeScript": 8752,
            "Rust": 3333,
            "JavaScript": 107
        }
    },
    {
        "name": "Huatuo-Llama-Med-Chinese",
        "description": "Repo for BenTsao [original name: HuaTuo (\u534e\u9a7c)], Instruction-tuning Large Language Models with Chinese Medical Knowledge. \u672c\u8349\uff08\u539f\u540d\uff1a\u534e\u9a7c\uff09\u6a21\u578b\u4ed3\u5e93\uff0c\u57fa\u4e8e\u4e2d\u6587\u533b\u5b66\u77e5\u8bc6\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6307\u4ee4\u5fae\u8c03",
        "languages": {
            "Python": 30740,
            "Shell": 3498
        }
    },
    {
        "name": "tree-of-thought-llm",
        "description": "[NeurIPS 2023] Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
        "languages": {
            "Python": 39444,
            "Jupyter Notebook": 8518,
            "Shell": 1806
        }
    },
    {
        "name": "tree-of-thoughts",
        "description": "Plug in and Play Implementation of Tree of Thoughts: Deliberate Problem Solving with Large Language Models that Elevates Model Reasoning by atleast 70% ",
        "languages": {
            "Python": 71814,
            "Shell": 2047
        }
    },
    {
        "name": "StyleTTS2",
        "description": "StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models",
        "languages": {
            "Python": 300468,
            "Jupyter Notebook": 85825
        }
    },
    {
        "name": "simpletransformers",
        "description": "Transformers for Information Retrieval, Text Classification, NER, QA, Language Modelling, Language Generation, T5, Multi-Modal, and Conversational AI",
        "languages": {
            "Python": 1518548,
            "Makefile": 1140,
            "Shell": 305
        }
    },
    {
        "name": "VisualGLM-6B",
        "description": "Chinese and English multimodal conversational language model | \u591a\u6a21\u6001\u4e2d\u82f1\u53cc\u8bed\u5bf9\u8bdd\u8bed\u8a00\u6a21\u578b",
        "languages": {
            "Python": 47531,
            "Shell": 3018
        }
    },
    {
        "name": "PromptPapers",
        "description": "Must-read papers on prompt-based tuning for pre-trained language models.",
        "languages": {}
    },
    {
        "name": "Baichuan2",
        "description": "A series of large language models developed by Baichuan Intelligent Technology",
        "languages": {
            "Python": 12159
        }
    },
    {
        "name": "scylla",
        "description": "Intelligent proxy pool for Humans\u2122 to extract content from the internet and build your own Large Language Models in this new AI era",
        "languages": {
            "Python": 76157,
            "TypeScript": 14557,
            "CSS": 1767,
            "HTML": 1554,
            "Makefile": 1540,
            "Dockerfile": 1163,
            "SCSS": 590,
            "JavaScript": 436,
            "Shell": 158
        }
    },
    {
        "name": "turbopilot",
        "description": "Turbopilot is an open source large-language-model based code completion engine that runs locally on CPU",
        "languages": {
            "C++": 549468,
            "Python": 9604,
            "CMake": 2793,
            "Shell": 181
        }
    },
    {
        "name": "CLUE",
        "description": "\u4e2d\u6587\u8bed\u8a00\u7406\u89e3\u6d4b\u8bc4\u57fa\u51c6 Chinese Language Understanding Evaluation Benchmark: datasets, baselines, pre-trained models, corpus and leaderboard  ",
        "languages": {
            "Python": 3585680,
            "Jupyter Notebook": 265952,
            "Shell": 222698
        }
    },
    {
        "name": "jsonformer",
        "description": "A Bulletproof Way to Generate Structured JSON from Language Models",
        "languages": {
            "Jupyter Notebook": 19973,
            "Python": 12190
        }
    },
    {
        "name": "lollms-webui",
        "description": "Lord of Large Language Models Web User Interface",
        "languages": {
            "Vue": 819141,
            "Python": 228554,
            "Batchfile": 59547,
            "Shell": 51825,
            "CSS": 45001,
            "JavaScript": 34401,
            "Inno Setup": 8352,
            "Jupyter Notebook": 3623,
            "Dockerfile": 890,
            "HTML": 707
        }
    },
    {
        "name": "self-instruct",
        "description": "Aligning pretrained language models with instruction data generated by themselves.",
        "languages": {
            "Python": 54972,
            "Jupyter Notebook": 6372,
            "Shell": 1297
        }
    },
    {
        "name": "alignment-handbook",
        "description": "Robust recipes to align language models with human and AI preferences",
        "languages": {
            "Python": 94452,
            "Shell": 3862,
            "Makefile": 1031,
            "MDX": 65
        }
    },
    {
        "name": "YaLM-100B",
        "description": "Pretrained language model with 100B parameters",
        "languages": {
            "Python": 795178,
            "C++": 68501,
            "Shell": 28485,
            "Cuda": 6220,
            "Dockerfile": 3510,
            "TeX": 1573,
            "Makefile": 703
        }
    },
    {
        "name": "mm-cot",
        "description": "Official implementation for \"Multimodal Chain-of-Thought Reasoning in Language Models\" (stay tuned and more will be updated)",
        "languages": {
            "Python": 1297899,
            "Shell": 4099
        }
    },
    {
        "name": "Qwen-VL",
        "description": "The official repo of Qwen-VL (\u901a\u4e49\u5343\u95ee-VL) chat & pretrained large vision language model proposed by Alibaba Cloud.",
        "languages": {
            "Python": 134791,
            "Shell": 6647
        }
    },
    {
        "name": "Luotuo-Chinese-LLM",
        "description": "\u9a86\u9a7c(Luotuo): Open Sourced Chinese Language Models. Developed by \u9648\u542f\u6e90 @ \u534e\u4e2d\u5e08\u8303\u5927\u5b66 & \u674e\u9c81\u9c81 @ \u5546\u6c64\u79d1\u6280 & \u51b7\u5b50\u6602 @ \u5546\u6c64\u79d1\u6280",
        "languages": {
            "Jupyter Notebook": 8464435,
            "Python": 2305,
            "Dockerfile": 983,
            "Shell": 979
        }
    },
    {
        "name": "moondream",
        "description": "tiny vision language model",
        "languages": {
            "Jupyter Notebook": 100685,
            "Python": 74928
        }
    },
    {
        "name": "text",
        "description": "Models, data loaders and abstractions for language processing, powered by PyTorch",
        "languages": {
            "Python": 793056,
            "C++": 104548,
            "Jupyter Notebook": 49544,
            "Shell": 17149,
            "CMake": 6607,
            "Batchfile": 5989,
            "C": 1165
        }
    },
    {
        "name": "Awesome-AIGC-Tutorials",
        "description": "Curated tutorials and resources for Large Language Models, AI Painting, and more. ",
        "languages": {}
    },
    {
        "name": "mergekit",
        "description": "Tools for merging pretrained large language models.",
        "languages": {
            "Python": 254301,
            "Jupyter Notebook": 2599
        }
    },
    {
        "name": "PLMpapers",
        "description": "Must-read Papers on pre-trained language models.",
        "languages": {}
    },
    {
        "name": "guardrails",
        "description": "Adding guardrails to large language models.",
        "languages": {
            "Python": 1056889,
            "Jupyter Notebook": 572867,
            "JavaScript": 13725,
            "Makefile": 2719,
            "Batchfile": 804
        }
    },
    {
        "name": "GLM",
        "description": "GLM (General Language Model)",
        "languages": {
            "Python": 932682,
            "Shell": 49217,
            "Dockerfile": 20209,
            "Perl": 4824
        }
    },
    {
        "name": "Baichuan-13B",
        "description": "A 13B large language model developed by Baichuan Intelligent Technology",
        "languages": {
            "Python": 5115
        }
    },
    {
        "name": "Pretrained-Language-Model",
        "description": "Pretrained language model and its related optimization techniques developed by Huawei Noah's Ark Lab.",
        "languages": {
            "Python": 4152390,
            "Shell": 139167,
            "C++": 22279,
            "Dockerfile": 2370,
            "Cython": 728
        }
    },
    {
        "name": "nlp-architect",
        "description": "A model library for exploring state-of-the-art deep learning topologies and techniques for optimizing Natural Language Processing neural networks",
        "languages": {
            "Python": 1159338,
            "Jupyter Notebook": 169849,
            "Perl": 49833,
            "JavaScript": 16582,
            "CSS": 16010,
            "Makefile": 8755,
            "Shell": 2292,
            "Dockerfile": 925,
            "HTML": 311
        }
    },
    {
        "name": "llm",
        "description": "Access large language models from the command-line",
        "languages": {
            "Python": 195998,
            "Just": 1028,
            "Shell": 929
        }
    },
    {
        "name": "awesome-speech-recognition-speech-synthesis-papers",
        "description": "Automatic Speech Recognition (ASR), Speaker Verification, Speech Synthesis, Text-to-Speech (TTS), Language Modelling, Singing Voice Synthesis (SVS), Voice Conversion (VC)",
        "languages": {}
    },
    {
        "name": "LLMZoo",
        "description": "\u26a1LLM Zoo is a project that provides data, models, and evaluation benchmark for large language models.\u26a1",
        "languages": {
            "Python": 107275,
            "Shell": 11500
        }
    },
    {
        "name": "XLM",
        "description": "PyTorch original implementation of Cross-lingual Language Model Pretraining.",
        "languages": {
            "Python": 266402,
            "Shell": 40647,
            "Jupyter Notebook": 23423,
            "Perl": 5233
        }
    },
    {
        "name": "NExT-GPT",
        "description": "Code and models for NExT-GPT: Any-to-Any Multimodal Large Language Model",
        "languages": {
            "Python": 415433,
            "Shell": 341
        }
    },
    {
        "name": "llm-attacks",
        "description": "Universal and Transferable Attacks on Aligned Language Models",
        "languages": {
            "Python": 112653,
            "Jupyter Notebook": 60916,
            "Shell": 3361
        }
    },
    {
        "name": "esm",
        "description": "Evolutionary Scale Modeling (esm): Pretrained language models for proteins",
        "languages": {
            "Python": 268893,
            "Shell": 2256
        }
    },
    {
        "name": "pyllama",
        "description": "LLaMA: Open and Efficient Foundation Language Models",
        "languages": {
            "Python": 136215,
            "Shell": 7134
        }
    },
    {
        "name": "MGM",
        "description": "Official repo for \"Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models\"",
        "languages": {
            "Python": 476215,
            "Shell": 52166,
            "JavaScript": 9991,
            "HTML": 7669,
            "CSS": 1822
        }
    },
    {
        "name": "Gepetto",
        "description": "IDA plugin which queries OpenAI's GPT language models to speed up reverse-engineering",
        "languages": {
            "Python": 19440
        }
    },
    {
        "name": "BIG-bench",
        "description": "Beyond the Imitation Game collaborative benchmark for measuring and extrapolating the capabilities of language models",
        "languages": {
            "Python": 1564542,
            "Jupyter Notebook": 638615,
            "Dockerfile": 1453,
            "Shell": 1436
        }
    },
    {
        "name": "char-rnn-tensorflow",
        "description": " Multi-layer Recurrent Neural Networks (LSTM, RNN) for character-level language models in Python using Tensorflow ",
        "languages": {
            "Python": 18274
        }
    },
    {
        "name": "Eureka",
        "description": "Official Repository for \"Eureka: Human-Level Reward Design via Coding Large Language Models\"",
        "languages": {
            "Jupyter Notebook": 23800877,
            "Python": 5351700,
            "HTML": 10952,
            "Batchfile": 528,
            "CMake": 332
        }
    },
    {
        "name": "inference",
        "description": "Replace OpenAI GPT with another LLM in your app by changing a single line of code. Xinference gives you the freedom to use any LLM you need. With Xinference, you're empowered to run inference with any open-source language models, speech recognition models, and multimodal models, whether in the cloud, on-premises, or even on your laptop.",
        "languages": {
            "Python": 1089553,
            "JavaScript": 150657,
            "Dockerfile": 2980,
            "HTML": 1722,
            "CSS": 473
        }
    },
    {
        "name": "Qwen1.5",
        "description": "Qwen1.5 is the improved version of Qwen, the large language model series developed by Qwen team, Alibaba Cloud.",
        "languages": {
            "Shell": 3169
        }
    },
    {
        "name": "prompt-engine",
        "description": "A library for helping developers craft prompts for Large Language Models",
        "languages": {
            "TypeScript": 33659,
            "JavaScript": 134
        }
    },
    {
        "name": "LLM4Decompile",
        "description": "Reverse Engineering: Decompiling Binary Code with Large Language Models",
        "languages": {
            "Python": 28278,
            "Shell": 424
        }
    },
    {
        "name": "kenlm",
        "description": "KenLM: Faster and Smaller Language Model Queries",
        "languages": {
            "C++": 1173482,
            "CMake": 27433,
            "Cython": 11280,
            "Python": 5861,
            "C": 3245,
            "Shell": 1505
        }
    },
    {
        "name": "Video-LLaMA",
        "description": "[EMNLP 2023 Demo] Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding",
        "languages": {
            "Python": 455575
        }
    },
    {
        "name": "lida",
        "description": "Automatic Generation of Visualizations and Infographics using Large Language Models",
        "languages": {
            "Jupyter Notebook": 253361,
            "JavaScript": 241886,
            "HTML": 221408,
            "Python": 89989
        }
    },
    {
        "name": "chain-of-thought-hub",
        "description": "Benchmarking large language models' complex reasoning ability with chain-of-thought prompting",
        "languages": {
            "Jupyter Notebook": 2679314,
            "Python": 61093
        }
    },
    {
        "name": "dbrx",
        "description": "Code examples and resources for DBRX, a large language model developed by Databricks",
        "languages": {
            "Python": 94515
        }
    },
    {
        "name": "sglang",
        "description": "SGLang is a structured generation language designed for large language models (LLMs). It makes your interaction with models faster and more controllable.",
        "languages": {
            "Python": 746417,
            "Shell": 2561
        }
    },
    {
        "name": "audiolm-pytorch",
        "description": "Implementation of AudioLM, a SOTA Language Modeling Approach to Audio Generation out of Google Research, in Pytorch",
        "languages": {
            "Python": 198607,
            "Jupyter Notebook": 27982
        }
    },
    {
        "name": "EasyLM",
        "description": "Large language models (LLMs) made easy, EasyLM is a one stop solution for pre-training, finetuning, evaluating and serving LLMs in JAX/Flax.",
        "languages": {
            "Python": 322644,
            "Shell": 9573
        }
    },
    {
        "name": "Awesome-LLM-Robotics",
        "description": "A comprehensive list of papers using large language/multi-modal models for Robotics/RL, including papers, codes, and related websites",
        "languages": {}
    },
    {
        "name": "JuMP.jl",
        "description": "Modeling language for Mathematical Optimization (linear, mixed-integer, conic, semidefinite, nonlinear)",
        "languages": {
            "Julia": 1314515
        }
    },
    {
        "name": "RL4LMs",
        "description": "A modular RL library to fine-tune language models to human preferences",
        "languages": {
            "Python": 695027,
            "HTML": 172434,
            "Perl": 12498,
            "Shell": 12469,
            "Dockerfile": 991
        }
    },
    {
        "name": "finetune-transformer-lm",
        "description": "Code and model for the paper \"Improving Language Understanding by Generative Pre-Training\"",
        "languages": {
            "Python": 30482
        }
    },
    {
        "name": "aiXcoder-7B",
        "description": "official repository of aiXcoder-7B Code Large Language Model",
        "languages": {
            "Python": 351314
        }
    },
    {
        "name": "makemore",
        "description": "An autoregressive character-level language model for making more things",
        "languages": {
            "Python": 29659
        }
    },
    {
        "name": "awesome-gpt4",
        "description": "A curated list of prompts, tools, and resources regarding the GPT-4 language model.",
        "languages": {}
    },
    {
        "name": "text-generation-webui-colab",
        "description": "A colab gradio web UI for running Large Language Models",
        "languages": {
            "Jupyter Notebook": 84341
        }
    },
    {
        "name": "promptbench",
        "description": "A unified evaluation framework for large language models",
        "languages": {
            "Python": 721930
        }
    },
    {
        "name": "human-eval",
        "description": "Code for the paper \"Evaluating Large Language Models Trained on Code\"",
        "languages": {
            "Python": 12580
        }
    },
    {
        "name": "awd-lstm-lm",
        "description": "LSTM and QRNN Language Model Toolkit for PyTorch",
        "languages": {
            "Python": 54289,
            "Shell": 1434
        }
    },
    {
        "name": "api-for-open-llm",
        "description": "Openai style api for open large language models, using LLMs just as chatgpt! Support for LLaMA, LLaMA-2, BLOOM, Falcon, Baichuan, Qwen, Xverse, SqlCoder, CodeLLaMA, ChatGLM, ChatGLM2, ChatGLM3 etc. \u5f00\u6e90\u5927\u6a21\u578b\u7684\u7edf\u4e00\u540e\u7aef\u63a5\u53e3",
        "languages": {
            "Python": 476995,
            "C++": 838,
            "Dockerfile": 308
        }
    },
    {
        "name": "TavernAI",
        "description": "Atmospheric adventure chat for AI language models (KoboldAI, NovelAI, Pygmalion, OpenAI chatgpt, gpt-4)",
        "languages": {
            "JavaScript": 821469,
            "HTML": 132102,
            "CSS": 120161,
            "Jupyter Notebook": 84138,
            "Shell": 947,
            "Dockerfile": 395,
            "Batchfile": 172,
            "PowerShell": 126
        }
    },
    {
        "name": "mPLUG-Owl",
        "description": "mPLUG-Owl & mPLUG-Owl2: Modularized Multimodal Large Language Model",
        "languages": {
            "Python": 749506,
            "Shell": 5649
        }
    },
    {
        "name": "ecco",
        "description": "Explain, analyze, and visualize NLP language models. Ecco creates interactive visualizations directly in Jupyter notebooks explaining the behavior of Transformer-based language models (like GPT2, BERT, RoBERTA, T5, and T0).",
        "languages": {
            "Jupyter Notebook": 1370414,
            "Python": 152760,
            "HTML": 35536,
            "CSS": 2937
        }
    },
    {
        "name": "ChatYuan",
        "description": "ChatYuan: Large Language Model for Dialogue in Chinese and English",
        "languages": {
            "Python": 25710
        }
    },
    {
        "name": "toolformer-pytorch",
        "description": "Implementation of Toolformer, Language Models That Can Use Tools, by MetaAI",
        "languages": {
            "Python": 49312
        }
    },
    {
        "name": "ctrl",
        "description": "Conditional Transformer Language Model for Controllable Generation",
        "languages": {
            "Python": 55784
        }
    },
    {
        "name": "graph-of-thoughts",
        "description": "Official Implementation of \"Graph of Thoughts: Solving Elaborate Problems with Large Language Models\"",
        "languages": {
            "Python": 76544
        }
    },
    {
        "name": "pyomo",
        "description": "An object-oriented algebraic modeling language in Python for structured optimization problems.",
        "languages": {
            "Python": 16352450,
            "Jupyter Notebook": 702031,
            "C++": 249605,
            "JetBrains MPS": 42542,
            "AMPL": 34511,
            "GAMS": 18633,
            "CMake": 10393,
            "Shell": 7365,
            "C": 6118
        }
    },
    {
        "name": "biobert",
        "description": "Bioinformatics'2020: BioBERT: a pre-trained biomedical language representation model for biomedical text mining",
        "languages": {
            "Python": 289420,
            "Perl": 12743,
            "Shell": 601
        }
    },
    {
        "name": "Chain-of-ThoughtsPapers",
        "description": "A trend starts from \"Chain of Thought Prompting Elicits Reasoning in Large Language Models\".",
        "languages": {}
    },
    {
        "name": "prompt2model",
        "description": "prompt2model - Generate Deployable Models from Natural Language Instructions",
        "languages": {
            "Python": 542810,
            "Jupyter Notebook": 23211
        }
    },
    {
        "name": "lightllm",
        "description": "LightLLM is a Python-based LLM (Large Language Model) inference and serving framework, notable for its lightweight design, easy scalability, and high-speed performance.",
        "languages": {
            "Python": 932485,
            "Shell": 4876,
            "Dockerfile": 2022
        }
    },
    {
        "name": "ChineseGLUE",
        "description": "Language Understanding Evaluation benchmark for Chinese: datasets, baselines, pre-trained models,corpus and leaderboard",
        "languages": {
            "Python": 3570577,
            "Jupyter Notebook": 265952,
            "Shell": 176931
        }
    },
    {
        "name": "VLM_survey",
        "description": "Collection of AWESOME vision-language models for vision tasks",
        "languages": {}
    },
    {
        "name": "FARM",
        "description": ":house_with_garden: Fast & easy transfer learning for NLP. Harvesting language models for the industry. Focus on Question Answering.",
        "languages": {
            "Python": 1005324,
            "Jupyter Notebook": 430447,
            "HTML": 1578,
            "Dockerfile": 378
        }
    },
    {
        "name": "Code-LMs",
        "description": "Guide to using pre-trained large language models of source code",
        "languages": {
            "Python": 17017,
            "Shell": 2139
        }
    },
    {
        "name": "gpt2-ml",
        "description": "GPT2 for Multiple Languages, including pretrained models. GPT2 \u591a\u8bed\u8a00\u652f\u6301, 15\u4ebf\u53c2\u6570\u4e2d\u6587\u9884\u8bad\u7ec3\u6a21\u578b",
        "languages": {
            "Python": 93859,
            "Perl": 3184,
            "Jupyter Notebook": 2764,
            "Shell": 1812,
            "Dockerfile": 721
        }
    },
    {
        "name": "MoE-LLaVA",
        "description": "Mixture-of-Experts for Large Vision-Language Models",
        "languages": {
            "Python": 1084795,
            "Shell": 50085,
            "JavaScript": 9991,
            "HTML": 7669,
            "CSS": 1822
        }
    },
    {
        "name": "helm",
        "description": "Holistic Evaluation of Language Models (HELM), a framework to increase the transparency of language models (https://arxiv.org/abs/2211.09110). This framework is also used to evaluate text-to-image models in Holistic Evaluation of Text-to-Image Models (HEIM) (https://arxiv.org/abs/2311.04287).",
        "languages": {
            "Python": 3251392,
            "TypeScript": 145941,
            "JavaScript": 92999,
            "HTML": 13772,
            "Shell": 4704,
            "CSS": 3050
        }
    },
    {
        "name": "bilm-tf",
        "description": "Tensorflow implementation of contextualized word representations from bi-directional language models",
        "languages": {
            "Python": 137829,
            "Dockerfile": 1165,
            "Shell": 190
        }
    },
    {
        "name": "lm-hackers",
        "description": "Hackers' Guide to Language Models",
        "languages": {
            "Jupyter Notebook": 768040,
            "Python": 2117
        }
    },
    {
        "name": "chronos-forecasting",
        "description": "Chronos: Pretrained (Language) Models for Probabilistic Time Series Forecasting",
        "languages": {
            "Python": 24044
        }
    },
    {
        "name": "CPM-1-Generate",
        "description": "Chinese Pre-Trained Language Models (CPM-LM) Version-I",
        "languages": {
            "Python": 519967,
            "C++": 14009,
            "Shell": 3062,
            "Makefile": 279
        }
    },
    {
        "name": "InternLM-XComposer",
        "description": "InternLM-XComposer2 is a groundbreaking vision-language large model (VLLM) excelling in free-form text-image composition and comprehension. ",
        "languages": {
            "Python": 905231,
            "Jupyter Notebook": 62917,
            "Shell": 41014
        }
    },
    {
        "name": "nlp-journey",
        "description": "Documents, papers and codes related to  Natural Language Processing, including Topic Model, Word Embedding, Named Entity Recognition, Text Classificatin, Text Generation, Text Similarity, Machine Translation)\uff0cetc. All codes are implemented intensorflow 2.0.",
        "languages": {
            "Python": 116106
        }
    },
    {
        "name": "codeshell",
        "description": "A series of code large language models developed by PKU-KCL",
        "languages": {
            "Python": 88495,
            "Shell": 3110
        }
    },
    {
        "name": "ReAct",
        "description": "[ICLR 2023] ReAct: Synergizing Reasoning and Acting in Language Models",
        "languages": {
            "Jupyter Notebook": 2063260,
            "Python": 13158
        }
    },
    {
        "name": "Vary",
        "description": "Official code implementation of Vary: Scaling Up the Vision Vocabulary of Large Vision Language Models.",
        "languages": {
            "Python": 266188
        }
    },
    {
        "name": "meditron",
        "description": "Meditron is a suite of open-source medical Large Language Models (LLMs).",
        "languages": {
            "Python": 305685,
            "Shell": 33198,
            "TypeScript": 29019
        }
    },
    {
        "name": "chat-ollama",
        "description": "ChatOllama is an open source chatbot based on LLMs. It supports a wide range of language models, and knowledge base management.",
        "languages": {
            "Vue": 72581,
            "TypeScript": 59777,
            "SCSS": 27420,
            "Dockerfile": 439,
            "Shell": 225
        }
    },
    {
        "name": "spacy-models",
        "description": "\ud83d\udcab  Models for the spaCy Natural Language Processing (NLP) library",
        "languages": {
            "Python": 59045
        }
    },
    {
        "name": "pytorch-openai-transformer-lm",
        "description": "\ud83d\udc25A PyTorch implementation of OpenAI's finetuned transformer language model with a script to import the weights pre-trained by OpenAI",
        "languages": {
            "Python": 45890
        }
    },
    {
        "name": "CoOp",
        "description": "Prompt Learning for Vision-Language Models (IJCV'22, CVPR'22)",
        "languages": {
            "Python": 134456,
            "Shell": 5875
        }
    },
    {
        "name": "LISA",
        "description": "Project Page for \"LISA: Reasoning Segmentation via Large Language Model\"",
        "languages": {
            "Python": 529871
        }
    },
    {
        "name": "long_llama",
        "description": "LongLLaMA is a large language model capable of handling long contexts. It is based on OpenLLaMA and fine-tuned with the Focused Transformer (FoT) method.",
        "languages": {
            "Python": 287417,
            "Jupyter Notebook": 150122,
            "Shell": 3159
        }
    },
    {
        "name": "refact",
        "description": "WebUI for Fine-Tuning and Self-hosting of Open-Source Large Language Models for Coding ",
        "languages": {
            "JavaScript": 1618168,
            "Python": 608925,
            "CSS": 63532,
            "HTML": 60738,
            "Dockerfile": 1862,
            "Shell": 1331
        }
    },
    {
        "name": "promptoftheyear",
        "description": "In the evolving world of Large Language Models (LLMs), crafting effective prompts has become an essential skill. That's why I've created this collection, showcasing the most impactful prompts of the year across various intriguing domains. \ud83c\udf10",
        "languages": {}
    },
    {
        "name": "Macaw-LLM",
        "description": "Macaw-LLM: Multi-Modal Language Modeling with Image, Video, Audio, and Text Integration",
        "languages": {
            "Python": 148981,
            "Shell": 2446
        }
    },
    {
        "name": "enchanted",
        "description": "Enchanted is iOS and macOS app for chatting with private self hosted language models such as Llama2, Mistral or Vicuna using Ollama.",
        "languages": {
            "Swift": 187260
        }
    },
    {
        "name": "OpenCodeInterpreter",
        "description": "OpenCodeInterpreter is a suite of open-source code generation systems aimed at bridging the gap between large language models and sophisticated proprietary systems like the GPT-4 Code Interpreter. It significantly enhances code generation capabilities by integrating execution and iterative refinement functionalities.",
        "languages": {
            "Python": 353789,
            "Shell": 14746,
            "Dockerfile": 435
        }
    },
    {
        "name": "DALEX",
        "description": "moDel Agnostic Language for Exploration and eXplanation",
        "languages": {
            "Python": 724597,
            "R": 244584
        }
    },
    {
        "name": "word-rnn-tensorflow",
        "description": "Multi-layer Recurrent Neural Networks (LSTM, RNN) for word-level language models in Python using TensorFlow.",
        "languages": {
            "Python": 28813
        }
    },
    {
        "name": "LAMA",
        "description": " LAnguage Model Analysis",
        "languages": {
            "Python": 111527,
            "Shell": 5377
        }
    },
    {
        "name": "Transformer",
        "description": "Transformer seq2seq model, program that can build a language translator from parallel corpus",
        "languages": {
            "Python": 30208,
            "Jupyter Notebook": 4270
        }
    },
    {
        "name": "prismer",
        "description": "The implementation of \"Prismer: A Vision-Language Model with Multi-Task Experts\".",
        "languages": {
            "Python": 902307,
            "Cuda": 62296,
            "C++": 6887,
            "Shell": 1237
        }
    },
    {
        "name": "BitNet",
        "description": "Implementation of \"BitNet: Scaling 1-bit Transformers for Large Language Models\" in pytorch",
        "languages": {
            "Python": 110371,
            "Cuda": 2020,
            "C++": 999
        }
    },
    {
        "name": "pororo",
        "description": "PORORO: Platform Of neuRal mOdels for natuRal language prOcessing",
        "languages": {
            "Python": 835454,
            "Shell": 2237,
            "Dockerfile": 1682,
            "Makefile": 233
        }
    },
    {
        "name": "Megatron-DeepSpeed",
        "description": "Ongoing research training transformer language models at scale, including: BERT & GPT-2",
        "languages": {
            "Python": 1379211,
            "C++": 94428,
            "Cuda": 32819,
            "Shell": 19995,
            "C": 3452,
            "Makefile": 932
        }
    },
    {
        "name": "cramming",
        "description": "Cramming the training of a (BERT-type) language model into limited compute.",
        "languages": {
            "Python": 375242,
            "Shell": 126481
        }
    },
    {
        "name": "self-rewarding-lm-pytorch",
        "description": "Implementation of the training framework proposed in Self-Rewarding Language Model, from MetaAI",
        "languages": {
            "Python": 67078
        }
    },
    {
        "name": "readme-ai",
        "description": "\ud83d\udc7e Automated README file generator, powered by large language model APIs.",
        "languages": {
            "Python": 243065,
            "Shell": 9911,
            "Makefile": 1659,
            "Dockerfile": 1045
        }
    },
    {
        "name": "LLM-eval-survey",
        "description": "The official GitHub page for the survey paper \"A Survey on Evaluation of Large Language Models\".",
        "languages": {}
    },
    {
        "name": "MotionGPT",
        "description": "[NeurIPS 2023] MotionGPT: Human Motion as a Foreign Language, a unified motion-language generation model using LLMs",
        "languages": {
            "Python": 711379,
            "CSS": 7012,
            "Shell": 3700
        }
    },
    {
        "name": "OpenMoE",
        "description": "A family of open-sourced Mixture-of-Experts (MoE) Large Language Models",
        "languages": {
            "Python": 60374,
            "Shell": 4551
        }
    },
    {
        "name": "laravel-translatable",
        "description": "A Laravel package for multilingual models",
        "languages": {
            "PHP": 122906
        }
    },
    {
        "name": "TinyGPT-V",
        "description": "TinyGPT-V: Efficient Multimodal Large Language Model via Small Backbones",
        "languages": {
            "Python": 1115929
        }
    },
    {
        "name": "FastEdit",
        "description": "\ud83e\ude79Editing large language models within 10 seconds\u26a1",
        "languages": {
            "Python": 53325
        }
    },
    {
        "name": "MiniChain",
        "description": "A tiny library for coding with large language models.",
        "languages": {
            "Python": 30698,
            "Smarty": 1553,
            "Makefile": 279
        }
    },
    {
        "name": "auto-cot",
        "description": "Official implementation for \"Automatic Chain of Thought Prompting in Large Language Models\" (stay tuned & more will be updated)",
        "languages": {
            "Jupyter Notebook": 47730,
            "Python": 32547
        }
    },
    {
        "name": "languagemodels",
        "description": "Explore large language models in 512MB of RAM",
        "languages": {
            "Python": 56791,
            "TeX": 9577,
            "Makefile": 2111
        }
    },
    {
        "name": "llm-chain",
        "description": "`llm-chain` is a powerful rust crate for building chains in large language models allowing you to summarise text and complete complex tasks",
        "languages": {
            "Rust": 633740,
            "JavaScript": 9294,
            "C++": 5199,
            "CSS": 1544,
            "MDX": 698,
            "C": 19
        }
    },
    {
        "name": "SWE-bench",
        "description": "[ICLR 2024] SWE-Bench: Can Language Models Resolve Real-world Github Issues?",
        "languages": {
            "Python": 356412,
            "Jupyter Notebook": 5433,
            "Shell": 3954
        }
    },
    {
        "name": "yarn",
        "description": "YaRN: Efficient Context Window Extension of Large Language Models",
        "languages": {
            "Python": 311981,
            "Shell": 12617
        }
    },
    {
        "name": "awesome-vision-language-pretraining-papers",
        "description": "Recent Advances in Vision and Language PreTrained Models (VL-PTMs)",
        "languages": {}
    },
    {
        "name": "RetNet",
        "description": "An implementation of \"Retentive Network: A Successor to Transformer for Large Language Models\" ",
        "languages": {
            "Python": 39196
        }
    },
    {
        "name": "PPLM",
        "description": "Plug and Play Language Model implementation. Allows to steer topic and attributes of GPT-2 models.",
        "languages": {
            "Python": 427422,
            "Jupyter Notebook": 122342,
            "Shell": 242
        }
    },
    {
        "name": "lm-human-preferences",
        "description": "Code for the paper Fine-Tuning Language Models from Human Preferences",
        "languages": {
            "Python": 163036
        }
    },
    {
        "name": "rwkv.cpp",
        "description": "INT4/INT5/INT8 and FP16 inference on CPU for RWKV language model",
        "languages": {
            "C++": 84837,
            "Python": 73004,
            "C": 32296,
            "CMake": 19202
        }
    },
    {
        "name": "alpaca_eval",
        "description": "An automatic evaluator for instruction-following language models. Human-validated, high-quality, cheap, and fast.",
        "languages": {
            "Jupyter Notebook": 3442504,
            "Python": 324956
        }
    },
    {
        "name": "mario-gpt",
        "description": "[Neurips 2023] Generating Mario Levels with GPT2. Code for the paper \"MarioGPT: Open-Ended Text2Level Generation through Large Language Models\" https://arxiv.org/abs/2302.05981",
        "languages": {
            "Python": 152776,
            "Jupyter Notebook": 141913,
            "Makefile": 739
        }
    }
]