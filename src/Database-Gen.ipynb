{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d07a4a-0237-4d78-82b0-36ebeb784d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 171\n",
    "end = 172\n",
    "count = 100\n",
    "existing_pages = 2\n",
    "extra_pages = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716cf26b-665a-4d6f-b584-ccdb776b56e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import requests\n",
    "\n",
    "# URL of the languages.yml file in the GitHub Linguist repository\n",
    "url = \"https://raw.githubusercontent.com/github/linguist/b3664e4f242c842e356bd011090f85514d147948/lib/linguist/languages.yml\"\n",
    "\n",
    "# Fetch the content of the YAML file\n",
    "response = requests.get(url)\n",
    "yaml_content = response.text\n",
    "\n",
    "# Parse the YAML content\n",
    "languages_data = yaml.safe_load(yaml_content)\n",
    "\n",
    "# Extract language names\n",
    "languages = list(languages_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91972646-2f5b-42ae-931f-b2156ae67213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metadata for Go repositories...\n",
      "Metadata for Go repositories stored successfully in Go_repos_metadata.json\n",
      "Metadata for Go repositories stored successfully in Go_repos_metadata.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# GitHub API base URL\n",
    "base_url = \"https://api.github.com\"\n",
    "\n",
    "# GitHub personal access token\n",
    "# Replace 'YOUR_ACCESS_TOKEN' with your actual token\n",
    "access_token = 'YOUR_ACCESS_TOKEN'\n",
    "\n",
    "# Function to fetch repository metadata for a given language\n",
    "def fetch_repo_metadata(language, page):\n",
    "    # Endpoint to search repositories by language\n",
    "    search_endpoint = f\"{base_url}/search/repositories\"\n",
    "    \n",
    "    # Query parameters for the search endpoint\n",
    "    params = {\n",
    "        'q': f'language:{language}',\n",
    "        'sort': 'stars',\n",
    "        'order': 'desc',\n",
    "        'per_page': 100,  # Number of results per page (maximum allowed)\n",
    "        'page': page\n",
    "    }\n",
    "    \n",
    "    # Headers including the access token\n",
    "    headers = {\n",
    "        'Authorization': f'token {access_token}',\n",
    "        'Accept': 'application/vnd.github.v3+json'\n",
    "    }\n",
    "\n",
    "    # Make the API request\n",
    "    response = requests.get(search_endpoint, params=params, headers=headers)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract the first few repositories\n",
    "        repositories = data['items'][:count]\n",
    "        \n",
    "        # Fetch language data for each repository and extract only required metadata\n",
    "        repo_metadata = []\n",
    "        for repo in repositories:\n",
    "            # Fetch language data for the repository\n",
    "            language_url = f\"{base_url}/repos/{repo['full_name']}/languages\"\n",
    "            language_response = requests.get(language_url, headers=headers)\n",
    "            if language_response.status_code == 200:\n",
    "                # Parse language data\n",
    "                languages = language_response.json()\n",
    "                \n",
    "                # Extract required metadata\n",
    "                metadata = {\n",
    "                    'name': repo['name'],\n",
    "                    'description': repo['description'],\n",
    "                    'languages': languages\n",
    "                }\n",
    "                \n",
    "                repo_metadata.append(metadata)\n",
    "            else:\n",
    "                print(f\"Failed to fetch language data for {repo['full_name']}. Status code: {language_response.status_code}\")\n",
    "        \n",
    "        # Return metadata for each repository\n",
    "        return repo_metadata\n",
    "    else:\n",
    "        # Print error message if request failed\n",
    "        print(f\"Failed to fetch repositories for {language}. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to store repository metadata in a JSON file\n",
    "def store_metadata(language, metadata):\n",
    "    # File path to store metadata\n",
    "    file_path = f\"{language}_repos_metadata.json\"\n",
    "    \n",
    "    # Write metadata to the JSON file\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(metadata, file, indent=4)\n",
    "    \n",
    "    print(f\"Metadata for {language} repositories stored successfully in {file_path}\")\n",
    "\n",
    "def load_metadata(language):\n",
    "    # File path for metadata\n",
    "    file_path = f\"{language}_repos_metadata.json\"\n",
    "    \n",
    "    # Write metadata to the JSON file\n",
    "    with open(file_path, 'r') as file:\n",
    "        metadata = json.load(file)\n",
    "        return metadata\n",
    "\n",
    "# Iterate over each language\n",
    "for i in range(start,end):\n",
    "    language = languages[i]\n",
    "    print(f\"Fetching metadata for {language} repositories...\")\n",
    "        \n",
    "    # Fetch repository metadata\n",
    "    all_metadata = load_metadata(language)\n",
    "    for p in range(existing_pages+1,extra_pages+existing_pages+1):\n",
    "        repo_metadata = fetch_repo_metadata(language,p)\n",
    "        if repo_metadata:\n",
    "            all_metadata.extend(repo_metadata)\n",
    "            store_metadata(language, all_metadata)\n",
    "       \n",
    "    print(f\"Metadata retrieval for {language} complete.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8bc1a1e4-e9e6-4eb5-a44a-243a5bb07e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "merged_data = []\n",
    "\n",
    "for file in json_files:\n",
    "    file_path = os.path.join(current_dir, file)\n",
    "    file_path = file_path + \"_repos_metadata.json\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        try:\n",
    "            json_data = json.load(f)\n",
    "            merged_data.extend(json_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error reading file {file}: {e}\")\n",
    "\n",
    "with open(\"../all_repos.json\", 'w') as f:\n",
    "    json.dump(merged_data, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1370dc22-deb9-46c3-aac1-d8e4e6a3db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../langList.json\", 'r') as f:\n",
    "    try:\n",
    "        json_files = json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error reading file {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a967d4c1-aacc-4c35-bc6b-1ce6e96347c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../urgent.txt\", 'w') as f:\n",
    "    f.write(\"language: repos, aprox index\\n\")\n",
    "    for i in range(0,511):\n",
    "        r = merged_data[i]\n",
    "        if (len(r) < 200):\n",
    "            f.write(f\"{json_files[i]}: {len(r)} {i}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5631a561-3ede-4466-8db3-d38bea00613d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80384"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "08bb3e09-07e3-4988-b60f-5a8a01ff9092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TypeScript'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages[495]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ce640581-81ba-4c7e-bd44-d261505e306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from langList.json\n",
    "with open('../langList.json', 'r') as file:\n",
    "    lang_list = json.load(file)\n",
    "\n",
    "# Create a dictionary mapping string names to their index\n",
    "lang_dict = {lang: index for index, lang in enumerate(lang_list)}\n",
    "\n",
    "# Write the dictionary to a JSON file\n",
    "with open('../list2lang.json', 'w') as file:\n",
    "    json.dump(lang_dict, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
